2019-06-17 07:39:12,791 INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /tmp/junit7940220987662211376/hdds of  storage type : DISK and capacity : 104021790720
2019-06-17 07:39:12,798 INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /tmp/junit7940220987662211376/hdds to VolumeSet
2019-06-17 07:39:12,811 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@670b40af
2019-06-17 07:39:12,847 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@670b40af
2019-06-17 07:39:12,930 WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-17 07:39:12,977 INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /tmp/junit1684220953648549571/hdds of  storage type : DISK and capacity : 104021790720
2019-06-17 07:39:12,977 INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /tmp/junit1684220953648549571/hdds to VolumeSet
2019-06-17 07:39:12,977 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@32cf48b7
2019-06-17 07:39:12,978 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@32cf48b7
2019-06-17 07:39:13,182 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-17 07:39:14,058 INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /tmp/junit1684220953648549571/hdds of  storage type : DISK and capacity : 104021790720
2019-06-17 07:39:14,058 INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /tmp/junit1684220953648549571/hdds to VolumeSet
2019-06-17 07:39:14,059 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2e8e8225
2019-06-17 07:39:14,059 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2e8e8225
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-06-17 07:39:14,917 WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-06-17 07:39:14,940 INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-17 07:39:14,950 INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9858 (custom)
2019-06-17 07:39:14,951 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-17 07:39:14,953 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-17 07:39:14,954 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-17 07:39:14,955 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-17 07:39:15,082 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/tmp/junit1684220953648549571/junit7613513888514147293/ratis] (custom)
2019-06-17 07:39:15,116 WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-17 07:39:15,141 WARN  volume.VolumeUsage (VolumeUsage.java:saveScmUsed(176)) - Failed to write scmUsed to /tmp/junit1684220953648549571/scmUsed
java.io.FileNotFoundException: /tmp/junit1684220953648549571/scmUsed (No such file or directory)
	at java.io.FileOutputStream.open0(Native Method)
	at java.io.FileOutputStream.open(FileOutputStream.java:270)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:213)
	at java.io.FileOutputStream.<init>(FileOutputStream.java:162)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.saveScmUsed(VolumeUsage.java:165)
	at org.apache.hadoop.ozone.container.common.volume.VolumeUsage.shutdown(VolumeUsage.java:101)
	at org.apache.hadoop.ozone.container.common.volume.VolumeInfo.shutdownUsageThread(VolumeInfo.java:115)
	at org.apache.hadoop.ozone.container.common.volume.HddsVolume.shutdown(HddsVolume.java:404)
	at org.apache.hadoop.ozone.container.common.volume.VolumeSet.saveVolumeSetUsed(VolumeSet.java:412)
	at org.apache.hadoop.ozone.container.common.volume.VolumeSet.lambda$initializeVolumeSet$2(VolumeSet.java:198)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-17 07:39:15,143 WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted

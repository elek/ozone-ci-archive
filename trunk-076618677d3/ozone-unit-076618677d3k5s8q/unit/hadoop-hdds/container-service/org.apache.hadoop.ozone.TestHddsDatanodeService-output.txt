2019-06-17 02:14:12,246 WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-hddsdatanode.properties,hadoop-metrics2.properties
2019-06-17 02:14:12,324 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-06-17 02:14:12,324 INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - HddsDatanode metrics system started
2019-06-17 02:14:12,400 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-unit-076618677d3k5s8q-1549492551 ip:192.168.134.93
2019-06-17 02:14:12,439 INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-hdds/container-service/target/test-dir/BaKLQ0rAGF/disk1/hdds of  storage type : DISK and capacity : 104021790720
2019-06-17 02:14:12,440 INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-hdds/container-service/target/test-dir/BaKLQ0rAGF/disk1/hdds to VolumeSet
2019-06-17 02:14:12,451 INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@3098cf3b
2019-06-17 02:14:12,471 INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@3098cf3b
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-06-17 02:14:13,023 WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-06-17 02:14:13,043 INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-17 02:14:13,050 INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 9858 (custom)
2019-06-17 02:14:13,051 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-17 02:14:13,054 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-17 02:14:13,054 INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-17 02:14:13,055 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-17 02:14:13,165 INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-hdds/container-service/target/test-dir/BaKLQ0rAGF/ratis] (custom)
2019-06-17 02:14:13,194 INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-17 02:14:13,244 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-06-17 02:14:13,284 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:9882
2019-06-17 02:14:13,303 INFO  util.log (Log.java:initialized(192)) - Logging initialized @1739ms
2019-06-17 02:14:13,375 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-17 02:14:13,378 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.hddsDatanode is not defined
2019-06-17 02:14:13,384 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-17 02:14:13,386 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-17 02:14:13,386 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-17 02:14:13,386 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-17 02:14:13,405 INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 9882
2019-06-17 02:14:13,406 INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-17 02:14:13,437 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@30c31dd7{/logs,file:///opt/src/hadoop-hdds/container-service/target/log,AVAILABLE}
2019-06-17 02:14:13,438 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@596df867{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-17 02:14:13,466 INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3a71c100{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-17 02:14:13,474 INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@3fc08eec{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
2019-06-17 02:14:13,475 INFO  server.Server (Server.java:doStart(419)) - Started @1911ms
2019-06-17 02:14:13,504 INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:9882
2019-06-17 02:14:13,504 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.TestHddsDatanodeService$MockService@7b02e036
2019-06-17 02:14:13,505 INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.TestHddsDatanodeService$MockService@7b02e036
2019-06-17 02:14:13,507 INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-17 02:14:13,508 ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(352)) - Unable to start the DatanodeState Machine
java.util.concurrent.RejectedExecutionException: Task java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask@3acf60d3 rejected from org.apache.hadoop.util.concurrent.HadoopScheduledThreadPoolExecutor@1406cdbd[Shutting down, pool size = 1, active threads = 1, queued tasks = 1, completed tasks = 0]
	at java.util.concurrent.ThreadPoolExecutor$AbortPolicy.rejectedExecution(ThreadPoolExecutor.java:2063)
	at java.util.concurrent.ThreadPoolExecutor.reject(ThreadPoolExecutor.java:830)
	at java.util.concurrent.ScheduledThreadPoolExecutor.delayedExecute(ScheduledThreadPoolExecutor.java:326)
	at java.util.concurrent.ScheduledThreadPoolExecutor.schedule(ScheduledThreadPoolExecutor.java:533)
	at org.apache.hadoop.ozone.container.common.report.ReportPublisher.init(ReportPublisher.java:57)
	at org.apache.hadoop.ozone.container.common.report.ReportManager.init(ReportManager.java:65)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.start(DatanodeStateMachine.java:173)
	at org.apache.hadoop.ozone.container.common.statemachine.DatanodeStateMachine.lambda$startDaemon$0(DatanodeStateMachine.java:349)
	at java.lang.Thread.run(Thread.java:748)
2019-06-17 02:14:13,509 WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-17 02:14:13,521 INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-17 02:14:13,524 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3a71c100{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-17 02:14:13,528 INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@3fc08eec{HTTP/1.1,[http/1.1]}{0.0.0.0:9882}
2019-06-17 02:14:13,528 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@596df867{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-17 02:14:13,529 INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@30c31dd7{/logs,file:///opt/src/hadoop-hdds/container-service/target/log,UNAVAILABLE}

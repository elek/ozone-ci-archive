2019-06-18 14:18:56,940 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-18 14:18:57,064 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-18 14:18:57,068 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-18 14:18:57,090 INFO  util.log (Log.java:initialized(192)) - Logging initialized @1035ms
2019-06-18 14:18:57,230 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-06-18 14:18:57,230 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-06-18 14:18:57,231 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-06-18 14:18:57,231 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-06-18 14:18:57,231 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-06-18 14:18:57,232 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-06-18 14:18:57,248 INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-06-18 14:18:57,248 INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-06-18 14:18:57,250 INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-06-18 14:18:57,320 INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3d299e3
2019-06-18 14:18:57,322 INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-06-18 14:18:57,404 INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(119)) - Entering startup safe mode.
2019-06-18 14:18:57,495 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-18 14:18:57,521 INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-06-18 14:18:57,523 WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-18 14:18:57,588 WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
2019-06-18 14:18:57,661 WARN  util.NativeCodeLoader (NativeCodeLoader.java:<clinit>(60)) - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-06-18 14:18:57,990 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-18 14:18:58,025 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34183
2019-06-18 14:18:58,058 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-18 14:18:58,059 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38631
2019-06-18 14:18:58,067 INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 1000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-18 14:18:58,068 INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 43117
2019-06-18 14:18:58,126 INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-06-18 14:18:58,333 INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-18 14:18:58,349 INFO  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(81)) - Http request log for http.requests.scm is not defined
2019-06-18 14:18:58,358 INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-18 14:18:58,360 INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-06-18 14:18:58,361 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-18 14:18:58,361 INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-18 14:18:58,504 INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(109)) - Added a new node: /default-rack/211.197.75.81
2019-06-18 14:18:58,505 INFO  node.SCMNodeManager (SCMNodeManager.java:register(269)) - Registered Data node : 1474313f-77f0-43f6-a2f7-ceff24df70c3{ip: 211.197.75.81, host: localhost, networkLocation: /default-rack, certSerialId: null}
2019-06-18 14:18:58,506 INFO  net.NetworkTopology (NetworkTopologyImpl.java:add(109)) - Added a new node: /default-rack/62.198.219.31
2019-06-18 14:18:58,507 INFO  node.SCMNodeManager (SCMNodeManager.java:register(269)) - Registered Data node : 19470c0b-f35c-49c0-94cb-ff9110502906{ip: 62.198.219.31, host: localhost, networkLocation: /default-rack, certSerialId: null}
2019-06-18 14:18:59,517 INFO  node.StaleNodeHandler (StaleNodeHandler.java:onMessage(58)) - Datanode 1474313f-77f0-43f6-a2f7-ceff24df70c3{ip: 211.197.75.81, host: localhost, networkLocation: /default-rack, certSerialId: null} moved to stale state. Finalizing its pipelines []
2019-06-18 14:18:59,698 ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$initializePipeline$4(198)) - Pipeline initialization failed for pipeline:PipelineID=c195d8cd-ab30-4af7-8bdd-fdbcb5ced2d7 node:1474313f-77f0-43f6-a2f7-ceff24df70c3
2019-06-18 14:18:59,699 ERROR pipeline.RatisPipelineProvider (RatisPipelineProvider.java:lambda$null$5(235)) - Failed invoke Ratis rpc org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider$$Lambda$53/625312758@34b8548 for 1474313f-77f0-43f6-a2f7-ceff24df70c3
java.io.IOException: Pipeline initialization failed for pipeline:PipelineID=c195d8cd-ab30-4af7-8bdd-fdbcb5ced2d7 node:1474313f-77f0-43f6-a2f7-ceff24df70c3
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$initializePipeline$4(RatisPipelineProvider.java:199)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$null$5(RatisPipelineProvider.java:231)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184)
	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382)
	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482)
	at java.util.stream.ForEachOps$ForEachTask.compute(ForEachOps.java:291)
	at java.util.concurrent.CountedCompleter.exec(CountedCompleter.java:731)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinTask.doInvoke(ForkJoinTask.java:401)
	at java.util.concurrent.ForkJoinTask.invoke(ForkJoinTask.java:734)
	at java.util.stream.ForEachOps$ForEachOp.evaluateParallel(ForEachOps.java:160)
	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateParallel(ForEachOps.java:174)
	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:233)
	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418)
	at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:583)
	at org.apache.hadoop.hdds.scm.pipeline.RatisPipelineProvider.lambda$callRatisRpc$6(RatisPipelineProvider.java:225)
	at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)
	at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)
	at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)
	at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)
	at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)

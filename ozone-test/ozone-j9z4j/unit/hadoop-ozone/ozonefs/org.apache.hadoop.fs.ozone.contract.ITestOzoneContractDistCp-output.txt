2019-06-14 09:31:43,624 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:43,697 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:43,700 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:43,718 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @736ms
2019-06-14 09:31:43,820 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-06-14 09:31:43,821 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-06-14 09:31:43,821 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-06-14 09:31:43,821 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-06-14 09:31:43,822 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-06-14 09:31:43,822 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-06-14 09:31:43,833 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-06-14 09:31:43,834 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-06-14 09:31:43,836 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-06-14 09:31:43,928 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-06-14 09:31:43,929 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-06-14 09:31:43,931 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(108)) - Entering startup safe mode.
2019-06-14 09:31:44,001 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@3bb9a3ff
2019-06-14 09:31:44,003 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-06-14 09:31:44,058 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:44,080 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-06-14 09:31:44,083 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:44,166 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-06-14 09:31:44,626 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-14 09:31:44,654 [Socket Reader #1 for port 46261] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 46261
2019-06-14 09:31:44,675 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-14 09:31:44,675 [Socket Reader #1 for port 34109] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34109
2019-06-14 09:31:44,715 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-14 09:31:44,716 [Socket Reader #1 for port 34049] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34049
2019-06-14 09:31:44,732 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-06-14 09:31:44,814 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:44,826 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:44,833 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:44,834 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-06-14 09:31:44,835 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:44,835 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:44,855 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(752)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:34049
2019-06-14 09:31:44,887 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-06-14 09:31:44,895 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-06-14 09:31:44,896 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-06-14 09:31:45,073 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(149)) - RPC server for Client  is listening at /0.0.0.0:34049
2019-06-14 09:31:45,074 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-14 09:31:45,074 [IPC Server listener on 34049] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34049: starting
2019-06-14 09:31:45,077 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(761)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:34109
2019-06-14 09:31:45,077 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(137)) - RPC server for Block Protocol is listening at /0.0.0.0:34109
2019-06-14 09:31:45,077 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-14 09:31:45,077 [IPC Server listener on 34109] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34109: starting
2019-06-14 09:31:45,091 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(765)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:46261
2019-06-14 09:31:45,091 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:46261
2019-06-14 09:31:45,091 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-14 09:31:45,092 [IPC Server listener on 46261] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 46261: starting
2019-06-14 09:31:45,095 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 36785
2019-06-14 09:31:45,096 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:45,125 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@32c726ee{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:45,126 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@34c01041{/static,file:///opt/src/hadoop-hdds/server-scm/target/classes/webapps/static/,AVAILABLE}
2019-06-14 09:31:45,148 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@71984c3{/,file:///opt/src/hadoop-hdds/server-scm/target/classes/webapps/scm/,AVAILABLE}{/scm}
2019-06-14 09:31:45,153 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@50eca7c6{HTTP/1.1,[http/1.1]}{0.0.0.0:36785}
2019-06-14 09:31:45,153 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @2172ms
2019-06-14 09:31:45,154 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of SCM is listening at http://0.0.0.0:36785
2019-06-14 09:31:45,160 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@71ae31b0] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-14 09:31:45,163 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:45,234 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:45,235 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(519)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-06-14 09:31:45,235 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(525)) - OM Node ID is not set. Setting it to the OmStorage's OmID: bb3a53e4-6428-4e3b-8495-11d8669f0251
2019-06-14 09:31:45,236 [JUnit] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-06-14 09:31:45,237 [JUnit] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-06-14 09:31:45,237 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(476)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-06-14 09:31:45,428 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:45,435 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-06-14 09:31:45,435 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-06-14 09:31:45,435 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-06-14 09:31:45,436 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-06-14 09:31:45,436 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-06-14 09:31:45,436 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-06-14 09:31:45,436 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-06-14 09:31:45,436 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-06-14 09:31:45,437 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-06-14 09:31:45,437 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-06-14 09:31:45,437 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-06-14 09:31:45,437 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-06-14 09:31:45,437 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-06-14 09:31:45,438 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-06-14 09:31:45,438 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-06-14 09:31:45,438 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-06-14 09:31:45,438 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-06-14 09:31:45,438 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-06-14 09:31:45,439 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-06-14 09:31:45,953 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-14 09:31:45,953 [Socket Reader #1 for port 35323] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 35323
2019-06-14 09:31:45,979 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-14 09:31:45,980 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1217)) - OzoneManager RPC server is listening at localhost/127.0.0.1:35323
2019-06-14 09:31:45,980 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-06-14 09:31:45,985 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-14 09:31:45,985 [IPC Server listener on 35323] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 35323: starting
2019-06-14 09:31:45,996 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-06-14 09:31:45,998 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:45,999 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:46,001 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:46,002 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-06-14 09:31:46,002 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:46,002 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:46,004 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45691
2019-06-14 09:31:46,004 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:46,006 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22fa55b2{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:46,006 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@6594402a{/static,file:///opt/src/hadoop-ozone/ozone-manager/target/classes/webapps/static/,AVAILABLE}
2019-06-14 09:31:46,010 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2c0f7678{/,file:///opt/src/hadoop-ozone/ozone-manager/target/classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-06-14 09:31:46,011 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@44d70181{HTTP/1.1,[http/1.1]}{0.0.0.0:45691}
2019-06-14 09:31:46,011 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3029ms
2019-06-14 09:31:46,013 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:45691
2019-06-14 09:31:46,223 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-14 09:31:46,297 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-j9z4j-3433919898 ip:192.168.46.41
2019-06-14 09:31:46,331 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-14 09:31:46,333 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/containers/hdds to VolumeSet
2019-06-14 09:31:46,335 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2d84cb86
2019-06-14 09:31:46,359 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2d84cb86
2019-06-14 09:31:46,426 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 46523
2019-06-14 09:31:46,498 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-14 09:31:46,508 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 46523 (custom)
2019-06-14 09:31:46,509 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-14 09:31:46,511 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:46,511 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-14 09:31:46,512 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:46,691 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis] (custom)
2019-06-14 09:31:46,698 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 38325
2019-06-14 09:31:46,731 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-14 09:31:46,743 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-14 09:31:46,745 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:46,745 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:46,748 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:46,748 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-14 09:31:46,749 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:46,749 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:46,750 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 46447
2019-06-14 09:31:46,750 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:46,752 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@2add4d24{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:46,753 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12b5454f{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-14 09:31:46,756 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5f18f9d2{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-14 09:31:46,757 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@598260a6{HTTP/1.1,[http/1.1]}{0.0.0.0:46447}
2019-06-14 09:31:46,757 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3776ms
2019-06-14 09:31:46,758 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:46447
Jun 14, 2019 9:31:46 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-14 09:31:47,594 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@4548d254
2019-06-14 09:31:47,598 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-14 09:31:47,598 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-j9z4j-3433919898 ip:192.168.46.41
2019-06-14 09:31:47,605 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4807a990] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-14 09:31:47,617 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-14 09:31:47,618 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/containers/hdds to VolumeSet
2019-06-14 09:31:47,618 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@6badba10
2019-06-14 09:31:47,634 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@6badba10
2019-06-14 09:31:47,661 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 42411
2019-06-14 09:31:47,663 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-14 09:31:47,663 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 42411 (custom)
2019-06-14 09:31:47,663 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-14 09:31:47,664 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:47,664 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-14 09:31:47,665 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:47,665 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis] (custom)
2019-06-14 09:31:47,666 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 46605
2019-06-14 09:31:47,666 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-14 09:31:47,667 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-14 09:31:47,669 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:47,670 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:47,672 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:47,673 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-14 09:31:47,673 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:47,673 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:47,674 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39039
2019-06-14 09:31:47,674 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:47,679 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@74d6736{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:47,679 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@668625f5{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-14 09:31:47,682 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3330f3ad{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-14 09:31:47,683 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@563af4e7{HTTP/1.1,[http/1.1]}{0.0.0.0:39039}
2019-06-14 09:31:47,684 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4703ms
2019-06-14 09:31:47,685 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39039
Jun 14, 2019 9:31:47 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-14 09:31:47,739 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/meta/datanode.id
2019-06-14 09:31:47,903 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@9c73fff
2019-06-14 09:31:47,903 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-14 09:31:47,903 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-j9z4j-3433919898 ip:192.168.46.41
2019-06-14 09:31:47,918 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@54fcde80] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-14 09:31:47,919 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-14 09:31:47,919 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/containers/hdds to VolumeSet
2019-06-14 09:31:47,920 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2abbd0d9
2019-06-14 09:31:47,922 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2abbd0d9
2019-06-14 09:31:47,923 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/meta/datanode.id
2019-06-14 09:31:47,943 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 38669
2019-06-14 09:31:47,944 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-14 09:31:47,945 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 38669 (custom)
2019-06-14 09:31:47,945 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-14 09:31:47,945 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:47,946 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-14 09:31:47,946 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:47,946 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis] (custom)
2019-06-14 09:31:47,947 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 37089
2019-06-14 09:31:47,948 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-14 09:31:47,949 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-14 09:31:47,950 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:47,951 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:47,953 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:47,954 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-14 09:31:47,954 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:47,955 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:47,955 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 41673
2019-06-14 09:31:47,955 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:47,957 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@65f40689{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:47,958 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@33eb6758{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-14 09:31:47,961 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@76e3b45b{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-14 09:31:47,962 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@10b4e7f8{HTTP/1.1,[http/1.1]}{0.0.0.0:41673}
2019-06-14 09:31:47,963 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4982ms
2019-06-14 09:31:47,964 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:41673
Jun 14, 2019 9:31:47 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-14 09:31:48,087 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@468e8565
2019-06-14 09:31:48,087 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-14 09:31:48,088 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-j9z4j-3433919898 ip:192.168.46.41
2019-06-14 09:31:48,094 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@689ce06b] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-14 09:31:48,095 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/meta/datanode.id
2019-06-14 09:31:48,101 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-14 09:31:48,101 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/containers/hdds to VolumeSet
2019-06-14 09:31:48,102 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@17e0933c
2019-06-14 09:31:48,102 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@17e0933c
2019-06-14 09:31:48,118 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 34265
2019-06-14 09:31:48,123 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-14 09:31:48,123 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 34265 (custom)
2019-06-14 09:31:48,123 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-14 09:31:48,123 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:48,124 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-14 09:31:48,124 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:48,124 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis] (custom)
2019-06-14 09:31:48,125 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 35819
2019-06-14 09:31:48,125 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-14 09:31:48,161 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-14 09:31:48,163 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:48,164 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:48,166 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:48,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-14 09:31:48,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:48,167 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:48,168 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 42837
2019-06-14 09:31:48,168 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:48,172 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66383c29{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:48,172 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5d152bcd{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-14 09:31:48,178 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@2291d9a0{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-14 09:31:48,179 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5e26f1ed{HTTP/1.1,[http/1.1]}{0.0.0.0:42837}
2019-06-14 09:31:48,181 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5199ms
2019-06-14 09:31:48,182 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:42837
Jun 14, 2019 9:31:48 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-14 09:31:48,338 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@47b33e07
2019-06-14 09:31:48,338 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-14 09:31:48,338 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-j9z4j-3433919898 ip:192.168.46.41
2019-06-14 09:31:48,347 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/meta/datanode.id
2019-06-14 09:31:48,352 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@1103eed5] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-14 09:31:48,352 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-14 09:31:48,352 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/containers/hdds to VolumeSet
2019-06-14 09:31:48,352 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@19489b27
2019-06-14 09:31:48,358 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@19489b27
2019-06-14 09:31:48,374 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 38597
2019-06-14 09:31:48,375 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-14 09:31:48,375 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 38597 (custom)
2019-06-14 09:31:48,376 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-14 09:31:48,376 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:48,376 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-14 09:31:48,376 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:48,377 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis] (custom)
2019-06-14 09:31:48,377 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 41557
2019-06-14 09:31:48,378 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-14 09:31:48,379 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-14 09:31:48,380 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-14 09:31:48,382 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-14 09:31:48,383 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-14 09:31:48,384 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-14 09:31:48,384 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-14 09:31:48,384 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-14 09:31:48,385 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45619
2019-06-14 09:31:48,385 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-14 09:31:48,399 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5ae15{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-14 09:31:48,399 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@12219f6a{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-14 09:31:48,403 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@37a0ec3c{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-14 09:31:48,406 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@422ad5e2{HTTP/1.1,[http/1.1]}{0.0.0.0:45619}
2019-06-14 09:31:48,406 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @5425ms
2019-06-14 09:31:48,407 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45619
Jun 14, 2019 9:31:48 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-14 09:31:48,580 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@383cb5ce
2019-06-14 09:31:48,581 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-14 09:31:48,581 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@567e72b9] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-14 09:31:48,583 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/meta/datanode.id
2019-06-14 09:31:49,581 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-14 09:31:49,626 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-14 09:31:49,626 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-14 09:31:49,626 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 0fd43f4d-887d-4ae8-add1-de86fbcb71c1 at port 46523
2019-06-14 09:31:49,640 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start RPC server
2019-06-14 09:31:49,800 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: GrpcService started, listening on 0.0.0.0/0.0.0.0:46523
2019-06-14 09:31:49,919 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-14 09:31:49,920 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-14 09:31:49,921 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis d14f1d27-9abd-48d3-981e-07fbbfd7075f at port 42411
2019-06-14 09:31:49,958 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: start RPC server
2019-06-14 09:31:49,960 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: GrpcService started, listening on 0.0.0.0/0.0.0.0:42411
2019-06-14 09:31:50,099 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-14 09:31:50,101 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-14 09:31:50,101 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 86e25bb3-b667-4401-8ad3-7e3322543d24 at port 38669
2019-06-14 09:31:50,121 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start RPC server
2019-06-14 09:31:50,123 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: GrpcService started, listening on 0.0.0.0/0.0.0.0:38669
2019-06-14 09:31:50,351 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-14 09:31:50,352 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-14 09:31:50,352 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 at port 34265
2019-06-14 09:31:50,356 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start RPC server
2019-06-14 09:31:50,358 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: GrpcService started, listening on 0.0.0.0/0.0.0.0:34265
2019-06-14 09:31:50,581 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-14 09:31:50,586 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-14 09:31:50,588 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-14 09:31:50,588 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 7878b601-6f67-4deb-a261-1ba03dfc2f7b at port 38597
2019-06-14 09:31:50,595 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: start RPC server
2019-06-14 09:31:50,597 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: GrpcService started, listening on 0.0.0.0/0.0.0.0:38597
2019-06-14 09:31:51,582 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-14 09:31:51,627 [IPC Server handler 17 on 46261] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 0fd43f4d-887d-4ae8-add1-de86fbcb71c1{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}
2019-06-14 09:31:51,629 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-06-14 09:31:51,630 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-06-14 09:31:51,630 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-06-14 09:31:51,922 [IPC Server handler 15 on 46261] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : d14f1d27-9abd-48d3-981e-07fbbfd7075f{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}
2019-06-14 09:31:52,051 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: addNew group-F9458460E34B:[0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523] returns group-F9458460E34B:java.util.concurrent.CompletableFuture@5e7780fc[Not completed]
2019-06-14 09:31:52,057 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: new RaftServerImpl for group-F9458460E34B:[0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,058 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,058 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,058 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,059 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,064 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B ConfigurationManager, init=-1: [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,065 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis] (custom)
2019-06-14 09:31:52,070 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/40ab39b1-bb56-4f64-991c-f9458460e34b does not exist. Creating ...
2019-06-14 09:31:52,075 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/40ab39b1-bb56-4f64-991c-f9458460e34b/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,079 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/40ab39b1-bb56-4f64-991c-f9458460e34b has been successfully formatted.
2019-06-14 09:31:52,080 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,081 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,082 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,084 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,087 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,090 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,093 [pool-37-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/40ab39b1-bb56-4f64-991c-f9458460e34b
2019-06-14 09:31:52,094 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,094 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,096 [IPC Server handler 18 on 46261] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 86e25bb3-b667-4401-8ad3-7e3322543d24{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}
2019-06-14 09:31:52,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,097 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,098 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,098 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,099 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,100 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,102 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,212 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,213 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,214 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,232 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start group-F9458460E34B
2019-06-14 09:31:52,233 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,234 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start FollowerState
2019-06-14 09:31:52,235 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9458460E34B,id=0fd43f4d-887d-4ae8-add1-de86fbcb71c1
2019-06-14 09:31:52,278 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 40ab39b1-bb56-4f64-991c-f9458460e34b, Nodes: 0fd43f4d-887d-4ae8-add1-de86fbcb71c1{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-14 09:31:52,291 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: addNew group-FDE03975E078:[86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] returns group-FDE03975E078:java.util.concurrent.CompletableFuture@4aeaa363[Not completed]
2019-06-14 09:31:52,292 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: new RaftServerImpl for group-FDE03975E078:[86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,293 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,293 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,293 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,293 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,293 [pool-79-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 ConfigurationManager, init=-1: [86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,293 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis] (custom)
2019-06-14 09:31:52,294 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/69d44346-3131-46ec-9501-fde03975e078 does not exist. Creating ...
2019-06-14 09:31:52,296 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/69d44346-3131-46ec-9501-fde03975e078/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,298 [pool-79-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/69d44346-3131-46ec-9501-fde03975e078 has been successfully formatted.
2019-06-14 09:31:52,298 [pool-79-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,298 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,298 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,298 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,298 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/69d44346-3131-46ec-9501-fde03975e078
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,299 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,300 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,300 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,300 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,300 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start group-FDE03975E078
2019-06-14 09:31:52,300 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,300 [pool-79-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start FollowerState
2019-06-14 09:31:52,301 [pool-79-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-FDE03975E078,id=86e25bb3-b667-4401-8ad3-7e3322543d24
2019-06-14 09:31:52,312 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 69d44346-3131-46ec-9501-fde03975e078, Nodes: 86e25bb3-b667-4401-8ad3-7e3322543d24{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-14 09:31:52,326 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: addNew group-600A8E3C0556:[d14f1d27-9abd-48d3-981e-07fbbfd7075f:192.168.46.41:42411] returns group-600A8E3C0556:java.util.concurrent.CompletableFuture@4f448f16[Not completed]
2019-06-14 09:31:52,351 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: new RaftServerImpl for group-600A8E3C0556:[d14f1d27-9abd-48d3-981e-07fbbfd7075f:192.168.46.41:42411] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,351 [IPC Server handler 16 on 46261] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}
2019-06-14 09:31:52,352 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,352 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,352 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,352 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,352 [pool-58-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 ConfigurationManager, init=-1: [d14f1d27-9abd-48d3-981e-07fbbfd7075f:192.168.46.41:42411], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,352 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis] (custom)
2019-06-14 09:31:52,353 [pool-58-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis/e57e42f0-1ff9-4ff7-ba37-600a8e3c0556 does not exist. Creating ...
2019-06-14 09:31:52,355 [pool-58-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis/e57e42f0-1ff9-4ff7-ba37-600a8e3c0556/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,358 [pool-58-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis/e57e42f0-1ff9-4ff7-ba37-600a8e3c0556 has been successfully formatted.
2019-06-14 09:31:52,359 [pool-58-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,360 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,360 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,360 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,360 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,360 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,360 [pool-58-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis/e57e42f0-1ff9-4ff7-ba37-600a8e3c0556
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,361 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,362 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: start group-600A8E3C0556
2019-06-14 09:31:52,363 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,363 [pool-58-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: start FollowerState
2019-06-14 09:31:52,363 [pool-58-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-600A8E3C0556,id=d14f1d27-9abd-48d3-981e-07fbbfd7075f
2019-06-14 09:31:52,369 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: e57e42f0-1ff9-4ff7-ba37-600a8e3c0556, Nodes: d14f1d27-9abd-48d3-981e-07fbbfd7075f{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-14 09:31:52,379 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: addNew group-77828CEAED7A:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265] returns group-77828CEAED7A:java.util.concurrent.CompletableFuture@252aa43e[Not completed]
2019-06-14 09:31:52,382 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: new RaftServerImpl for group-77828CEAED7A:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,382 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,382 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,383 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,383 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,383 [pool-100-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A ConfigurationManager, init=-1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,383 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis] (custom)
2019-06-14 09:31:52,383 [pool-100-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/d1dd4f5b-272a-44e2-9bc6-77828ceaed7a does not exist. Creating ...
2019-06-14 09:31:52,385 [pool-100-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/d1dd4f5b-272a-44e2-9bc6-77828ceaed7a/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,387 [pool-100-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/d1dd4f5b-272a-44e2-9bc6-77828ceaed7a has been successfully formatted.
2019-06-14 09:31:52,387 [pool-100-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/d1dd4f5b-272a-44e2-9bc6-77828ceaed7a
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,388 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,389 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,390 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,390 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start group-77828CEAED7A
2019-06-14 09:31:52,390 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,390 [pool-100-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start FollowerState
2019-06-14 09:31:52,390 [pool-100-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-77828CEAED7A,id=2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0
2019-06-14 09:31:52,399 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d1dd4f5b-272a-44e2-9bc6-77828ceaed7a, Nodes: 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-14 09:31:52,425 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: addNew group-D07D4A80573F:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] returns group-D07D4A80573F:java.util.concurrent.CompletableFuture@6797a0db[Not completed]
2019-06-14 09:31:52,427 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: new RaftServerImpl for group-D07D4A80573F:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,427 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,427 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,427 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,427 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,427 [pool-79-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-D07D4A80573F ConfigurationManager, init=-1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,428 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis] (custom)
2019-06-14 09:31:52,428 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f does not exist. Creating ...
2019-06-14 09:31:52,430 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,431 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: new RaftServerImpl for group-D07D4A80573F:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,431 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,431 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,431 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,432 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,432 [pool-100-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F ConfigurationManager, init=-1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,432 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis] (custom)
2019-06-14 09:31:52,432 [pool-100-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f does not exist. Creating ...
2019-06-14 09:31:52,432 [pool-79-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f has been successfully formatted.
2019-06-14 09:31:52,432 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: addNew group-D07D4A80573F:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] returns group-D07D4A80573F:java.util.concurrent.CompletableFuture@635a053f[Not completed]
2019-06-14 09:31:52,432 [pool-79-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,433 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,433 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: addNew group-D07D4A80573F:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] returns group-D07D4A80573F:java.util.concurrent.CompletableFuture@2295224d[Not completed]
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: new RaftServerImpl for group-D07D4A80573F:[2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-D07D4A80573F ConfigurationManager, init=-1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis] (custom)
2019-06-14 09:31:52,434 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f does not exist. Creating ...
2019-06-14 09:31:52,433 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,434 [pool-100-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,435 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,435 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,435 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,435 [pool-79-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,436 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,437 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,437 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,437 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,437 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,437 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,437 [pool-100-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f has been successfully formatted.
2019-06-14 09:31:52,437 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start group-D07D4A80573F
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,438 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-D07D4A80573F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,438 [pool-79-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start FollowerState
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,438 [pool-79-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D07D4A80573F,id=86e25bb3-b667-4401-8ad3-7e3322543d24
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,438 [pool-100-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f
2019-06-14 09:31:52,439 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,439 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,439 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,439 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f has been successfully formatted.
2019-06-14 09:31:52,439 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,439 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,439 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,439 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,440 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,440 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,440 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,441 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,441 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,441 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,441 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,441 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,442 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,442 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,446 [pool-37-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f
2019-06-14 09:31:52,446 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,447 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,448 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,448 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,448 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,448 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start group-D07D4A80573F
2019-06-14 09:31:52,448 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,449 [pool-100-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start FollowerState
2019-06-14 09:31:52,449 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,449 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,449 [pool-100-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D07D4A80573F,id=2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0
2019-06-14 09:31:52,454 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,454 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start group-D07D4A80573F
2019-06-14 09:31:52,454 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-D07D4A80573F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,454 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start FollowerState
2019-06-14 09:31:52,455 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-D07D4A80573F,id=0fd43f4d-887d-4ae8-add1-de86fbcb71c1
2019-06-14 09:31:52,459 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 445fd37c-da5f-43b3-a546-d07d4a80573f, Nodes: 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}0fd43f4d-887d-4ae8-add1-de86fbcb71c1{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}86e25bb3-b667-4401-8ad3-7e3322543d24{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-06-14 09:31:52,582 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-06-14 09:31:52,585 [IPC Server handler 17 on 46261] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 7878b601-6f67-4deb-a261-1ba03dfc2f7b{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}
2019-06-14 09:31:52,596 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: addNew group-BBFF490E5A8C:[7878b601-6f67-4deb-a261-1ba03dfc2f7b:192.168.46.41:38597] returns group-BBFF490E5A8C:java.util.concurrent.CompletableFuture@49b61933[Not completed]
2019-06-14 09:31:52,596 [pool-121-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: new RaftServerImpl for group-BBFF490E5A8C:[7878b601-6f67-4deb-a261-1ba03dfc2f7b:192.168.46.41:38597] with ContainerStateMachine:uninitialized
2019-06-14 09:31:52,596 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-14 09:31:52,597 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-14 09:31:52,597 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-14 09:31:52,597 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:52,597 [pool-121-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C ConfigurationManager, init=-1: [7878b601-6f67-4deb-a261-1ba03dfc2f7b:192.168.46.41:38597], old=null, confs=<EMPTY_MAP>
2019-06-14 09:31:52,597 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis] (custom)
2019-06-14 09:31:52,597 [pool-121-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis/962bd719-d651-4217-9c2d-bbff490e5a8c does not exist. Creating ...
2019-06-14 09:31:52,599 [pool-121-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis/962bd719-d651-4217-9c2d-bbff490e5a8c/in_use.lock acquired by nodename 24331@ozone-j9z4j-3433919898
2019-06-14 09:31:52,601 [pool-121-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis/962bd719-d651-4217-9c2d-bbff490e5a8c has been successfully formatted.
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis/962bd719-d651-4217-9c2d-bbff490e5a8c
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-14 09:31:52,602 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-14 09:31:52,603 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-14 09:31:52,604 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-14 09:31:52,604 [pool-121-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: start group-BBFF490E5A8C
2019-06-14 09:31:52,604 [pool-121-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-14 09:31:52,604 [pool-121-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: start FollowerState
2019-06-14 09:31:52,604 [pool-121-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-BBFF490E5A8C,id=7878b601-6f67-4deb-a261-1ba03dfc2f7b
2019-06-14 09:31:52,609 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 962bd719-d651-4217-9c2d-bbff490e5a8c, Nodes: 7878b601-6f67-4deb-a261-1ba03dfc2f7b{ip: 192.168.46.41, host: ozone-j9z4j-3433919898, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-14 09:31:53,305 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(101)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 changes to CANDIDATE, lastRpcTime:1004, electionTimeout:1004ms
2019-06-14 09:31:53,306 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown FollowerState
2019-06-14 09:31:53,306 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-14 09:31:53,307 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start LeaderElection
2019-06-14 09:31:53,314 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1: begin an election at term 1 for -1: [86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null
2019-06-14 09:31:53,315 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown LeaderElection
2019-06-14 09:31:53,315 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-14 09:31:53,316 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 change Leader from null to 86e25bb3-b667-4401-8ad3-7e3322543d24 at term 1 for becomeLeader, leader elected after 1017ms
2019-06-14 09:31:53,320 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-14 09:31:53,320 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-14 09:31:53,323 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-14 09:31:53,323 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-14 09:31:53,329 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start LeaderState
2019-06-14 09:31:53,346 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,355 [86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 set configuration 0: [86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null at 0
2019-06-14 09:31:53,370 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(101)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B changes to CANDIDATE, lastRpcTime:1136, electionTimeout:1136ms
2019-06-14 09:31:53,372 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown FollowerState
2019-06-14 09:31:53,372 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-14 09:31:53,372 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start LeaderElection
2019-06-14 09:31:53,385 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2: begin an election at term 1 for -1: [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523], old=null
2019-06-14 09:31:53,386 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown LeaderElection
2019-06-14 09:31:53,386 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-14 09:31:53,386 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B change Leader from null to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1 at term 1 for becomeLeader, leader elected after 1305ms
2019-06-14 09:31:53,386 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-14 09:31:53,386 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-14 09:31:53,387 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-14 09:31:53,387 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-14 09:31:53,388 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(101)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 changes to CANDIDATE, lastRpcTime:1025, electionTimeout:1025ms
2019-06-14 09:31:53,388 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: shutdown FollowerState
2019-06-14 09:31:53,388 [Thread-215] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-14 09:31:53,388 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: start LeaderElection
2019-06-14 09:31:53,390 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start LeaderState
2019-06-14 09:31:53,392 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,398 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B set configuration 0: [0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523], old=null at 0
2019-06-14 09:31:53,400 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3: begin an election at term 1 for -1: [d14f1d27-9abd-48d3-981e-07fbbfd7075f:192.168.46.41:42411], old=null
2019-06-14 09:31:53,400 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: shutdown LeaderElection
2019-06-14 09:31:53,400 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-14 09:31:53,400 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 change Leader from null to d14f1d27-9abd-48d3-981e-07fbbfd7075f at term 1 for becomeLeader, leader elected after 1040ms
2019-06-14 09:31:53,401 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-14 09:31:53,402 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-14 09:31:53,402 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-14 09:31:53,402 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-14 09:31:53,402 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: start LeaderState
2019-06-14 09:31:53,402 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,405 [d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556:LeaderElection3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 set configuration 0: [d14f1d27-9abd-48d3-981e-07fbbfd7075f:192.168.46.41:42411], old=null at 0
2019-06-14 09:31:53,450 [Thread-224] INFO  impl.FollowerState (FollowerState.java:run(101)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F changes to CANDIDATE, lastRpcTime:1001, electionTimeout:1001ms
2019-06-14 09:31:53,450 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown FollowerState
2019-06-14 09:31:53,450 [Thread-224] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-14 09:31:53,451 [Thread-224] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start LeaderElection
2019-06-14 09:31:53,456 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4: begin an election at term 1 for -1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null
2019-06-14 09:31:53,483 [grpc-default-executor-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-D07D4A80573F changes role from FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0
2019-06-14 09:31:53,483 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown FollowerState
2019-06-14 09:31:53,483 [grpc-default-executor-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: start FollowerState
2019-06-14 09:31:53,483 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(109)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-14 09:31:53,492 [grpc-default-executor-2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-D07D4A80573F changes role from FOLLOWER to FOLLOWER at term 1 for recognizeCandidate:2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0
2019-06-14 09:31:53,492 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown FollowerState
2019-06-14 09:31:53,492 [Thread-221] INFO  impl.FollowerState (FollowerState.java:run(109)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-14 09:31:53,492 [grpc-default-executor-2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: start FollowerState
2019-06-14 09:31:53,502 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4: Election PASSED; received 1 response(s) [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1,true-t1] and 0 exception(s); 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:t1, leader=null, voted=2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0, raftlog=2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null
2019-06-14 09:31:53,503 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown LeaderElection
2019-06-14 09:31:53,503 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-14 09:31:53,504 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F change Leader from null to 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 at term 1 for becomeLeader, leader elected after 1066ms
2019-06-14 09:31:53,503 [Thread-218] INFO  impl.FollowerState (FollowerState.java:run(101)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A changes to CANDIDATE, lastRpcTime:1113, electionTimeout:1110ms
2019-06-14 09:31:53,505 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown FollowerState
2019-06-14 09:31:53,505 [Thread-218] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-14 09:31:53,506 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start LeaderElection
2019-06-14 09:31:53,505 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-14 09:31:53,506 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-14 09:31:53,506 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-14 09:31:53,506 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-14 09:31:53,509 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-06-14 09:31:53,510 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:53,510 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-06-14 09:31:53,511 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-06-14 09:31:53,511 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-14 09:31:53,512 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-14 09:31:53,513 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start LeaderState
2019-06-14 09:31:53,513 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,546 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5: begin an election at term 1 for -1: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265], old=null
2019-06-14 09:31:53,546 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown LeaderElection
2019-06-14 09:31:53,546 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-14 09:31:53,547 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A change Leader from null to 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 at term 1 for becomeLeader, leader elected after 1158ms
2019-06-14 09:31:53,547 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-14 09:31:53,547 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-14 09:31:53,550 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F:LeaderElection4] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F set configuration 0: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null at 0
2019-06-14 09:31:53,583 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
2019-06-14 09:31:53,584 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/40ab39b1-bb56-4f64-991c-f9458460e34b/current/log_inprogress_0
2019-06-14 09:31:53,584 [d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/ratis/e57e42f0-1ff9-4ff7-ba37-600a8e3c0556/current/log_inprogress_0
Jun 14, 2019 9:31:53 AM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-14 09:31:53,594 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-D07D4A80573F change Leader from null to 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 at term 1 for appendEntries, leader elected after 1154ms
2019-06-14 09:31:53,602 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/current/log_inprogress_0
2019-06-14 09:31:53,603 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-14 09:31:53,603 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-14 09:31:53,604 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: start LeaderState
2019-06-14 09:31:53,604 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,605 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-D07D4A80573F change Leader from null to 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 at term 1 for appendEntries, leader elected after 1171ms
2019-06-14 09:31:53,624 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A set configuration 0: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265], old=null at 0
2019-06-14 09:31:53,675 [86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/69d44346-3131-46ec-9501-fde03975e078/current/log_inprogress_0
2019-06-14 09:31:53,678 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/d1dd4f5b-272a-44e2-9bc6-77828ceaed7a/current/log_inprogress_0
2019-06-14 09:31:53,687 [grpc-default-executor-1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-D07D4A80573F set configuration 0: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null at 0
2019-06-14 09:31:53,687 [grpc-default-executor-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,688 [grpc-default-executor-2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-D07D4A80573F set configuration 0: [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:192.168.46.41:34265, 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523, 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669], old=null at 0
2019-06-14 09:31:53,689 [grpc-default-executor-2] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,693 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(101)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C changes to CANDIDATE, lastRpcTime:1089, electionTimeout:1089ms
2019-06-14 09:31:53,693 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: shutdown FollowerState
2019-06-14 09:31:53,693 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-14 09:31:53,694 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: start LeaderElection
2019-06-14 09:31:53,732 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6: begin an election at term 1 for -1: [7878b601-6f67-4deb-a261-1ba03dfc2f7b:192.168.46.41:38597], old=null
2019-06-14 09:31:53,733 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: shutdown LeaderElection
2019-06-14 09:31:53,733 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-14 09:31:53,733 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C change Leader from null to 7878b601-6f67-4deb-a261-1ba03dfc2f7b at term 1 for becomeLeader, leader elected after 1131ms
2019-06-14 09:31:53,734 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-14 09:31:53,734 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-14 09:31:53,734 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-14 09:31:53,734 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-14 09:31:53,735 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: start LeaderState
2019-06-14 09:31:53,735 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker: Starting segment from index:0
2019-06-14 09:31:53,735 [7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C:LeaderElection6] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C set configuration 0: [7878b601-6f67-4deb-a261-1ba03dfc2f7b:192.168.46.41:38597], old=null at 0
2019-06-14 09:31:53,735 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/current/log_inprogress_0
2019-06-14 09:31:53,771 [86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/current/log_inprogress_0
2019-06-14 09:31:53,781 [7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/ratis/962bd719-d651-4217-9c2d-bbff490e5a8c/current/log_inprogress_0
2019-06-14 09:31:53,855 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:31:54,299 [Thread-256] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket35831.volume50200 implemented by OzoneFileSystem{URI=o3fs://bucket35831.volume50200, workingDir=o3fs://bucket35831.volume50200/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
09:31:54.313 [IPC Server handler 15 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:54.414 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:54.444 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:54,449 [Thread-256] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update an unchanged directory structure from local to remote; expect no copy
2019-06-14 09:31:54,625 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:54,654 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
09:31:54.724 [IPC Server handler 18 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:54,807 [Thread-256] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-06-14 09:31:54,807 [Thread-256] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:31:54,808 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.mb is deprecated. Instead, use mapreduce.task.io.sort.mb
2019-06-14 09:31:54,808 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - io.sort.factor is deprecated. Instead, use mapreduce.task.io.sort.factor
2019-06-14 09:31:54,828 [Thread-256] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:54,835 [Thread-256] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:54,839 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:54,866 [Thread-256] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:31:54,912 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:9
2019-06-14 09:31:55,029 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1751710343_0001
2019-06-14 09:31:55,029 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:31:55,157 [Thread-256] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:31:55,158 [Thread-256] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1751710343_0001
2019-06-14 09:31:55,158 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1751710343_0001
2019-06-14 09:31:55,164 [Thread-330] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:31:55,171 [Thread-330] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,171 [Thread-330] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,172 [Thread-330] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:31:55,213 [Thread-330] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:31:55,216 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000000_0
2019-06-14 09:31:55,244 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,245 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,259 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:55,262 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:1632+566
2019-06-14 09:31:55,270 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,270 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
09:31:55.290 [IPC Server handler 15 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,292 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
09:31:55.303 [IPC Server handler 12 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,307 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0
09:31:55.653 [IPC Server handler 1 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.654 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.656 [IPC Server handler 19 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.662 [IPC Server handler 15 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.672 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,672 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0
2019-06-14 09:31:55,675 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
09:31:55.678 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0
09:31:55.753 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.755 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.756 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.762 [IPC Server handler 19 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.768 [IPC Server handler 12 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,770 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000000_0
2019-06-14 09:31:55,774 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:55,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000000_0 is done. And is in the process of committing
2019-06-14 09:31:55,780 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:55,780 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000000_0 is allowed to commit now
2019-06-14 09:31:55,781 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000000_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:55,782 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3 [300.0B/300.0B]
2019-06-14 09:31:55,782 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000000_0' done.
2019-06-14 09:31:55,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=204109
		FILE: Number of bytes written=813518
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=700
		O3FS: Number of read operations=29
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=7
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=36
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=700
		Bytes Copied=700
		Bytes Expected=700
		Files Copied=2
2019-06-14 09:31:55,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000000_0
2019-06-14 09:31:55,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000001_0
2019-06-14 09:31:55,788 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,788 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,788 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:55,789 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:827+550
2019-06-14 09:31:55,789 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,789 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,799 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
09:31:55.802 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,803 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0
09:31:55.886 [IPC Server handler 10 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.888 [IPC Server handler 7 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.889 [IPC Server handler 3 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.896 [IPC Server handler 18 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.903 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,904 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0
2019-06-14 09:31:55,904 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
09:31:55.908 [IPC Server handler 0 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,909 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0
09:31:55.948 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.951 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:55.957 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:55,958 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000001_0
2019-06-14 09:31:55,959 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:55,959 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000001_0 is done. And is in the process of committing
2019-06-14 09:31:55,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:55,960 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000001_0 is allowed to commit now
2019-06-14 09:31:55,961 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000001_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:55,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5 [500.0B/500.0B]
2019-06-14 09:31:55,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000001_0' done.
2019-06-14 09:31:55,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000001_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=209261
		FILE: Number of bytes written=813526
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=48
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=700
		Bytes Copied=700
		Bytes Expected=700
		Files Copied=2
2019-06-14 09:31:55,963 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000001_0
2019-06-14 09:31:55,963 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000002_0
2019-06-14 09:31:55,966 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,966 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,967 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:55,967 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:0+317
2019-06-14 09:31:55,968 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,968 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,978 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-06-14 09:31:55,986 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:55,986 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000002_0 is done. And is in the process of committing
2019-06-14 09:31:55,987 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:55,987 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000002_0 is allowed to commit now
2019-06-14 09:31:55,988 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000002_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:55,988 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-06-14 09:31:55,988 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000002_0' done.
2019-06-14 09:31:55,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=213681
		FILE: Number of bytes written=813534
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=51
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:55,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000002_0
2019-06-14 09:31:55,989 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000003_0
2019-06-14 09:31:55,992 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,992 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:55,992 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:55,993 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:2198+271
2019-06-14 09:31:55,994 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:55,994 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,002 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:31:56,008 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,008 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000003_0 is done. And is in the process of committing
2019-06-14 09:31:56,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,009 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000003_0 is allowed to commit now
2019-06-14 09:31:56,010 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000003_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:56,010 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:31:56,010 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000003_0' done.
2019-06-14 09:31:56,011 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=218101
		FILE: Number of bytes written=813542
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=54
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:56,011 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000003_0
2019-06-14 09:31:56,011 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000004_0
2019-06-14 09:31:56,014 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,014 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:56,015 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:2469+271
2019-06-14 09:31:56,015 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,016 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,024 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:31:56,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000004_0 is done. And is in the process of committing
2019-06-14 09:31:56,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,029 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000004_0 is allowed to commit now
2019-06-14 09:31:56,030 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000004_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:56,030 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:31:56,031 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000004_0' done.
2019-06-14 09:31:56,031 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=222009
		FILE: Number of bytes written=813550
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=57
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:56,031 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000004_0
2019-06-14 09:31:56,031 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000005_0
2019-06-14 09:31:56,034 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,034 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,034 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:56,035 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:317+255
2019-06-14 09:31:56,035 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,035 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,044 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-06-14 09:31:56,050 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,050 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000005_0 is done. And is in the process of committing
2019-06-14 09:31:56,051 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,051 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000005_0 is allowed to commit now
2019-06-14 09:31:56,052 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000005_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:56,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-06-14 09:31:56,052 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000005_0' done.
2019-06-14 09:31:56,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=225917
		FILE: Number of bytes written=813558
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=60
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:56,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000005_0
2019-06-14 09:31:56,053 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000006_0
2019-06-14 09:31:56,056 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,056 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,057 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:56,057 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:572+255
2019-06-14 09:31:56,058 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,058 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,068 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-06-14 09:31:56,073 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,074 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000006_0 is done. And is in the process of committing
2019-06-14 09:31:56,075 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,075 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000006_0 is allowed to commit now
2019-06-14 09:31:56,075 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000006_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:56,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-06-14 09:31:56,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000006_0' done.
2019-06-14 09:31:56,076 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=229825
		FILE: Number of bytes written=813566
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=63
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:56,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000006_0
2019-06-14 09:31:56,077 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000007_0
2019-06-14 09:31:56,080 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,080 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,080 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:56,081 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:1377+255
2019-06-14 09:31:56,081 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,081 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,090 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-06-14 09:31:56,096 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,096 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000007_0 is done. And is in the process of committing
2019-06-14 09:31:56,097 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,097 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000007_0 is allowed to commit now
2019-06-14 09:31:56,098 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000007_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:56,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-06-14 09:31:56,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000007_0' done.
2019-06-14 09:31:56,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=233221
		FILE: Number of bytes written=813574
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1400
		O3FS: Number of read operations=66
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=13
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:56,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000007_0
2019-06-14 09:31:56,099 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1751710343_0001_m_000008_0
2019-06-14 09:31:56,102 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,103 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,103 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:56,104 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/fileList.seq:2740+251
2019-06-14 09:31:56,104 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:56,104 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:56,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
09:31:56.117 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:56,117 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000008_0
2019-06-14 09:31:56,174 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1751710343_0001 running in uber mode : false
2019-06-14 09:31:56,179 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
09:31:56.198 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:56.207 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:56.216 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000008_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000008_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:56,216 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/.distcp.tmp.attempt_local1751710343_0001_m_000008_0
2019-06-14 09:31:56,217 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,217 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1751710343_0001_m_000008_0 is done. And is in the process of committing
2019-06-14 09:31:56,218 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:56,218 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1751710343_0001_m_000008_0 is allowed to commit now
2019-06-14 09:31:56,219 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1751710343_0001_m_000008_0' to file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943/_logs
2019-06-14 09:31:56,219 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1 [100.0B/100.0B]
2019-06-14 09:31:56,219 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1751710343_0001_m_000008_0' done.
2019-06-14 09:31:56,219 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1751710343_0001_m_000008_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=236733
		FILE: Number of bytes written=813582
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=75
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=16
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=100
		Bytes Copied=100
		Bytes Expected=100
		Files Copied=1
2019-06-14 09:31:56,220 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1751710343_0001_m_000008_0
2019-06-14 09:31:56,220 [Thread-330] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:31:56,244 [Thread-330] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root1132782726/.staging/_distcp614154943
2019-06-14 09:31:57,182 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1751710343_0001 completed successfully
2019-06-14 09:31:57,236 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 25
	File System Counters
		FILE: Number of bytes read=1992857
		FILE: Number of bytes written=7321950
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=12000
		O3FS: Number of read operations=503
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=114
	Map-Reduce Framework
		Map input records=11
		Map output records=0
		Input split bytes=1350
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=36
		Total committed heap usage (bytes)=4539285504
	File Input Format Counters 
		Bytes Read=27387
	File Output Format Counters 
		Bytes Written=72
	DistCp Counters
		Bandwidth in Btyes=1500
		Bytes Copied=1500
		Bytes Expected=1500
		Files Copied=5
		DIR_COPY=6
2019-06-14 09:31:57,241 [Thread-256] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Destination tree after distcp: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir:
2019-06-14 09:31:57,250 [Thread-256] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:31:57,392 [Thread-256] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - 
Executing Update

2019-06-14 09:31:57,393 [Thread-256] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - 
Distcp -update from file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir
2019-06-14 09:31:57,393 [Thread-256] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Local to update: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local:
2019-06-14 09:31:57,418 [Thread-256] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2; type=file; length=200  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3; type=file; length=300  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4; type=file; length=400  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5; type=file; length=500  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1; type=file; length=100
2019-06-14 09:31:57,420 [Thread-256] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Remote before update: o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir:
2019-06-14 09:31:57,430 [Thread-256] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:31:57,445 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:57,451 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:57,499 [Thread-256] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-06-14 09:31:57,499 [Thread-256] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:31:57,505 [Thread-256] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:57,511 [Thread-256] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:57,512 [Thread-256] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:57,518 [Thread-256] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:31:57,547 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-06-14 09:31:57,556 [Thread-256] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:31:57,567 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local279118228_0002
2019-06-14 09:31:57,567 [Thread-256] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:31:57,644 [Thread-256] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:31:57,646 [Thread-503] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:31:57,647 [Thread-256] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local279118228_0002
2019-06-14 09:31:57,647 [Thread-503] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,647 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local279118228_0002
2019-06-14 09:31:57,647 [Thread-503] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,647 [Thread-503] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:31:57,658 [Thread-503] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:31:57,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000000_0
2019-06-14 09:31:57,658 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,659 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,660 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:1381+550
2019-06-14 09:31:57,662 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,662 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-06-14 09:31:57,678 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-06-14 09:31:57,679 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:31:57,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:31:57,683 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,683 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000000_0 is done. And is in the process of committing
2019-06-14 09:31:57,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000000_0 is allowed to commit now
2019-06-14 09:31:57,684 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000000_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1/file2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:31:57,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000000_0' done.
2019-06-14 09:31:57,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=440287
		FILE: Number of bytes written=1623027
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=107
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=324
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Skipped=500
		Files Skipped=2
2019-06-14 09:31:57,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000000_0
2019-06-14 09:31:57,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000001_0
2019-06-14 09:31:57,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:0+333
2019-06-14 09:31:57,687 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,687 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,697 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-06-14 09:31:57,701 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000001_0 is done. And is in the process of committing
2019-06-14 09:31:57,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,702 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000001_0 is allowed to commit now
2019-06-14 09:31:57,703 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000001_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,706 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2
2019-06-14 09:31:57,706 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000001_0' done.
2019-06-14 09:31:57,706 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=444877
		FILE: Number of bytes written=1623035
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=110
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:57,706 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000001_0
2019-06-14 09:31:57,706 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000002_0
2019-06-14 09:31:57,707 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,707 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,707 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,708 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:2170+283
2019-06-14 09:31:57,708 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,708 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,716 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-06-14 09:31:57,719 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-06-14 09:31:57,719 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,719 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000002_0 is done. And is in the process of committing
2019-06-14 09:31:57,720 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,720 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000002_0 is allowed to commit now
2019-06-14 09:31:57,721 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000002_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,721 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-06-14 09:31:57,721 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000002_0' done.
2019-06-14 09:31:57,722 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000002_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=449467
		FILE: Number of bytes written=1623207
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=112
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=172
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Skipped=500
		Files Skipped=1
2019-06-14 09:31:57,722 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000002_0
2019-06-14 09:31:57,722 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000003_0
2019-06-14 09:31:57,722 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,722 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,722 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,723 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:2708+283
2019-06-14 09:31:57,723 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,723 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-06-14 09:31:57,734 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-06-14 09:31:57,734 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,734 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000003_0 is done. And is in the process of committing
2019-06-14 09:31:57,735 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,735 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000003_0 is allowed to commit now
2019-06-14 09:31:57,735 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000003_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-06-14 09:31:57,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000003_0' done.
2019-06-14 09:31:57,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000003_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=454057
		FILE: Number of bytes written=1623379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=114
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=172
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Skipped=400
		Files Skipped=1
2019-06-14 09:31:57,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000003_0
2019-06-14 09:31:57,736 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000004_0
2019-06-14 09:31:57,737 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,737 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,737 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,738 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:333+271
2019-06-14 09:31:57,738 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,739 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,747 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:31:57,751 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,751 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000004_0 is done. And is in the process of committing
2019-06-14 09:31:57,752 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,752 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000004_0 is allowed to commit now
2019-06-14 09:31:57,753 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000004_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir2/subDir2 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:31:57,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000004_0' done.
2019-06-14 09:31:57,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=458135
		FILE: Number of bytes written=1623387
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=117
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:57,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000004_0
2019-06-14 09:31:57,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000005_0
2019-06-14 09:31:57,754 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,754 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,754 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,755 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:604+271
2019-06-14 09:31:57,755 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,755 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,762 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:31:57,766 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,766 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000005_0 is done. And is in the process of committing
2019-06-14 09:31:57,767 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,767 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000005_0 is allowed to commit now
2019-06-14 09:31:57,767 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000005_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:31:57,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000005_0' done.
2019-06-14 09:31:57,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=462213
		FILE: Number of bytes written=1623395
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=120
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:57,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000005_0
2019-06-14 09:31:57,768 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000006_0
2019-06-14 09:31:57,769 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,769 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,769 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,770 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:1126+255
2019-06-14 09:31:57,770 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,771 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,778 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-06-14 09:31:57,782 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,782 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000006_0 is done. And is in the process of committing
2019-06-14 09:31:57,783 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,783 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000006_0 is allowed to commit now
2019-06-14 09:31:57,784 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000006_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir1
2019-06-14 09:31:57,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000006_0' done.
2019-06-14 09:31:57,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=466291
		FILE: Number of bytes written=1623403
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=123
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:57,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000006_0
2019-06-14 09:31:57,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000007_0
2019-06-14 09:31:57,785 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,785 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,785 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,786 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:2453+255
2019-06-14 09:31:57,786 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,786 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,794 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-06-14 09:31:57,798 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,798 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000007_0 is done. And is in the process of committing
2019-06-14 09:31:57,799 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,799 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000007_0 is allowed to commit now
2019-06-14 09:31:57,799 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000007_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,799 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/subDir4 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/subDir4
2019-06-14 09:31:57,800 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000007_0' done.
2019-06-14 09:31:57,800 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=469857
		FILE: Number of bytes written=1623411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=126
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:57,800 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000007_0
2019-06-14 09:31:57,800 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000008_0
2019-06-14 09:31:57,800 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,800 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,801 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,801 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:875+251
2019-06-14 09:31:57,802 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,802 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,809 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
2019-06-14 09:31:57,812 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
2019-06-14 09:31:57,812 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,813 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000008_0 is done. And is in the process of committing
2019-06-14 09:31:57,813 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,813 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000008_0 is allowed to commit now
2019-06-14 09:31:57,814 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000008_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,814 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir/file1 to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir/file1
2019-06-14 09:31:57,814 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000008_0' done.
2019-06-14 09:31:57,814 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000008_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=473423
		FILE: Number of bytes written=1623567
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=128
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=156
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Skipped=100
		Files Skipped=1
2019-06-14 09:31:57,814 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000008_0
2019-06-14 09:31:57,814 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local279118228_0002_m_000009_0
2019-06-14 09:31:57,815 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,815 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,815 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:57,815 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/fileList.seq:1931+239
2019-06-14 09:31:57,815 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:57,815 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:57,823 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-06-14 09:31:57,827 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,827 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local279118228_0002_m_000009_0 is done. And is in the process of committing
2019-06-14 09:31:57,827 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:57,827 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local279118228_0002_m_000009_0 is allowed to commit now
2019-06-14 09:31:57,828 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local279118228_0002_m_000009_0' to file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101/_logs
2019-06-14 09:31:57,828 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/local/inputDir to o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir/inputDir
2019-06-14 09:31:57,828 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local279118228_0002_m_000009_0' done.
2019-06-14 09:31:57,829 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local279118228_0002_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=476989
		FILE: Number of bytes written=1623575
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=1500
		O3FS: Number of read operations=131
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=19
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=152
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:57,829 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local279118228_0002_m_000009_0
2019-06-14 09:31:57,829 [Thread-503] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:31:57,841 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(393)) - -delete option is enabled. About to remove entries from target that are missing in source
2019-06-14 09:31:57,848 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(402)) - Source listing completed in 0:00:00.005
2019-06-14 09:31:57,849 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:listTargetFiles(560)) - Scanning destination directory o3fs://bucket35831.volume50200/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureNoChange/remote/outputDir with thread count: 40
09:31:57.851 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume50200, bucket=bucket35831, key=NONE, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume50200 bucket: bucket35831 key: NONE
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:57,871 [Thread-503] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-06-14 09:31:57,872 [Thread-503] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:31:57,881 [Thread-503] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:57,894 [Thread-503] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:57,902 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(421)) - Destination listing completed in 0:00:00.055
2019-06-14 09:31:57,904 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(499)) - Completed deletion of files from OzoneFileSystem{URI=o3fs://bucket35831.volume50200, workingDir=o3fs://bucket35831.volume50200/user/root, userName=root, statistics=0 bytes read, 1500 bytes written, 146 read ops, 0 large read ops, 19 write ops}
2019-06-14 09:31:57,904 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(506)) - Deleted from target: files: 0 directories: 0; skipped deletions 0; deletions already missing 0; failed deletes 0
2019-06-14 09:31:57,904 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(511)) - Number of tracked deleted directories 0
2019-06-14 09:31:57,904 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(512)) - Duration of deletions: 0:00:00.002
2019-06-14 09:31:57,905 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(514)) - Total duration of deletion operation: 0:00:00.062
2019-06-14 09:31:57,905 [Thread-503] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root1736980596/.staging/_distcp-2054986101
2019-06-14 09:31:58,647 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local279118228_0002 running in uber mode : false
2019-06-14 09:31:58,648 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:31:58,648 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local279118228_0002 completed successfully
2019-06-14 09:31:58,693 [Thread-256] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 24
	File System Counters
		FILE: Number of bytes read=4595596
		FILE: Number of bytes written=16233386
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=15000
		O3FS: Number of read operations=1188
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=190
	Map-Reduce Framework
		Map input records=11
		Map output records=5
		Input split bytes=1520
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=5043650560
	File Input Format Counters 
		Bytes Read=30430
	File Output Format Counters 
		Bytes Written=872
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Skipped=1500
		DIR_COPY=6
		Files Skipped=5
2019-06-14 09:31:58,738 [Thread-570] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:31:58,783 [Thread-570] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket88463.volume13471 implemented by OzoneFileSystem{URI=o3fs://bucket88463.volume13471, workingDir=o3fs://bucket88463.volume13471/user/root, userName=root, statistics=0 bytes read, 1500 bytes written, 149 read ops, 0 large read ops, 20 write ops}
09:31:58.784 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:58.803 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:58.815 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:58,818 [Thread-570] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from local to remote
2019-06-14 09:31:58,897 [Thread-570] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:58,914 [Thread-570] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
09:31:58.924 [IPC Server handler 7 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,000 [Thread-570] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-06-14 09:31:59,000 [Thread-570] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:31:59,009 [Thread-570] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:59,020 [Thread-570] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:31:59,020 [Thread-570] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:31:59,034 [Thread-570] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:31:59,085 [Thread-570] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:10
2019-06-14 09:31:59,125 [Thread-570] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1394990216_0003
2019-06-14 09:31:59,125 [Thread-570] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:31:59,249 [Thread-570] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:31:59,250 [Thread-570] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1394990216_0003
2019-06-14 09:31:59,250 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1394990216_0003
2019-06-14 09:31:59,261 [Thread-632] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:31:59,266 [Thread-632] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,266 [Thread-632] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,266 [Thread-632] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:31:59,301 [Thread-632] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:31:59,302 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000000_0
2019-06-14 09:31:59,303 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,303 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,304 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,304 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:1122+532
2019-06-14 09:31:59,305 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,305 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
09:31:59.327 [IPC Server handler 3 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,328 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
09:31:59.334 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0
09:31:59.439 [IPC Server handler 1 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.440 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.441 [IPC Server handler 19 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.447 [IPC Server handler 0 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.452 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,452 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0
2019-06-14 09:31:59,453 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
09:31:59.456 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,457 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0
09:31:59.489 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.492 [IPC Server handler 18 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.498 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,498 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000000_0
2019-06-14 09:31:59,498 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,499 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000000_0 is done. And is in the process of committing
2019-06-14 09:31:59,499 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,499 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000000_0 is allowed to commit now
2019-06-14 09:31:59,500 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000000_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1 [100.0B/100.0B]
2019-06-14 09:31:59,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000000_0' done.
2019-06-14 09:31:59,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=704284
		FILE: Number of bytes written=2451379
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=2100
		O3FS: Number of read operations=176
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=27
	Map-Reduce Framework
		Map input records=2
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=26
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=600
		Bytes Copied=600
		Bytes Expected=600
		Files Copied=2
2019-06-14 09:31:59,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000000_0
2019-06-14 09:31:59,500 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000001_0
2019-06-14 09:31:59,501 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,501 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,501 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:0+316
2019-06-14 09:31:59,502 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,502 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,510 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-06-14 09:31:59,514 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,515 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000001_0 is done. And is in the process of committing
2019-06-14 09:31:59,515 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,515 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000001_0 is allowed to commit now
2019-06-14 09:31:59,516 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000001_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,518 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-06-14 09:31:59,518 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000001_0' done.
2019-06-14 09:31:59,518 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=708843
		FILE: Number of bytes written=2451387
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=2100
		O3FS: Number of read operations=179
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=27
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:59,518 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000001_0
2019-06-14 09:31:59,518 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000002_0
2019-06-14 09:31:59,518 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,519 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,519 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,519 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:316+282
2019-06-14 09:31:59,519 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,519 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,527 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
09:31:59.531 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,531 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000002_0
09:31:59.565 [IPC Server handler 10 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.568 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.573 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000002_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000002_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,573 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000002_0
2019-06-14 09:31:59,574 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,574 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000002_0 is done. And is in the process of committing
2019-06-14 09:31:59,574 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,575 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000002_0 is allowed to commit now
2019-06-14 09:31:59,575 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000002_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,575 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4 [400.0B/400.0B]
2019-06-14 09:31:59,575 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000002_0' done.
2019-06-14 09:31:59,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000002_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=713818
		FILE: Number of bytes written=2451395
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=2500
		O3FS: Number of read operations=188
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=30
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=400
		Bytes Copied=400
		Bytes Expected=400
		Files Copied=1
2019-06-14 09:31:59,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000002_0
2019-06-14 09:31:59,576 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000003_0
2019-06-14 09:31:59,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,576 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,577 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:2698+282
2019-06-14 09:31:59,577 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,578 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,586 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
09:31:59.589 [IPC Server handler 14 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,590 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000003_0
09:31:59.626 [IPC Server handler 12 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.627 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.628 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.632 [IPC Server handler 10 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.636 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000003_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000003_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,637 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000003_0
2019-06-14 09:31:59,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,637 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000003_0 is done. And is in the process of committing
2019-06-14 09:31:59,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,638 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000003_0 is allowed to commit now
2019-06-14 09:31:59,639 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000003_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3 [300.0B/300.0B]
2019-06-14 09:31:59,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000003_0' done.
2019-06-14 09:31:59,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000003_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=718693
		FILE: Number of bytes written=2451403
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=2800
		O3FS: Number of read operations=199
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=300
		Bytes Copied=300
		Bytes Expected=300
		Files Copied=1
2019-06-14 09:31:59,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000003_0
2019-06-14 09:31:59,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000004_0
2019-06-14 09:31:59,640 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,640 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,640 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:598+270
2019-06-14 09:31:59,641 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,641 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,650 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:31:59,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000004_0 is done. And is in the process of committing
2019-06-14 09:31:59,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,656 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000004_0 is allowed to commit now
2019-06-14 09:31:59,657 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000004_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,657 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000004_0' done.
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=722740
		FILE: Number of bytes written=2451411
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=2800
		O3FS: Number of read operations=202
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000004_0
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000005_0
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:1654+270
2019-06-14 09:31:59,659 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,659 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,669 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:31:59,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000005_0 is done. And is in the process of committing
2019-06-14 09:31:59,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000005_0 is allowed to commit now
2019-06-14 09:31:59,674 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000005_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:31:59,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000005_0' done.
2019-06-14 09:31:59,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=726787
		FILE: Number of bytes written=2451419
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=2800
		O3FS: Number of read operations=205
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=33
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:59,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000005_0
2019-06-14 09:31:59,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000006_0
2019-06-14 09:31:59,675 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,675 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,675 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,676 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:1924+266
2019-06-14 09:31:59,676 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,676 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,684 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
09:31:59.686 [IPC Server handler 0 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000006_0
09:31:59.713 [IPC Server handler 8 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.714 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.715 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.719 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:31:59.727 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000006_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000006_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:31:59,728 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1394990216_0003_m_000006_0
2019-06-14 09:31:59,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000006_0 is done. And is in the process of committing
2019-06-14 09:31:59,728 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,729 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000006_0 is allowed to commit now
2019-06-14 09:31:59,729 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000006_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2 [200.0B/200.0B]
2019-06-14 09:31:59,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000006_0' done.
2019-06-14 09:31:59,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000006_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=731050
		FILE: Number of bytes written=2451427
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=216
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=36
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=200
		Bytes Copied=200
		Bytes Expected=200
		Files Copied=1
2019-06-14 09:31:59,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000006_0
2019-06-14 09:31:59,730 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000007_0
2019-06-14 09:31:59,731 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,731 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,731 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,732 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:868+254
2019-06-14 09:31:59,732 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,732 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,741 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:31:59,746 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,746 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000007_0 is done. And is in the process of committing
2019-06-14 09:31:59,746 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,747 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000007_0 is allowed to commit now
2019-06-14 09:31:59,747 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000007_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,748 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:31:59,748 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000007_0' done.
2019-06-14 09:31:59,748 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000007_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=734585
		FILE: Number of bytes written=2451435
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=219
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=36
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:59,748 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000007_0
2019-06-14 09:31:59,748 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000008_0
2019-06-14 09:31:59,749 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,749 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,749 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,749 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:2190+254
2019-06-14 09:31:59,749 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,749 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,757 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:31:59,761 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,761 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000008_0 is done. And is in the process of committing
2019-06-14 09:31:59,762 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,762 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000008_0 is allowed to commit now
2019-06-14 09:31:59,762 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000008_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:31:59,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000008_0' done.
2019-06-14 09:31:59,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000008_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=738120
		FILE: Number of bytes written=2451443
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=222
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=36
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:59,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000008_0
2019-06-14 09:31:59,763 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1394990216_0003_m_000009_0
2019-06-14 09:31:59,766 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,766 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,766 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:31:59,766 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/fileList.seq:2444+254
2019-06-14 09:31:59,767 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:31:59,767 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:31:59,774 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:31:59,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1394990216_0003_m_000009_0 is done. And is in the process of committing
2019-06-14 09:31:59,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:31:59,779 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1394990216_0003_m_000009_0 is allowed to commit now
2019-06-14 09:31:59,780 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1394990216_0003_m_000009_0' to file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769/_logs
2019-06-14 09:31:59,780 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:31:59,780 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1394990216_0003_m_000009_0' done.
2019-06-14 09:31:59,780 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1394990216_0003_m_000009_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=741655
		FILE: Number of bytes written=2451451
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=225
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=36
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3032
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:31:59,780 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1394990216_0003_m_000009_0
2019-06-14 09:31:59,780 [Thread-632] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:31:59,794 [Thread-632] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root806487446/.staging/_distcp1772323769
2019-06-14 09:32:00,265 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1394990216_0003 running in uber mode : false
2019-06-14 09:32:00,266 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:00,266 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1394990216_0003 completed successfully
2019-06-14 09:32:00,268 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 25
	File System Counters
		FILE: Number of bytes read=7240575
		FILE: Number of bytes written=24514150
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=27100
		O3FS: Number of read operations=2031
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=327
	Map-Reduce Framework
		Map input records=11
		Map output records=0
		Input split bytes=1500
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=26
		Total committed heap usage (bytes)=5043650560
	File Input Format Counters 
		Bytes Read=30320
	File Output Format Counters 
		Bytes Written=80
	DistCp Counters
		Bandwidth in Btyes=1500
		Bytes Copied=1500
		Bytes Expected=1500
		Files Copied=5
		DIR_COPY=6
2019-06-14 09:32:00,271 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Destination tree after distcp: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir:
2019-06-14 09:32:00,277 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:32:00,324 [Thread-570] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Now do an incremental update and save of missing files
2019-06-14 09:32:00,324 [Thread-570] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - 
Directories

2019-06-14 09:32:00,325 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Local to update: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir:
2019-06-14 09:32:00,346 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2; type=file; length=200  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3; type=file; length=300  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4; type=file; length=400  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5; type=file; length=500  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/file1; type=file; length=100
2019-06-14 09:32:00,347 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Remote before update: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir:
2019-06-14 09:32:00,353 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:32:00,373 [Thread-570] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:00,378 [Thread-570] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:00,419 [Thread-570] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 6; dirCnt = 4
2019-06-14 09:32:00,419 [Thread-570] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:00,424 [Thread-570] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 6
2019-06-14 09:32:00,429 [Thread-570] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 6
2019-06-14 09:32:00,430 [Thread-570] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:00,436 [Thread-570] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:32:00,463 [Thread-570] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:5
2019-06-14 09:32:00,472 [Thread-570] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:32:00,507 [Thread-570] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1030503133_0004
2019-06-14 09:32:00,507 [Thread-570] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:32:00,581 [Thread-570] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:32:00,583 [Thread-802] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:32:00,583 [Thread-570] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1030503133_0004
2019-06-14 09:32:00,584 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1030503133_0004
2019-06-14 09:32:00,584 [Thread-802] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,584 [Thread-802] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,584 [Thread-802] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:32:00,593 [Thread-802] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:32:00,593 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1030503133_0004_m_000000_0
2019-06-14 09:32:00,593 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,594 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,594 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:00,594 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/fileList.seq:1074+536
2019-06-14 09:32:00,594 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,595 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,604 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:00,607 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:00,608 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/newfile1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
09:32:00.610 [IPC Server handler 0 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:00,611 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1030503133_0004_m_000000_0
09:32:00.616 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:00.618 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:00.621 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1030503133_0004_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1030503133_0004_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:00,625 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1030503133_0004_m_000000_0
2019-06-14 09:32:00,628 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,628 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1030503133_0004_m_000000_0 is done. And is in the process of committing
2019-06-14 09:32:00,629 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,629 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1030503133_0004_m_000000_0 is allowed to commit now
2019-06-14 09:32:00,629 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1030503133_0004_m_000000_0' to file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/_logs
2019-06-14 09:32:00,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/newfile1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
2019-06-14 09:32:00,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1030503133_0004_m_000000_0' done.
2019-06-14 09:32:00,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1030503133_0004_m_000000_0: Counters: 26
	File System Counters
		FILE: Number of bytes read=936273
		FILE: Number of bytes written=3259637
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=265
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=42
	Map-Reduce Framework
		Map input records=2
		Map output records=1
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1654
	File Output Format Counters 
		Bytes Written=163
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Copied=0
		Bytes Expected=0
		Bytes Skipped=200
		Files Copied=1
		Files Skipped=1
2019-06-14 09:32:00,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1030503133_0004_m_000000_0
2019-06-14 09:32:00,630 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1030503133_0004_m_000001_0
2019-06-14 09:32:00,631 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,631 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,631 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:00,632 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/fileList.seq:0+323
2019-06-14 09:32:00,632 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,632 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,639 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:00,643 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,644 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1030503133_0004_m_000001_0 is done. And is in the process of committing
2019-06-14 09:32:00,644 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,644 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1030503133_0004_m_000001_0 is allowed to commit now
2019-06-14 09:32:00,645 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1030503133_0004_m_000001_0' to file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/_logs
2019-06-14 09:32:00,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:00,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1030503133_0004_m_000001_0' done.
2019-06-14 09:32:00,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1030503133_0004_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=938705
		FILE: Number of bytes written=3259645
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=268
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=42
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1654
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:00,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1030503133_0004_m_000001_0
2019-06-14 09:32:00,645 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1030503133_0004_m_000002_0
2019-06-14 09:32:00,646 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,646 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,646 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:00,647 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/fileList.seq:568+261
2019-06-14 09:32:00,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,647 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,654 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:00,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1030503133_0004_m_000002_0 is done. And is in the process of committing
2019-06-14 09:32:00,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,658 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1030503133_0004_m_000002_0 is allowed to commit now
2019-06-14 09:32:00,659 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1030503133_0004_m_000002_0' to file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/_logs
2019-06-14 09:32:00,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:00,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1030503133_0004_m_000002_0' done.
2019-06-14 09:32:00,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1030503133_0004_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=941137
		FILE: Number of bytes written=3259653
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=271
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=42
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1654
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:00,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1030503133_0004_m_000002_0
2019-06-14 09:32:00,659 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1030503133_0004_m_000003_0
2019-06-14 09:32:00,660 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,660 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,660 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:00,660 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/fileList.seq:323+245
2019-06-14 09:32:00,660 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,661 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,668 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:00,671 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,671 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1030503133_0004_m_000003_0 is done. And is in the process of committing
2019-06-14 09:32:00,671 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1030503133_0004_m_000003_0 is allowed to commit now
2019-06-14 09:32:00,672 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1030503133_0004_m_000003_0' to file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/_logs
2019-06-14 09:32:00,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:00,672 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1030503133_0004_m_000003_0' done.
2019-06-14 09:32:00,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1030503133_0004_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=943569
		FILE: Number of bytes written=3259661
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=274
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=42
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1654
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:00,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1030503133_0004_m_000003_0
2019-06-14 09:32:00,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1030503133_0004_m_000004_0
2019-06-14 09:32:00,673 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,673 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,673 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:00,674 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/fileList.seq:829+245
2019-06-14 09:32:00,674 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:00,674 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:00,682 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:00,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,685 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1030503133_0004_m_000004_0 is done. And is in the process of committing
2019-06-14 09:32:00,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:00,686 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1030503133_0004_m_000004_0 is allowed to commit now
2019-06-14 09:32:00,686 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1030503133_0004_m_000004_0' to file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335/_logs
2019-06-14 09:32:00,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:00,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1030503133_0004_m_000004_0' done.
2019-06-14 09:32:00,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1030503133_0004_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=945489
		FILE: Number of bytes written=3259669
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=3000
		O3FS: Number of read operations=277
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=42
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1654
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:00,687 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1030503133_0004_m_000004_0
2019-06-14 09:32:00,687 [Thread-802] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:32:00,699 [Thread-802] INFO  mapred.CopyCommitter (CopyCommitter.java:trackMissing(366)) - Tracking file changes to directory file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/trackDir
2019-06-14 09:32:00,699 [Thread-802] INFO  mapred.CopyCommitter (CopyCommitter.java:trackMissing(371)) - Source listing file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/trackDir/source_sorted.seq
2019-06-14 09:32:00,706 [Thread-802] INFO  mapred.CopyCommitter (CopyCommitter.java:listTargetFiles(560)) - Scanning destination directory o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir with thread count: 40
09:32:00.708 [IPC Server handler 7 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13471, bucket=bucket88463, key=NONE, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13471 bucket: bucket88463 key: NONE
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:00,762 [Thread-802] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 5
2019-06-14 09:32:00,762 [Thread-802] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:00,768 [Thread-802] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:00,773 [Thread-802] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:00,777 [Thread-802] INFO  mapred.CopyCommitter (CopyCommitter.java:trackMissing(381)) - Target listing file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/trackDir/target_sorted.seq
2019-06-14 09:32:00,778 [Thread-802] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root1643359385/.staging/_distcp-949797335
2019-06-14 09:32:01,584 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1030503133_0004 running in uber mode : false
2019-06-14 09:32:01,584 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:01,585 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1030503133_0004 completed successfully
2019-06-14 09:32:01,585 [Thread-570] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 27
	File System Counters
		FILE: Number of bytes read=4705173
		FILE: Number of bytes written=16298265
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=15000
		O3FS: Number of read operations=1355
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=210
	Map-Reduce Framework
		Map input records=6
		Map output records=1
		Input split bytes=755
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=2521825280
	File Input Format Counters 
		Bytes Read=8270
	File Output Format Counters 
		Bytes Written=195
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Copied=0
		Bytes Expected=0
		Bytes Skipped=200
		Files Copied=1
		DIR_COPY=4
		Files Skipped=1
2019-06-14 09:32:01,587 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - tracked udpate: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir:
2019-06-14 09:32:01,593 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1; type=file; length=0  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:32:01,599 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(410)) - /subDir1: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1
2019-06-14 09:32:01,599 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(410)) - /subDir1/file2: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2
2019-06-14 09:32:01,599 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(410)) - /subDir2: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2
2019-06-14 09:32:01,599 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(410)) - /subDir2/subDir2: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2
2019-06-14 09:32:01,599 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(410)) - /subDir2/subDir2/newfile1: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/newfile1
2019-06-14 09:32:01,599 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(410)) - /subDir4: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/local/inputDir/subDir4
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /file1: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir1: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir1/file2: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir2: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir2/subDir2: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir2/subDir2/file3: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir2/subDir2/newfile1: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
2019-06-14 09:32:01,600 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir4: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:01,601 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir4/subDir4: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:32:01,601 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir4/subDir4/file4: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
2019-06-14 09:32:01,601 [Thread-570] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:testTrackDeepDirectoryStructureToRemote(416)) - /subDir4/subDir4/file5: o3fs://bucket88463.volume13471/test/ITestOzoneContractDistCp/testTrackDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
2019-06-14 09:32:01,627 [Thread-848] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:32:01,660 [Thread-848] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket92439.volume25956 implemented by OzoneFileSystem{URI=o3fs://bucket92439.volume25956, workingDir=o3fs://bucket92439.volume25956/user/root, userName=root, statistics=0 bytes read, 3000 bytes written, 306 read ops, 0 large read ops, 43 write ops}
09:32:01.661 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:01.669 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:01.675 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:01,677 [Thread-848] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from local to remote
2019-06-14 09:32:01,682 [Thread-848] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - largeFilesToRemote with file size 1
2019-06-14 09:32:01,768 [Thread-848] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:01,774 [Thread-848] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
09:32:01.781 [IPC Server handler 8 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:01,810 [Thread-848] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-06-14 09:32:01,810 [Thread-848] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:01,816 [Thread-848] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-06-14 09:32:01,821 [Thread-848] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-06-14 09:32:01,821 [Thread-848] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:01,826 [Thread-848] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:32:01,854 [Thread-848] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:2
2019-06-14 09:32:01,871 [Thread-848] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local462276845_0005
2019-06-14 09:32:01,871 [Thread-848] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:32:01,949 [Thread-848] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:32:01,952 [Thread-896] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:32:01,952 [Thread-848] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local462276845_0005
2019-06-14 09:32:01,952 [Thread-896] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:01,952 [Thread-848] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local462276845_0005
2019-06-14 09:32:01,952 [Thread-896] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:01,952 [Thread-896] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:32:01,961 [Thread-896] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:32:01,961 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local462276845_0005_m_000000_0
2019-06-14 09:32:01,961 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:01,962 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:01,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:01,962 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1030191817/.staging/_distcp-251786582/fileList.seq:0+750
2019-06-14 09:32:01,962 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:01,963 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
09:32:01.973 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:01,973 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir to o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
09:32:01.976 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:01.977 [IPC Server handler 10 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:01,980 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file2 to o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
09:32:01.984 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:01,985 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0
09:32:02.133 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:02.137 [IPC Server handler 14 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:02.141 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:02,141 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0
2019-06-14 09:32:02,142 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
09:32:02.145 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:02,145 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0
09:32:02.286 [IPC Server handler 10 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:02.288 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:02.292 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:02,292 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000000_0
2019-06-14 09:32:02,292 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:02,293 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local462276845_0005_m_000000_0 is done. And is in the process of committing
2019-06-14 09:32:02,293 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:02,293 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local462276845_0005_m_000000_0 is allowed to commit now
2019-06-14 09:32:02,294 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local462276845_0005_m_000000_0' to file:/tmp/hadoop/mapred/staging/root1030191817/.staging/_distcp-251786582/_logs
2019-06-14 09:32:02,294 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file3 to o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file3 [4.0M/4.0M]
2019-06-14 09:32:02,294 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local462276845_0005_m_000000_0' done.
2019-06-14 09:32:02,294 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local462276845_0005_m_000000_0: Counters: 25
	File System Counters
		FILE: Number of bytes read=8553420
		FILE: Number of bytes written=13585188
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=7343032
		O3FS: Number of read operations=334
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=50
	Map-Reduce Framework
		Map input records=3
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1014
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=7340032
		Bytes Copied=7340032
		Bytes Expected=7340032
		Files Copied=2
		DIR_COPY=1
2019-06-14 09:32:02,294 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local462276845_0005_m_000000_0
2019-06-14 09:32:02,294 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local462276845_0005_m_000001_0
2019-06-14 09:32:02,295 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:02,295 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:02,295 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:02,295 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1030191817/.staging/_distcp-251786582/fileList.seq:750+228
2019-06-14 09:32:02,295 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:02,296 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:02,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
09:32:02.306 [IPC Server handler 14 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:02,307 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000001_0
09:32:02.358 [IPC Server handler 12 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:02.362 [IPC Server handler 8 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:02.366 [IPC Server handler 3 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume25956, bucket=bucket92439, key=test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume25956 bucket: bucket92439 key: test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:02,367 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/.distcp.tmp.attempt_local462276845_0005_m_000001_0
2019-06-14 09:32:02,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:02,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local462276845_0005_m_000001_0 is done. And is in the process of committing
2019-06-14 09:32:02,368 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:02,368 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local462276845_0005_m_000001_0 is allowed to commit now
2019-06-14 09:32:02,368 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local462276845_0005_m_000001_0' to file:/tmp/hadoop/mapred/staging/root1030191817/.staging/_distcp-251786582/_logs
2019-06-14 09:32:02,368 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/largeFilesToRemote/local/inputDir/file1 to o3fs://bucket92439.volume25956/test/ITestOzoneContractDistCp/largeFilesToRemote/remote/outputDir/inputDir/file1 [2.0M/2.0M]
2019-06-14 09:32:02,369 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local462276845_0005_m_000001_0' done.
2019-06-14 09:32:02,369 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local462276845_0005_m_000001_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=10668299
		FILE: Number of bytes written=13585196
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=9440184
		O3FS: Number of read operations=343
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=53
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1014
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=2097152
		Bytes Copied=2097152
		Bytes Expected=2097152
		Files Copied=1
2019-06-14 09:32:02,369 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local462276845_0005_m_000001_0
2019-06-14 09:32:02,369 [Thread-896] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:32:02,380 [Thread-896] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root1030191817/.staging/_distcp-251786582
2019-06-14 09:32:02,952 [Thread-848] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local462276845_0005 running in uber mode : false
2019-06-14 09:32:02,953 [Thread-848] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:02,953 [Thread-848] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local462276845_0005 completed successfully
2019-06-14 09:32:02,954 [Thread-848] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 25
	File System Counters
		FILE: Number of bytes read=19221719
		FILE: Number of bytes written=27170384
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=16783216
		O3FS: Number of read operations=677
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=103
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=302
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=1008730112
	File Input Format Counters 
		Bytes Read=2028
	File Output Format Counters 
		Bytes Written=16
	DistCp Counters
		Bandwidth in Btyes=9437184
		Bytes Copied=9437184
		Bytes Expected=9437184
		Files Copied=3
		DIR_COPY=1
2019-06-14 09:32:03,129 [Thread-957] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:32:03,171 [Thread-957] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket74388.volume58436 implemented by OzoneFileSystem{URI=o3fs://bucket74388.volume58436, workingDir=o3fs://bucket74388.volume58436/user/root, userName=root, statistics=0 bytes read, 9440184 bytes written, 360 read ops, 0 large read ops, 57 write ops}
09:32:03.172 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume58436, bucket=bucket74388, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume58436 bucket: bucket74388 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:03.179 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume58436, bucket=bucket74388, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume58436 bucket: bucket74388 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:03.186 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume58436, bucket=bucket74388, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume58436 bucket: bucket74388 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:03,192 [Thread-957] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy multiple large files from remote to local
09:32:03.193 [IPC Server handler 19 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume58436, bucket=bucket74388, key=test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume58436 bucket: bucket74388 key: test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:03,195 [Thread-957] INFO  contract.AbstractFSContractTestBase (AbstractContractDistCpTest.java:largeFiles(526)) - testLargeFilesFromRemote with file size 1
2019-06-14 09:32:03,477 [Thread-957] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:03,483 [Thread-957] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:03,503 [Thread-957] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 4; dirCnt = 1
2019-06-14 09:32:03,503 [Thread-957] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:03,509 [Thread-957] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-06-14 09:32:03,514 [Thread-957] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 4
2019-06-14 09:32:03,515 [Thread-957] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:03,519 [Thread-957] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:32:03,546 [Thread-957] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:1
2019-06-14 09:32:03,560 [Thread-957] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local2083989373_0006
2019-06-14 09:32:03,561 [Thread-957] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:32:03,621 [Thread-957] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:32:03,623 [Thread-1030] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:32:03,623 [Thread-957] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local2083989373_0006
2019-06-14 09:32:03,624 [Thread-1030] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:03,624 [Thread-957] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local2083989373_0006
2019-06-14 09:32:03,624 [Thread-1030] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:03,625 [Thread-1030] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:32:03,632 [Thread-1030] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:32:03,632 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local2083989373_0006_m_000000_0
2019-06-14 09:32:03,633 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:03,633 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:03,633 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:03,633 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1126751338/.staging/_distcp177653835/fileList.seq:0+946
2019-06-14 09:32:03,633 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:03,634 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:03,641 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket74388.volume58436/test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/inputDir
2019-06-14 09:32:03,649 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket74388.volume58436/test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file3 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/inputDir/file3
2019-06-14 09:32:03,650 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/.distcp.tmp.attempt_local2083989373_0006_m_000000_0
2019-06-14 09:32:03,714 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket74388.volume58436/test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file2 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/inputDir/file2
2019-06-14 09:32:03,715 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/.distcp.tmp.attempt_local2083989373_0006_m_000000_0
2019-06-14 09:32:03,767 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket74388.volume58436/test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file1 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/inputDir/file1
2019-06-14 09:32:03,770 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/.distcp.tmp.attempt_local2083989373_0006_m_000000_0
2019-06-14 09:32:03,822 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:03,823 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local2083989373_0006_m_000000_0 is done. And is in the process of committing
2019-06-14 09:32:03,823 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:03,823 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local2083989373_0006_m_000000_0 is allowed to commit now
2019-06-14 09:32:03,824 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local2083989373_0006_m_000000_0' to file:/tmp/hadoop/mapred/staging/root1126751338/.staging/_distcp177653835/_logs
2019-06-14 09:32:03,829 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying o3fs://bucket74388.volume58436/test/ITestOzoneContractDistCp/testLargeFilesFromRemote/remote/inputDir/file1 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testLargeFilesFromRemote/local/outputDir/inputDir/file1 [2.0M/2.0M]
2019-06-14 09:32:03,829 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local2083989373_0006_m_000000_0' done.
2019-06-14 09:32:03,830 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local2083989373_0006_m_000000_0: Counters: 25
	File System Counters
		FILE: Number of bytes read=10858331
		FILE: Number of bytes written=23827180
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18877368
		O3FS: Number of read operations=380
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=64
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=982
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=9437184
		Bytes Copied=9437184
		Bytes Expected=9437184
		Files Copied=3
		DIR_COPY=1
2019-06-14 09:32:03,830 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local2083989373_0006_m_000000_0
2019-06-14 09:32:03,830 [Thread-1030] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:32:03,850 [Thread-1030] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root1126751338/.staging/_distcp177653835
2019-06-14 09:32:04,625 [Thread-957] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local2083989373_0006 running in uber mode : false
2019-06-14 09:32:04,625 [Thread-957] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:04,625 [Thread-957] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local2083989373_0006 completed successfully
2019-06-14 09:32:04,626 [Thread-957] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 25
	File System Counters
		FILE: Number of bytes read=10858331
		FILE: Number of bytes written=23827180
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18877368
		O3FS: Number of read operations=380
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=64
	Map-Reduce Framework
		Map input records=4
		Map output records=0
		Input split bytes=150
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=982
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=9437184
		Bytes Copied=9437184
		Bytes Expected=9437184
		Files Copied=3
		DIR_COPY=1
2019-06-14 09:32:04,686 [Thread-1053] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:32:04,718 [Thread-1053] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket63722.volume91802 implemented by OzoneFileSystem{URI=o3fs://bucket63722.volume91802, workingDir=o3fs://bucket63722.volume91802/user/root, userName=root, statistics=0 bytes read, 18877368 bytes written, 383 read ops, 0 large read ops, 65 write ops}
09:32:04.719 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:04.725 [IPC Server handler 1 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:04.730 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:04,732 [Thread-1053] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - update a deep directory structure from local to remote
2019-06-14 09:32:04,784 [Thread-1053] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:04,788 [Thread-1053] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
09:32:04.794 [IPC Server handler 8 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:04,825 [Thread-1053] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-06-14 09:32:04,825 [Thread-1053] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:04,831 [Thread-1053] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:04,836 [Thread-1053] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:04,837 [Thread-1053] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:04,841 [Thread-1053] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:32:04,868 [Thread-1053] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:7
2019-06-14 09:32:04,884 [Thread-1053] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1940800716_0007
2019-06-14 09:32:04,884 [Thread-1053] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:32:04,956 [Thread-1053] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:32:04,958 [Thread-1115] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:32:04,958 [Thread-1053] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1940800716_0007
2019-06-14 09:32:04,959 [Thread-1115] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:04,959 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1940800716_0007
2019-06-14 09:32:04,960 [Thread-1115] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:04,960 [Thread-1115] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:32:04,969 [Thread-1115] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:32:04,969 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:04,969 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:04,969 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:04,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:04,970 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:1353+1367
2019-06-14 09:32:04,970 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:04,970 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
09:32:04.987 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:04,988 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
09:32:04.991 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:04,992 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
09:32:05.047 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.048 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.049 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.052 [IPC Server handler 19 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.056 [IPC Server handler 12 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,057 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:05,057 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/file3 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
09:32:05.061 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,061 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
09:32:05.103 [IPC Server handler 6 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.104 [IPC Server handler 10 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.105 [IPC Server handler 7 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.108 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.112 [IPC Server handler 14 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,112 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:05,113 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/file1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
09:32:05.116 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,116 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
09:32:05.141 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.143 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.147 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,147 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:05,147 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4/file5 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
09:32:05.150 [IPC Server handler 2 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,151 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
09:32:05.244 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.250 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.258 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,259 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:05,259 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
09:32:05.263 [IPC Server handler 8 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,263 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
09:32:05.292 [IPC Server handler 7 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.293 [IPC Server handler 3 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.293 [IPC Server handler 5 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.297 [IPC Server handler 1 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:05.300 [IPC Server handler 15 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:05,301 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/.distcp.tmp.attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:05,301 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,301 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000000_0 is done. And is in the process of committing
2019-06-14 09:32:05,302 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,302 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000000_0 is allowed to commit now
2019-06-14 09:32:05,302 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000000_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 100.0% Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2 [200.0B/200.0B]
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000000_0' done.
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000000_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=20500166
		FILE: Number of bytes written=24640406
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=438
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=5
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=1500
		Bytes Copied=1500
		Bytes Expected=1500
		Files Copied=5
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000000_0
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000001_0
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,303 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,304 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:05,304 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:0+317
2019-06-14 09:32:05,304 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,304 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-06-14 09:32:05,317 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,317 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000001_0 is done. And is in the process of committing
2019-06-14 09:32:05,317 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,317 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000001_0 is allowed to commit now
2019-06-14 09:32:05,318 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000001_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-06-14 09:32:05,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000001_0' done.
2019-06-14 09:32:05,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000001_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20504293
		FILE: Number of bytes written=24640414
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=441
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:05,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000001_0
2019-06-14 09:32:05,318 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000002_0
2019-06-14 09:32:05,319 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,319 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,319 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:05,319 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:572+271
2019-06-14 09:32:05,319 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,320 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,328 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:05,334 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000002_0 is done. And is in the process of committing
2019-06-14 09:32:05,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000002_0 is allowed to commit now
2019-06-14 09:32:05,336 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000002_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,336 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:05,336 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000002_0' done.
2019-06-14 09:32:05,336 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20508420
		FILE: Number of bytes written=24640422
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=444
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:05,336 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000002_0
2019-06-14 09:32:05,337 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000003_0
2019-06-14 09:32:05,337 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,337 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,337 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:05,338 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:2720+271
2019-06-14 09:32:05,339 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,339 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,348 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:32:05,352 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,352 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000003_0 is done. And is in the process of committing
2019-06-14 09:32:05,352 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,352 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000003_0 is allowed to commit now
2019-06-14 09:32:05,353 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000003_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4/subDir4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:32:05,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000003_0' done.
2019-06-14 09:32:05,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20512547
		FILE: Number of bytes written=24640430
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=447
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:05,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000003_0
2019-06-14 09:32:05,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000004_0
2019-06-14 09:32:05,354 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,354 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,354 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:05,355 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:317+255
2019-06-14 09:32:05,355 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,355 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,363 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:05,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000004_0 is done. And is in the process of committing
2019-06-14 09:32:05,367 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,368 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000004_0 is allowed to commit now
2019-06-14 09:32:05,368 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000004_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,370 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:05,370 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000004_0' done.
2019-06-14 09:32:05,370 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20516162
		FILE: Number of bytes written=24640438
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=450
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:05,370 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000004_0
2019-06-14 09:32:05,370 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000005_0
2019-06-14 09:32:05,374 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,374 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,374 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:05,375 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:843+255
2019-06-14 09:32:05,375 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,375 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,388 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:05,392 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,392 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000005_0 is done. And is in the process of committing
2019-06-14 09:32:05,393 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,393 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000005_0 is allowed to commit now
2019-06-14 09:32:05,393 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000005_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000005_0' done.
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20519777
		FILE: Number of bytes written=24640446
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=453
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000005_0
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1940800716_0007_m_000006_0
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,394 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,395 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:05,395 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/fileList.seq:1098+255
2019-06-14 09:32:05,395 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:05,395 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:05,403 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:05,408 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,408 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1940800716_0007_m_000006_0 is done. And is in the process of committing
2019-06-14 09:32:05,408 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:05,408 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1940800716_0007_m_000006_0 is allowed to commit now
2019-06-14 09:32:05,409 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1940800716_0007_m_000006_0' to file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200/_logs
2019-06-14 09:32:05,409 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:05,409 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1940800716_0007_m_000006_0' done.
2019-06-14 09:32:05,409 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1940800716_0007_m_000006_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20523392
		FILE: Number of bytes written=24640454
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=456
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=81
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=3043
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:05,410 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1940800716_0007_m_000006_0
2019-06-14 09:32:05,410 [Thread-1115] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:32:05,423 [Thread-1115] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root247891801/.staging/_distcp-1522858200
2019-06-14 09:32:05,960 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1940800716_0007 running in uber mode : false
2019-06-14 09:32:05,960 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:05,960 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1940800716_0007 completed successfully
2019-06-14 09:32:05,962 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 25
	File System Counters
		FILE: Number of bytes read=143584757
		FILE: Number of bytes written=172483010
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=132152076
		O3FS: Number of read operations=3129
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=567
	Map-Reduce Framework
		Map input records=11
		Map output records=0
		Input split bytes=1057
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=3530555392
	File Input Format Counters 
		Bytes Read=21301
	File Output Format Counters 
		Bytes Written=56
	DistCp Counters
		Bandwidth in Btyes=1500
		Bytes Copied=1500
		Bytes Expected=1500
		Files Copied=5
		DIR_COPY=6
2019-06-14 09:32:05,964 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Destination tree after distcp: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir:
2019-06-14 09:32:05,969 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:32:06,016 [Thread-1053] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Now do an incremental update with deletion of missing files
2019-06-14 09:32:06,016 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:distCpUpdateDeepDirectoryStructure(279)) - Source directory = file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir, dest=o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-06-14 09:32:06,023 [Thread-1053] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - 
Distcp -update from file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir
2019-06-14 09:32:06,023 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Local to update: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir:
2019-06-14 09:32:06,036 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2; type=file; length=200  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/newfile1; type=file; length=0
2019-06-14 09:32:06,037 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Remote before update: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir:
2019-06-14 09:32:06,041 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1; type=file; length=100  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500
2019-06-14 09:32:06,056 [Thread-1053] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:06,061 [Thread-1053] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:06,115 [Thread-1053] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 6; dirCnt = 4
2019-06-14 09:32:06,116 [Thread-1053] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:06,121 [Thread-1053] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 6
2019-06-14 09:32:06,126 [Thread-1053] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 6
2019-06-14 09:32:06,127 [Thread-1053] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:06,138 [Thread-1053] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:32:06,167 [Thread-1053] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:6
2019-06-14 09:32:06,176 [Thread-1053] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:32:06,182 [Thread-1053] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1459962270_0008
2019-06-14 09:32:06,182 [Thread-1053] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:32:06,246 [Thread-1053] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:32:06,247 [Thread-1053] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1459962270_0008
2019-06-14 09:32:06,247 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1459962270_0008
2019-06-14 09:32:06,247 [Thread-1270] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:32:06,249 [Thread-1270] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,249 [Thread-1270] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,249 [Thread-1270] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:32:06,259 [Thread-1270] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:32:06,259 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1459962270_0008_m_000000_0
2019-06-14 09:32:06,259 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,260 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,260 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:06,260 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/fileList.seq:0+336
2019-06-14 09:32:06,260 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,260 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,270 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:06,272 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(198)) - Skipping copy of file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:06,273 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,273 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1459962270_0008_m_000000_0 is done. And is in the process of committing
2019-06-14 09:32:06,273 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,273 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1459962270_0008_m_000000_0 is allowed to commit now
2019-06-14 09:32:06,274 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1459962270_0008_m_000000_0' to file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/_logs
2019-06-14 09:32:06,274 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1/file2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:06,274 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1459962270_0008_m_000000_0' done.
2019-06-14 09:32:06,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1459962270_0008_m_000000_0: Counters: 23
	File System Counters
		FILE: Number of bytes read=20718195
		FILE: Number of bytes written=25448191
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=486
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=84
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1660
	File Output Format Counters 
		Bytes Written=164
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Skipped=200
		Files Skipped=1
2019-06-14 09:32:06,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1459962270_0008_m_000000_0
2019-06-14 09:32:06,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1459962270_0008_m_000001_0
2019-06-14 09:32:06,275 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,275 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,275 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:06,276 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/fileList.seq:1074+280
2019-06-14 09:32:06,276 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,276 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,283 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/newfile1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
09:32:06.285 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:06,286 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1459962270_0008_m_000001_0
09:32:06.289 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:06.291 [IPC Server handler 17 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:06.295 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1459962270_0008_m_000001_0, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1459962270_0008_m_000001_0
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:06,295 [LocalJobRunner Map Task Executor #0] WARN  ozone.BasicOzoneFileSystem (BasicOzoneFileSystem.java:delete(427)) - delete: Path does not exist: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/.distcp.tmp.attempt_local1459962270_0008_m_000001_0
2019-06-14 09:32:06,295 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,296 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1459962270_0008_m_000001_0 is done. And is in the process of committing
2019-06-14 09:32:06,296 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,296 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1459962270_0008_m_000001_0 is allowed to commit now
2019-06-14 09:32:06,297 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1459962270_0008_m_000001_0' to file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/_logs
2019-06-14 09:32:06,297 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2/newfile1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1
2019-06-14 09:32:06,297 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1459962270_0008_m_000001_0' done.
2019-06-14 09:32:06,297 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1459962270_0008_m_000001_0: Counters: 24
	File System Counters
		FILE: Number of bytes read=20720792
		FILE: Number of bytes written=25448199
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=495
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=87
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1660
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Copied=0
		Bytes Expected=0
		Files Copied=1
2019-06-14 09:32:06,297 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1459962270_0008_m_000001_0
2019-06-14 09:32:06,298 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1459962270_0008_m_000002_0
2019-06-14 09:32:06,298 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,298 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,298 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:06,298 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/fileList.seq:1354+262
2019-06-14 09:32:06,299 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,299 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,306 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:06,309 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,310 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1459962270_0008_m_000002_0 is done. And is in the process of committing
2019-06-14 09:32:06,310 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,310 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1459962270_0008_m_000002_0 is allowed to commit now
2019-06-14 09:32:06,310 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1459962270_0008_m_000002_0' to file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/_logs
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1459962270_0008_m_000002_0' done.
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1459962270_0008_m_000002_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20723381
		FILE: Number of bytes written=25448207
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=498
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=87
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1660
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1459962270_0008_m_000002_0
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1459962270_0008_m_000003_0
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,311 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:06,312 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/fileList.seq:336+246
2019-06-14 09:32:06,312 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,312 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,320 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:06,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1459962270_0008_m_000003_0 is done. And is in the process of committing
2019-06-14 09:32:06,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,324 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1459962270_0008_m_000003_0 is allowed to commit now
2019-06-14 09:32:06,325 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1459962270_0008_m_000003_0' to file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/_logs
2019-06-14 09:32:06,325 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir2 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2
2019-06-14 09:32:06,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1459962270_0008_m_000003_0' done.
2019-06-14 09:32:06,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1459962270_0008_m_000003_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20725970
		FILE: Number of bytes written=25448215
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=501
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=87
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1660
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:06,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1459962270_0008_m_000003_0
2019-06-14 09:32:06,326 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1459962270_0008_m_000004_0
2019-06-14 09:32:06,327 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,327 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,327 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:06,327 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/fileList.seq:582+246
2019-06-14 09:32:06,328 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,328 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,335 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:06,339 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,339 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1459962270_0008_m_000004_0 is done. And is in the process of committing
2019-06-14 09:32:06,339 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,340 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1459962270_0008_m_000004_0 is allowed to commit now
2019-06-14 09:32:06,340 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1459962270_0008_m_000004_0' to file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/_logs
2019-06-14 09:32:06,340 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir4 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
2019-06-14 09:32:06,340 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1459962270_0008_m_000004_0' done.
2019-06-14 09:32:06,340 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1459962270_0008_m_000004_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20728047
		FILE: Number of bytes written=25448223
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=504
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=87
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1660
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:06,341 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1459962270_0008_m_000004_0
2019-06-14 09:32:06,341 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1459962270_0008_m_000005_0
2019-06-14 09:32:06,341 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,341 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,341 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:06,342 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/fileList.seq:828+246
2019-06-14 09:32:06,342 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:06,342 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:06,349 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:06,352 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1459962270_0008_m_000005_0 is done. And is in the process of committing
2019-06-14 09:32:06,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:06,353 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1459962270_0008_m_000005_0 is allowed to commit now
2019-06-14 09:32:06,354 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1459962270_0008_m_000005_0' to file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349/_logs
2019-06-14 09:32:06,354 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/local/inputDir/subDir1 to o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1
2019-06-14 09:32:06,354 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1459962270_0008_m_000005_0' done.
2019-06-14 09:32:06,354 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1459962270_0008_m_000005_0: Counters: 22
	File System Counters
		FILE: Number of bytes read=20730124
		FILE: Number of bytes written=25448231
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18878868
		O3FS: Number of read operations=507
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=87
	Map-Reduce Framework
		Map input records=1
		Map output records=0
		Input split bytes=151
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=1660
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=0
		DIR_COPY=1
2019-06-14 09:32:06,354 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1459962270_0008_m_000005_0
2019-06-14 09:32:06,354 [Thread-1270] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:32:06,370 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(393)) - -delete option is enabled. About to remove entries from target that are missing in source
2019-06-14 09:32:06,375 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(402)) - Source listing completed in 0:00:00.005
2019-06-14 09:32:06,376 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:listTargetFiles(560)) - Scanning destination directory o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir with thread count: 40
09:32:06.378 [IPC Server handler 0 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=NONE, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: NONE
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:06,393 [Thread-1270] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 5
2019-06-14 09:32:06,393 [Thread-1270] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:06,399 [Thread-1270] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:06,404 [Thread-1270] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:06,410 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(421)) - Destination listing completed in 0:00:00.035
2019-06-14 09:32:06,414 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(458)) - Deleted o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1 - missing at source
2019-06-14 09:32:06,416 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(458)) - Deleted o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3 - missing at source
09:32:06.424 [IPC Server handler 11 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(458)) - Deleted o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4 - missing at source
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(499)) - Completed deletion of files from OzoneFileSystem{URI=o3fs://bucket63722.volume91802, workingDir=o3fs://bucket63722.volume91802/user/root, userName=root, statistics=0 bytes read, 18878868 bytes written, 527 read ops, 0 large read ops, 90 write ops}
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(506)) - Deleted from target: files: 2 directories: 1; skipped deletions 2; deletions already missing 0; failed deletes 0
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(511)) - Number of tracked deleted directories 1
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(512)) - Duration of deletions: 0:00:00.017
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:deleteMissing(514)) - Total duration of deletion operation: 0:00:00.057
2019-06-14 09:32:06,427 [Thread-1270] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root1748027695/.staging/_distcp1532681349
2019-06-14 09:32:07,249 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1459962270_0008 running in uber mode : false
2019-06-14 09:32:07,249 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:07,250 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1459962270_0008 completed successfully
2019-06-14 09:32:07,251 [Thread-1053] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 27
	File System Counters
		FILE: Number of bytes read=124346509
		FILE: Number of bytes written=152689266
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=113273208
		O3FS: Number of read operations=2991
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=519
	Map-Reduce Framework
		Map input records=6
		Map output records=1
		Input split bytes=906
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=3026190336
	File Input Format Counters 
		Bytes Read=9960
	File Output Format Counters 
		Bytes Written=204
	DistCp Counters
		Bandwidth in Btyes=0
		Bytes Copied=0
		Bytes Expected=0
		Bytes Skipped=200
		Files Copied=1
		DIR_COPY=4
		Files Skipped=1
2019-06-14 09:32:07,252 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Updated Remote: o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir:
2019-06-14 09:32:07,256 [Thread-1053] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir1/file2; type=file; length=200  o3fs://bucket63722.volume91802/test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/newfile1; type=file; length=0
09:32:07.256 [IPC Server handler 3 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/file1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:07.259 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir2/subDir2/file3
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:07.259 [IPC Server handler 18 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4/file4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:07.260 [IPC Server handler 1 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume91802, bucket=bucket63722, key=test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume91802 bucket: bucket63722 key: test/ITestOzoneContractDistCp/testUpdateDeepDirectoryStructureToRemote/remote/outputDir/inputDir/subDir4/subDir4
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:07,284 [Thread-1318] INFO  Configuration.deprecation (Configuration.java:logDeprecation(1394)) - mapred.job.tracker is deprecated. Instead, use mapreduce.jobtracker.address
2019-06-14 09:32:07,319 [Thread-1318] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket64546.volume03852 implemented by OzoneFileSystem{URI=o3fs://bucket64546.volume03852, workingDir=o3fs://bucket64546.volume03852/user/root, userName=root, statistics=0 bytes read, 18878868 bytes written, 541 read ops, 0 large read ops, 91 write ops}
09:32:07.320 [IPC Server handler 4 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume03852, bucket=bucket64546, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume03852 bucket: bucket64546 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:07.327 [IPC Server handler 16 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume03852, bucket=bucket64546, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume03852 bucket: bucket64546 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:07.332 [IPC Server handler 13 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume03852, bucket=bucket64546, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume03852 bucket: bucket64546 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:07,334 [Thread-1318] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - copy a deep directory structure from remote to local
09:32:07.334 [IPC Server handler 9 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume03852, bucket=bucket64546, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume03852 bucket: bucket64546 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
09:32:07.337 [IPC Server handler 7 on 35323] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume03852, bucket=bucket64546, key=test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume03852 bucket: bucket64546 key: test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-14 09:32:07,552 [Thread-1318] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:07,557 [Thread-1318] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:07,584 [Thread-1318] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:printStats(608)) - Paths (files+dirs) cnt = 11; dirCnt = 6
2019-06-14 09:32:07,584 [Thread-1318] INFO  tools.SimpleCopyListing (SimpleCopyListing.java:doBuildListing(402)) - Build file listing completed.
2019-06-14 09:32:07,591 [Thread-1318] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:07,597 [Thread-1318] INFO  tools.DistCp (CopyListing.java:buildListing(94)) - Number of paths in the copy list: 11
2019-06-14 09:32:07,597 [Thread-1318] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - JobTracker metrics system started (again)
2019-06-14 09:32:07,602 [Thread-1318] WARN  mapreduce.JobResourceUploader (JobResourceUploader.java:uploadResourcesInternal(147)) - Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
2019-06-14 09:32:07,630 [Thread-1318] INFO  mapreduce.JobSubmitter (JobSubmitter.java:submitJobInternal(202)) - number of splits:1
2019-06-14 09:32:07,645 [Thread-1318] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(298)) - Submitting tokens for job: job_local1382098601_0009
2019-06-14 09:32:07,645 [Thread-1318] INFO  mapreduce.JobSubmitter (JobSubmitter.java:printTokens(299)) - Executing with tokens: []
2019-06-14 09:32:07,731 [Thread-1318] INFO  mapreduce.Job (Job.java:submit(1574)) - The url to track the job: http://localhost:8080/
2019-06-14 09:32:07,732 [Thread-1417] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(501)) - OutputCommitter set in config null
2019-06-14 09:32:07,733 [Thread-1318] INFO  tools.DistCp (DistCp.java:createAndSubmitJob(217)) - DistCp job-id: job_local1382098601_0009
2019-06-14 09:32:07,734 [Thread-1417] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:07,734 [Thread-1318] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1619)) - Running job: job_local1382098601_0009
2019-06-14 09:32:07,734 [Thread-1417] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:07,734 [Thread-1417] INFO  mapred.LocalJobRunner (LocalJobRunner.java:createOutputCommitter(519)) - OutputCommitter is org.apache.hadoop.tools.mapred.CopyCommitter
2019-06-14 09:32:07,743 [Thread-1417] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(478)) - Waiting for map tasks
2019-06-14 09:32:07,743 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(252)) - Starting task: attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,743 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:07,743 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:07,744 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:initialize(626)) -  Using ResourceCalculatorProcessTree : [ ]
2019-06-14 09:32:07,744 [LocalJobRunner Map Task Executor #0] INFO  mapred.MapTask (MapTask.java:runNewMapper(768)) - Processing split: file:/tmp/hadoop/mapred/staging/root776610181/.staging/_distcp687090293/fileList.seq:0+2787
2019-06-14 09:32:07,744 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(140)) - File Output Committer Algorithm version is 2
2019-06-14 09:32:07,744 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:<init>(155)) - FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
2019-06-14 09:32:07,753 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir
2019-06-14 09:32:07,761 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir4/subDir4/file4 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir4/subDir4/file4
2019-06-14 09:32:07,762 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/.distcp.tmp.attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,783 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2/file3 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir2/subDir2/file3
2019-06-14 09:32:07,784 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/.distcp.tmp.attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,800 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir2
2019-06-14 09:32:07,801 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir4 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir4
2019-06-14 09:32:07,802 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir2/subDir2 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir2/subDir2
2019-06-14 09:32:07,803 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir4/subDir4 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir4/subDir4
2019-06-14 09:32:07,804 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1/file2 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir1/file2
2019-06-14 09:32:07,804 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/.distcp.tmp.attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,816 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/file1 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/file1
2019-06-14 09:32:07,817 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/.distcp.tmp.attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,827 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir4/subDir4/file5 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir4/subDir4/file5
2019-06-14 09:32:07,828 [LocalJobRunner Map Task Executor #0] INFO  mapred.RetriableFileCopyCommand (RetriableFileCopyCommand.java:getTmpFile(260)) - Creating temp file: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/.distcp.tmp.attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,838 [LocalJobRunner Map Task Executor #0] INFO  mapred.CopyMapper (CopyMapper.java:map(154)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir1
2019-06-14 09:32:07,839 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:07,839 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1244)) - Task:attempt_local1382098601_0009_m_000000_0 is done. And is in the process of committing
2019-06-14 09:32:07,839 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - 
2019-06-14 09:32:07,839 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:commit(1421)) - Task attempt_local1382098601_0009_m_000000_0 is allowed to commit now
2019-06-14 09:32:07,840 [LocalJobRunner Map Task Executor #0] INFO  output.FileOutputCommitter (FileOutputCommitter.java:commitTask(598)) - Saved output of task 'attempt_local1382098601_0009_m_000000_0' to file:/tmp/hadoop/mapred/staging/root776610181/.staging/_distcp687090293/_logs
2019-06-14 09:32:07,840 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:statusUpdate(634)) - Copying o3fs://bucket64546.volume03852/test/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/remote/inputDir/subDir1 to file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir1
2019-06-14 09:32:07,840 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:sendDone(1380)) - Task 'attempt_local1382098601_0009_m_000000_0' done.
2019-06-14 09:32:07,841 [LocalJobRunner Map Task Executor #0] INFO  mapred.Task (Task.java:done(1276)) - Final Counters for attempt_local1382098601_0009_m_000000_0: Counters: 25
	File System Counters
		FILE: Number of bytes read=20951253
		FILE: Number of bytes written=26272535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18880368
		O3FS: Number of read operations=577
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=102
	Map-Reduce Framework
		Map input records=11
		Map output records=0
		Input split bytes=149
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=2839
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=1500
		Bytes Copied=1500
		Bytes Expected=1500
		Files Copied=5
		DIR_COPY=6
2019-06-14 09:32:07,841 [LocalJobRunner Map Task Executor #0] INFO  mapred.LocalJobRunner (LocalJobRunner.java:run(277)) - Finishing task: attempt_local1382098601_0009_m_000000_0
2019-06-14 09:32:07,841 [Thread-1417] INFO  mapred.LocalJobRunner (LocalJobRunner.java:runTasks(486)) - map task executor complete.
2019-06-14 09:32:07,849 [Thread-1417] INFO  mapred.CopyCommitter (CopyCommitter.java:cleanup(189)) - Cleaning up temporary work folder: file:/tmp/hadoop/mapred/staging/root776610181/.staging/_distcp687090293
2019-06-14 09:32:08,734 [Thread-1318] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1640)) - Job job_local1382098601_0009 running in uber mode : false
2019-06-14 09:32:08,734 [Thread-1318] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1647)) -  map 100% reduce 0%
2019-06-14 09:32:08,734 [Thread-1318] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1658)) - Job job_local1382098601_0009 completed successfully
2019-06-14 09:32:08,735 [Thread-1318] INFO  mapreduce.Job (Job.java:monitorAndPrintJob(1665)) - Counters: 25
	File System Counters
		FILE: Number of bytes read=20951253
		FILE: Number of bytes written=26272535
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		O3FS: Number of bytes read=0
		O3FS: Number of bytes written=18880368
		O3FS: Number of read operations=577
		O3FS: Number of large read operations=0
		O3FS: Number of write operations=102
	Map-Reduce Framework
		Map input records=11
		Map output records=0
		Input split bytes=149
		Spilled Records=0
		Failed Shuffles=0
		Merged Map outputs=0
		GC time elapsed (ms)=0
		Total committed heap usage (bytes)=504365056
	File Input Format Counters 
		Bytes Read=2839
	File Output Format Counters 
		Bytes Written=8
	DistCp Counters
		Bandwidth in Btyes=1500
		Bytes Copied=1500
		Bytes Expected=1500
		Files Copied=5
		DIR_COPY=6
2019-06-14 09:32:08,735 [Thread-1318] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(437)) - Destination tree after distcp: file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir:
2019-06-14 09:32:08,759 [Thread-1318] INFO  contract.AbstractContractDistCpTest (AbstractContractDistCpTest.java:lsR(446)) -   file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir1/file2; type=file; length=200  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir2/subDir2/file3; type=file; length=300  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir4/subDir4/file4; type=file; length=400  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/subDir4/subDir4/file5; type=file; length=500  file:/opt/src/hadoop-ozone/ozonefs/target/test-dir/ITestOzoneContractDistCp/testDeepDirectoryStructureFromRemote/local/outputDir/inputDir/file1; type=file; length=100
2019-06-14 09:32:08,772 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-06-14 09:32:08,774 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-06-14 09:32:08,774 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-06-14 09:32:08,774 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 35323
2019-06-14 09:32:08,775 [IPC Server listener on 35323] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 35323
2019-06-14 09:32:08,777 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-14 09:32:08,775 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-06-14 09:32:08,779 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2c0f7678{/,null,UNAVAILABLE}{/ozoneManager}
2019-06-14 09:32:08,782 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@44d70181{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:08,782 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@6594402a{/static,file:///opt/src/hadoop-ozone/ozone-manager/target/classes/webapps/static/,UNAVAILABLE}
2019-06-14 09:32:08,783 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22fa55b2{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-14 09:32:08,785 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Stopping the StorageContainerManager
2019-06-14 09:32:08,785 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(789)) - Stopping Replication Manager Service.
2019-06-14 09:32:08,785 [JUnit] INFO  container.ReplicationManager (ReplicationManager.java:stop(191)) - Replication Monitor Thread is not running.
2019-06-14 09:32:08,785 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(796)) - Stopping Lease Manager of the command watchers
2019-06-14 09:32:08,785 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(803)) - Stopping datanode service RPC server
2019-06-14 09:32:08,786 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(373)) - Stopping the RPC server for DataNodes
2019-06-14 09:32:08,786 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 46261
2019-06-14 09:32:08,786 [IPC Server listener on 46261] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 46261
2019-06-14 09:32:08,787 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping block service RPC server
2019-06-14 09:32:08,787 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-14 09:32:08,787 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(145)) - Stopping the RPC server for Block Protocol
2019-06-14 09:32:08,787 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34109
2019-06-14 09:32:08,788 [IPC Server listener on 34109] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34109
2019-06-14 09:32:08,788 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(818)) - Stopping the StorageContainerLocationProtocol RPC server
2019-06-14 09:32:08,788 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(157)) - Stopping the RPC server for Client Protocol
2019-06-14 09:32:08,789 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34049
2019-06-14 09:32:08,788 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-14 09:32:08,790 [IPC Server listener on 34049] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34049
2019-06-14 09:32:08,790 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-14 09:32:08,790 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(825)) - Stopping Storage Container Manager HTTP server.
2019-06-14 09:32:08,791 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@71984c3{/,null,UNAVAILABLE}{/scm}
2019-06-14 09:32:08,791 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@50eca7c6{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:08,792 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@34c01041{/static,file:///opt/src/hadoop-hdds/server-scm/target/classes/webapps/static/,UNAVAILABLE}
2019-06-14 09:32:08,792 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@32c726ee{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-14 09:32:08,793 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(836)) - Stopping Block Manager Service.
2019-06-14 09:32:08,793 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-06-14 09:32:08,793 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-06-14 09:32:08,794 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(858)) - Stopping SCM Event Queue.
2019-06-14 09:32:08,796 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(350)) - Shutting the HddsDatanodes
2019-06-14 09:32:08,797 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-14 09:32:08,798 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@4548d254
2019-06-14 09:32:08,798 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-14 09:32:08,799 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-14 09:32:08,799 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: close
2019-06-14 09:32:08,800 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown group-F9458460E34B
2019-06-14 09:32:08,800 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-F9458460E34B,id=0fd43f4d-887d-4ae8-add1-de86fbcb71c1
2019-06-14 09:32:08,800 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown LeaderState
2019-06-14 09:32:08,801 [ForkJoinPool.commonPool-worker-1] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-PendingRequests: sendNotLeaderResponses
2019-06-14 09:32:08,802 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-0fd43f4d-887d-4ae8-add1-de86fbcb71c1-group-F9458460E34B: set stopIndex = 0
2019-06-14 09:32:08,802 [StateMachineUpdater-0fd43f4d-887d-4ae8-add1-de86fbcb71c1-group-F9458460E34B] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-14 09:32:08,804 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-F9458460E34B closes. The last applied log index is 0
2019-06-14 09:32:08,804 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:08,806 [ForkJoinPool.commonPool-worker-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker close()
2019-06-14 09:32:08,806 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown group-D07D4A80573F
2019-06-14 09:32:08,806 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D07D4A80573F,id=0fd43f4d-887d-4ae8-add1-de86fbcb71c1
2019-06-14 09:32:08,806 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown FollowerState
2019-06-14 09:32:08,806 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-0fd43f4d-887d-4ae8-add1-de86fbcb71c1-group-D07D4A80573F: set stopIndex = 104
2019-06-14 09:32:08,806 [StateMachineUpdater-0fd43f4d-887d-4ae8-add1-de86fbcb71c1-group-D07D4A80573F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:1, i:103)
2019-06-14 09:32:08,807 [StateMachineUpdater-0fd43f4d-887d-4ae8-add1-de86fbcb71c1-group-D07D4A80573F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/sm/snapshot.1_103
2019-06-14 09:32:08,806 [Thread-241] INFO  impl.FollowerState (FollowerState.java:run(109)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-14 09:32:08,815 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:group-D07D4A80573F closes. The last applied log index is 104
2019-06-14 09:32:08,815 [0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:08,816 [ForkJoinPool.commonPool-worker-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1-RaftLogWorker close()
2019-06-14 09:32:08,818 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown server with port 46523 now
2019-06-14 09:32:08,822 [grpc-default-executor-0] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: appendEntries onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:08,822 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 0fd43f4d-887d-4ae8-add1-de86fbcb71c1: shutdown server with port 46523 successfully
2019-06-14 09:32:08,827 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-14 09:32:08,828 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-06-14 09:32:08,830 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 105 -> 0
2019-06-14 09:32:08,836 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:46261 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "ozone-j9z4j-3433919898/192.168.46.41"; destination host is: "0.0.0.0":46261; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-14 09:32:08,844 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-14 09:32:08,844 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5f18f9d2{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-14 09:32:08,845 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@598260a6{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:08,845 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12b5454f{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-14 09:32:08,845 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@2add4d24{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-14 09:32:08,846 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-14 09:32:08,846 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@9c73fff
2019-06-14 09:32:08,847 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-14 09:32:08,847 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-14 09:32:08,847 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: close
2019-06-14 09:32:08,848 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: shutdown group-600A8E3C0556
2019-06-14 09:32:08,848 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-600A8E3C0556,id=d14f1d27-9abd-48d3-981e-07fbbfd7075f
2019-06-14 09:32:08,848 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: shutdown LeaderState
2019-06-14 09:32:08,848 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f-PendingRequests: sendNotLeaderResponses
2019-06-14 09:32:08,849 [StateMachineUpdater-d14f1d27-9abd-48d3-981e-07fbbfd7075f-group-600A8E3C0556] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-14 09:32:08,849 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-d14f1d27-9abd-48d3-981e-07fbbfd7075f-group-600A8E3C0556: set stopIndex = 0
2019-06-14 09:32:08,851 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f:group-600A8E3C0556 closes. The last applied log index is 0
2019-06-14 09:32:08,851 [d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:08,852 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f-RaftLogWorker close()
2019-06-14 09:32:08,852 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: shutdown server with port 42411 now
2019-06-14 09:32:08,853 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - d14f1d27-9abd-48d3-981e-07fbbfd7075f: shutdown server with port 42411 successfully
2019-06-14 09:32:08,854 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-14 09:32:08,867 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-14 09:32:08,868 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3330f3ad{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-14 09:32:08,868 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@563af4e7{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:08,868 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@668625f5{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-14 09:32:08,868 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@74d6736{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-14 09:32:08,869 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-14 09:32:08,869 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@468e8565
2019-06-14 09:32:08,870 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-14 09:32:09,045 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:09,047 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:09,542 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:09,544 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:09,842 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:10,044 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:10,046 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:10,545 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:10,546 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:10,842 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:11,045 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:11,048 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:11,546 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:11,550 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:11,843 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:12,048 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:12,050 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:12,547 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:12,548 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:12,843 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:13,049 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:13,050 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:13,550 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:13,552 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:13,844 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:13,870 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:46261 for past 0 seconds.
java.io.InterruptedIOException: DestHost:destPort 0.0.0.0:46261 , LocalHost:localPort ozone-j9z4j-3433919898/192.168.46.41:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
	at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:945)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:706)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:943)
	... 18 more
2019-06-14 09:32:13,872 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-14 09:32:13,873 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: close
2019-06-14 09:32:13,873 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown group-FDE03975E078
2019-06-14 09:32:13,873 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown group-D07D4A80573F
2019-06-14 09:32:13,873 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-FDE03975E078,id=86e25bb3-b667-4401-8ad3-7e3322543d24
2019-06-14 09:32:13,874 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D07D4A80573F,id=86e25bb3-b667-4401-8ad3-7e3322543d24
2019-06-14 09:32:13,874 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown LeaderState
2019-06-14 09:32:13,874 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown FollowerState
2019-06-14 09:32:13,874 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-86e25bb3-b667-4401-8ad3-7e3322543d24-group-D07D4A80573F: set stopIndex = 104
2019-06-14 09:32:13,874 [StateMachineUpdater-86e25bb3-b667-4401-8ad3-7e3322543d24-group-D07D4A80573F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:1, i:103)
2019-06-14 09:32:13,874 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-PendingRequests: sendNotLeaderResponses
2019-06-14 09:32:13,880 [StateMachineUpdater-86e25bb3-b667-4401-8ad3-7e3322543d24-group-D07D4A80573F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/sm/snapshot.1_103
2019-06-14 09:32:13,880 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-86e25bb3-b667-4401-8ad3-7e3322543d24-group-FDE03975E078: set stopIndex = 0
2019-06-14 09:32:13,874 [Thread-242] INFO  impl.FollowerState (FollowerState.java:run(109)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-14 09:32:13,880 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-D07D4A80573F closes. The last applied log index is 104
2019-06-14 09:32:13,880 [StateMachineUpdater-86e25bb3-b667-4401-8ad3-7e3322543d24-group-FDE03975E078] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-14 09:32:13,882 [86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:13,882 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 86e25bb3-b667-4401-8ad3-7e3322543d24:group-FDE03975E078 closes. The last applied log index is 0
2019-06-14 09:32:13,883 [86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:13,883 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker close()
2019-06-14 09:32:13,884 [ForkJoinPool.commonPool-worker-0] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 86e25bb3-b667-4401-8ad3-7e3322543d24-RaftLogWorker close()
2019-06-14 09:32:13,885 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown server with port 38669 now
2019-06-14 09:32:13,886 [grpc-default-executor-0] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: appendEntries onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:13,886 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 86e25bb3-b667-4401-8ad3-7e3322543d24: shutdown server with port 38669 successfully
2019-06-14 09:32:13,889 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-06-14 09:32:13,891 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-14 09:32:13,906 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 105 -> 0
2019-06-14 09:32:13,914 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-14 09:32:13,914 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@76e3b45b{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-14 09:32:13,915 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@10b4e7f8{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:13,915 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@33eb6758{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-14 09:32:13,915 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@65f40689{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-14 09:32:13,916 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-14 09:32:13,916 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@47b33e07
2019-06-14 09:32:13,916 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-14 09:32:14,052 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:14,053 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:14,061 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:14,062 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:14,552 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:14,553 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:14,561 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:14,562 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:14,872 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:15,054 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:15,055 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:15,062 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:15,063 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:15,555 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:15,556 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:15,564 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:15,566 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:15,872 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:16,056 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:16,057 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:16,066 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:16,067 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:16,556 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:16,557 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:16,564 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:16,564 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:16,873 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:17,057 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:17,058 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:17,064 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:17,065 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:17,558 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:17,559 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:17,564 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:17,565 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:17,873 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:18,058 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:18,059 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:18,065 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:18,066 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:18,559 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:18,560 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:18,565 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:18,566 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:18,874 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:19,059 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:19,061 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:19,066 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:19,067 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:19,560 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:19,561 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:19,566 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:19,567 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:19,919 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:20,061 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:20,062 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:20,067 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:20,067 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:20,561 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:20,563 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:20,567 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:20,569 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:20,920 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:21,062 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:21,062 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:21,071 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:21,071 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:21,564 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:21,565 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:21,568 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:21,568 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:21,920 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:22,064 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:22,064 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:22,068 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:22,069 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:22,564 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:22,564 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:22,569 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:22,569 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:22,921 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:23,065 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:23,065 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:23,069 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:23,070 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:23,565 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 0fd43f4d-887d-4ae8-add1-de86fbcb71c1:192.168.46.41:46523: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:23,566 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->0fd43f4d-887d-4ae8-add1-de86fbcb71c1: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:23,570 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: Failed appendEntries to 86e25bb3-b667-4401-8ad3-7e3322543d24:192.168.46.41:38669: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-14 09:32:23,570 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0->86e25bb3-b667-4401-8ad3-7e3322543d24: nextIndex: updateUnconditionally 0 -> 0
2019-06-14 09:32:23,916 [JUnit] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:close(257)) - Unable to shutdown state machine properly.
2019-06-14 09:32:23,917 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-14 09:32:23,917 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: close
2019-06-14 09:32:23,917 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown group-77828CEAED7A
2019-06-14 09:32:23,918 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-77828CEAED7A,id=2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0
2019-06-14 09:32:23,918 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown LeaderState
2019-06-14 09:32:23,918 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-PendingRequests: sendNotLeaderResponses
2019-06-14 09:32:23,919 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-group-77828CEAED7A: set stopIndex = 0
2019-06-14 09:32:23,919 [StateMachineUpdater-2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-group-77828CEAED7A] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-14 09:32:23,920 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-77828CEAED7A closes. The last applied log index is 0
2019-06-14 09:32:23,921 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:23,922 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:23,922 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker close()
2019-06-14 09:32:23,923 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown group-D07D4A80573F
2019-06-14 09:32:23,923 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-D07D4A80573F,id=2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0
2019-06-14 09:32:23,923 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown LeaderState
2019-06-14 09:32:23,923 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-PendingRequests: sendNotLeaderResponses
2019-06-14 09:32:23,923 [org.apache.ratis.server.impl.LogAppender$$Lambda$310/1623962707@6222c4cf] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(142)) - GrpcLogAppender(2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 -> 0fd43f4d-887d-4ae8-add1-de86fbcb71c1): Wait interrupted by java.lang.InterruptedException
2019-06-14 09:32:23,923 [org.apache.ratis.server.impl.LogAppender$$Lambda$310/1623962707@35db248] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(142)) - GrpcLogAppender(2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0 -> 86e25bb3-b667-4401-8ad3-7e3322543d24): Wait interrupted by java.lang.InterruptedException
2019-06-14 09:32:23,925 [StateMachineUpdater-2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-group-D07D4A80573F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:1, i:103)
2019-06-14 09:32:23,925 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-group-D07D4A80573F: set stopIndex = 104
2019-06-14 09:32:23,926 [StateMachineUpdater-2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-group-D07D4A80573F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/ratis/445fd37c-da5f-43b3-a546-d07d4a80573f/sm/snapshot.1_103
2019-06-14 09:32:23,927 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0:group-D07D4A80573F closes. The last applied log index is 104
2019-06-14 09:32:23,927 [2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:23,928 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0-RaftLogWorker close()
2019-06-14 09:32:23,929 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown server with port 34265 now
2019-06-14 09:32:23,930 [grpc-default-executor-3] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 11-UnorderedRequestStreamObserver11: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:23,930 [grpc-default-executor-0] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 9-UnorderedRequestStreamObserver9: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:23,933 [grpc-default-executor-7] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 3-UnorderedRequestStreamObserver3: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:23,934 [grpc-default-executor-5] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 7-UnorderedRequestStreamObserver7: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:23,935 [grpc-default-executor-3] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:23,934 [grpc-default-executor-6] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 5-UnorderedRequestStreamObserver5: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-14 09:32:23,934 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 2e2bc98d-c1d2-463c-9f8e-4ffa2b5c97d0: shutdown server with port 34265 successfully
2019-06-14 09:32:23,939 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-14 09:32:23,955 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-14 09:32:23,955 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@2291d9a0{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-14 09:32:23,956 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5e26f1ed{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:23,956 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5d152bcd{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-14 09:32:23,956 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66383c29{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-14 09:32:23,957 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-14 09:32:23,957 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@383cb5ce
2019-06-14 09:32:23,958 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-14 09:32:24,924 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:25,924 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:26,925 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:27,926 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:28,926 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:46261. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-14 09:32:28,927 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:46261 for past 0 seconds.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-14 09:32:28,928 [Datanode State Machine Thread - 1] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,928 [Datanode State Machine Thread - 1] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,930 [Datanode State Machine Thread - 2] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,931 [Datanode State Machine Thread - 2] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,958 [Datanode State Machine Thread - 3] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,958 [Datanode State Machine Thread - 3] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,958 [Datanode State Machine Thread - 2] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,959 [Datanode State Machine Thread - 2] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,960 [Datanode State Machine Thread - 3] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,960 [Datanode State Machine Thread - 3] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,961 [Datanode State Machine Thread - 4] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,961 [Datanode State Machine Thread - 4] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,961 [Datanode State Machine Thread - 5] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,962 [Datanode State Machine Thread - 5] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,962 [Datanode State Machine Thread - 4] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,962 [Datanode State Machine Thread - 4] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,963 [Datanode State Machine Thread - 6] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,963 [Datanode State Machine Thread - 6] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,964 [Datanode State Machine Thread - 7] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,964 [Datanode State Machine Thread - 7] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,965 [Datanode State Machine Thread - 8] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,965 [Datanode State Machine Thread - 8] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,967 [Datanode State Machine Thread - 9] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,967 [Datanode State Machine Thread - 9] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,967 [Datanode State Machine Thread - 10] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,968 [Datanode State Machine Thread - 10] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,968 [Datanode State Machine Thread - 10] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:46261 for past 10 seconds.
java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "ozone-j9z4j-3433919898/192.168.46.41"; destination host is: "0.0.0.0":46261; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:816)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-14 09:32:28,968 [Datanode State Machine Thread - 11] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,969 [Datanode State Machine Thread - 11] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,969 [Datanode State Machine Thread - 12] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,969 [Datanode State Machine Thread - 12] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,970 [Datanode State Machine Thread - 13] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,970 [Datanode State Machine Thread - 13] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,971 [Datanode State Machine Thread - 14] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-14 09:32:28,971 [Datanode State Machine Thread - 14] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-14 09:32:28,971 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-14 09:32:28,972 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: close
2019-06-14 09:32:28,972 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: shutdown group-BBFF490E5A8C
2019-06-14 09:32:28,972 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-BBFF490E5A8C,id=7878b601-6f67-4deb-a261-1ba03dfc2f7b
2019-06-14 09:32:28,972 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: shutdown LeaderState
2019-06-14 09:32:28,973 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b-PendingRequests: sendNotLeaderResponses
2019-06-14 09:32:28,973 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-7878b601-6f67-4deb-a261-1ba03dfc2f7b-group-BBFF490E5A8C: set stopIndex = 0
2019-06-14 09:32:28,974 [StateMachineUpdater-7878b601-6f67-4deb-a261-1ba03dfc2f7b-group-BBFF490E5A8C] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-14 09:32:28,981 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b:group-BBFF490E5A8C closes. The last applied log index is 0
2019-06-14 09:32:28,982 [7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-14 09:32:28,982 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b-RaftLogWorker close()
2019-06-14 09:32:28,983 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: shutdown server with port 38597 now
2019-06-14 09:32:28,984 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 7878b601-6f67-4deb-a261-1ba03dfc2f7b: shutdown server with port 38597 successfully
2019-06-14 09:32:28,989 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-df9bd44c-4091-48ac-a614-ed346aa3829a/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-14 09:32:29,009 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-14 09:32:29,009 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@37a0ec3c{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-14 09:32:29,012 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@422ad5e2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-14 09:32:29,013 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@12219f6a{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-14 09:32:29,013 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5ae15{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}

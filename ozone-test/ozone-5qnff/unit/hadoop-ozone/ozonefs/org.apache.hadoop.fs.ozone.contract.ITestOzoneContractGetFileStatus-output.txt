2019-06-12 13:20:54,467 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:54,548 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:54,552 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:54,567 [JUnit] INFO  util.log (Log.java:initialized(192)) - Logging initialized @786ms
2019-06-12 13:20:54,661 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedBlocks
2019-06-12 13:20:54,661 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedBlocks
2019-06-12 13:20:54,662 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: validCerts
2019-06-12 13:20:54,662 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:validCerts
2019-06-12 13:20:54,662 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: revokedCerts
2019-06-12 13:20:54,662 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:revokedCerts
2019-06-12 13:20:54,672 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-06-12 13:20:54,672 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-06-12 13:20:54,674 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-06-12 13:20:54,758 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-06-12 13:20:54,759 [JUnit] WARN  server.ServerUtils (ServerUtils.java:sanitizeUserArgs(70)) - ozone.scm.stale.node.interval value = 300000 is larger than max = 100000 based on the key value of ozone.scm.heartbeat.thread.interval, reset to the max value 100000.
2019-06-12 13:20:54,766 [JUnit] INFO  node.SCMNodeManager (SCMNodeManager.java:<init>(108)) - Entering startup safe mode.
2019-06-12 13:20:54,843 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchemaFromFile(125)) - Loading file from sun.misc.CompoundEnumeration@6e20b53a
2019-06-12 13:20:54,845 [JUnit] INFO  net.NodeSchemaLoader (NodeSchemaLoader.java:loadSchema(171)) - Loading network topology layer schema file
2019-06-12 13:20:54,916 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:54,957 [JUnit] INFO  pipeline.SCMPipelineManager (SCMPipelineManager.java:initializePipelineState(126)) - No pipeline exists in current db
2019-06-12 13:20:54,960 [JUnit] WARN  server.ServerUtils (ServerUtils.java:getScmDbDir(145)) - ozone.scm.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:55,034 [JUnit] WARN  events.EventQueue (EventQueue.java:fireEvent(175)) - No event handler registered for event TypedEvent{payloadType=SafeModeStatus, name='SafeModeStatus'}
ERROR StatusLogger No Log4j 2 configuration file found. Using default configuration (logging only errors to the console), or user programmatically provided configurations. Set system property 'log4j2.debug' to show Log4j 2 internal initialization logging. See https://logging.apache.org/log4j/2.x/manual/configuration.html for instructions on how to configure Log4j 2
2019-06-12 13:20:55,573 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-12 13:20:55,593 [Socket Reader #1 for port 33157] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 33157
2019-06-12 13:20:55,612 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-12 13:20:55,612 [Socket Reader #1 for port 42175] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 42175
2019-06-12 13:20:55,652 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-12 13:20:55,652 [Socket Reader #1 for port 38293] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 38293
2019-06-12 13:20:55,668 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for scm at: http://0.0.0.0:0
2019-06-12 13:20:55,757 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:20:55,768 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:20:55,776 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:20:55,778 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context scm
2019-06-12 13:20:55,778 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:20:55,778 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:20:55,796 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(752)) - StorageContainerLocationProtocol RPC server is listening at /0.0.0.0:38293
2019-06-12 13:20:55,836 [JUnit] WARN  impl.MetricsConfig (MetricsConfig.java:loadFirst(134)) - Cannot locate configuration: tried hadoop-metrics2-storagecontainermanager.properties,hadoop-metrics2.properties
2019-06-12 13:20:55,846 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:startTimer(374)) - Scheduled Metric snapshot period at 10 second(s).
2019-06-12 13:20:55,846 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:start(191)) - StorageContainerManager metrics system started
2019-06-12 13:20:56,036 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:start(149)) - RPC server for Client  is listening at /0.0.0.0:38293
2019-06-12 13:20:56,041 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-12 13:20:56,042 [IPC Server listener on 38293] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 38293: starting
2019-06-12 13:20:56,059 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(761)) - ScmBlockLocationProtocol RPC server is listening at /0.0.0.0:42175
2019-06-12 13:20:56,059 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:start(137)) - RPC server for Block Protocol is listening at /0.0.0.0:42175
2019-06-12 13:20:56,059 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-12 13:20:56,060 [IPC Server listener on 42175] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 42175: starting
2019-06-12 13:20:56,064 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:start(765)) - ScmDatanodeProtocl RPC server is listening at /0.0.0.0:33157
2019-06-12 13:20:56,064 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:start(191)) - RPC server for DataNodes is listening at /0.0.0.0:33157
2019-06-12 13:20:56,065 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-12 13:20:56,065 [IPC Server listener on 33157] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 33157: starting
2019-06-12 13:20:56,070 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34737
2019-06-12 13:20:56,072 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:20:56,121 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@e57b96d{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:20:56,124 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@22f31dec{/static,file:///opt/src/hadoop-hdds/server-scm/target/classes/webapps/static/,AVAILABLE}
2019-06-12 13:20:56,169 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@69637b10{/,file:///opt/src/hadoop-hdds/server-scm/target/classes/webapps/scm/,AVAILABLE}{/scm}
2019-06-12 13:20:56,176 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@63192798{HTTP/1.1,[http/1.1]}{0.0.0.0:34737}
2019-06-12 13:20:56,177 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @2396ms
2019-06-12 13:20:56,178 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of SCM is listening at http://0.0.0.0:34737
2019-06-12 13:20:56,190 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@73c60324] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-12 13:20:56,194 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:56,295 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:56,297 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(519)) - OM Service ID is not set. Setting it to the default ID: omServiceIdDefault
2019-06-12 13:20:56,298 [JUnit] INFO  om.OzoneManager (OzoneManager.java:setOMNodeDetails(525)) - OM Node ID is not set. Setting it to the OmStorage's OmID: e68ff387-8b89-4a61-822c-6a1e164b2a48
2019-06-12 13:20:56,300 [JUnit] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-06-12 13:20:56,300 [JUnit] WARN  scm.HddsServerUtil (HddsServerUtil.java:getDefaultRatisDirectory(354)) - Storage directory for Ratis is not configured. It is a good idea to map this to an SSD disk. Falling back to ozone.metadata.dirs
2019-06-12 13:20:56,301 [JUnit] INFO  om.OzoneManager (OzoneManager.java:loadOMHAConfigs(476)) - Found matching OM address with OMServiceId: null, OMNodeId: null, RPC Address: localhost:0 and Ratis port: 9872
2019-06-12 13:20:56,530 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:56,538 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: userTable
2019-06-12 13:20:56,539 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:userTable
2019-06-12 13:20:56,539 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: volumeTable
2019-06-12 13:20:56,539 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:volumeTable
2019-06-12 13:20:56,539 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: bucketTable
2019-06-12 13:20:56,539 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:bucketTable
2019-06-12 13:20:56,540 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: keyTable
2019-06-12 13:20:56,540 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:keyTable
2019-06-12 13:20:56,540 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: deletedTable
2019-06-12 13:20:56,540 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:deletedTable
2019-06-12 13:20:56,541 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: openKeyTable
2019-06-12 13:20:56,541 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:openKeyTable
2019-06-12 13:20:56,541 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3Table
2019-06-12 13:20:56,541 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3Table
2019-06-12 13:20:56,541 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: multipartInfoTable
2019-06-12 13:20:56,541 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:multipartInfoTable
2019-06-12 13:20:56,542 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: dTokenTable
2019-06-12 13:20:56,542 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:dTokenTable
2019-06-12 13:20:56,542 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: s3SecretTable
2019-06-12 13:20:56,542 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:s3SecretTable
2019-06-12 13:20:56,543 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: prefixTable
2019-06-12 13:20:56,543 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(161)) - Using default column profile:DBProfile.DISK for Table:prefixTable
2019-06-12 13:20:56,543 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:addTable(110)) - using custom profile for table: default
2019-06-12 13:20:56,543 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:processTables(167)) - Using default column profile:DBProfile.DISK for Table:default
2019-06-12 13:20:56,544 [JUnit] INFO  db.DBStoreBuilder (DBStoreBuilder.java:getDbProfile(198)) - Using default options. DBProfile.DISK
2019-06-12 13:20:57,195 [JUnit] INFO  ipc.CallQueueManager (CallQueueManager.java:<init>(84)) - Using callQueue: class java.util.concurrent.LinkedBlockingQueue, queueCapacity: 2000, scheduler: class org.apache.hadoop.ipc.DefaultRpcScheduler, ipcBackoff: false.
2019-06-12 13:20:57,202 [Socket Reader #1 for port 34047] INFO  ipc.Server (Server.java:run(1074)) - Starting Socket Reader #1 for port 34047
2019-06-12 13:20:57,243 [JUnit] WARN  scm.ScmUtils (ScmUtils.java:getDBPath(63)) - ozone.om.db.dirs is not configured. We recommend adding this setting. Falling back to ozone.metadata.dirs instead.
2019-06-12 13:20:57,244 [JUnit] INFO  om.OzoneManager (OzoneManager.java:start(1217)) - OzoneManager RPC server is listening at localhost/127.0.0.1:34047
2019-06-12 13:20:57,244 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - OzoneManager metrics system started (again)
2019-06-12 13:20:57,258 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1314)) - IPC Server Responder: starting
2019-06-12 13:20:57,261 [IPC Server listener on 34047] INFO  ipc.Server (Server.java:run(1153)) - IPC Server listener on 34047: starting
2019-06-12 13:20:57,295 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for ozoneManager at: http://0.0.0.0:0
2019-06-12 13:20:57,299 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:20:57,301 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:20:57,305 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:20:57,317 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context ozoneManager
2019-06-12 13:20:57,317 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:20:57,318 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:20:57,323 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 44583
2019-06-12 13:20:57,324 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:20:57,327 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@66f66866{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:20:57,328 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@4d666b41{/static,file:///opt/src/hadoop-ozone/ozone-manager/target/classes/webapps/static/,AVAILABLE}
2019-06-12 13:20:57,333 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@18ca3c62{/,file:///opt/src/hadoop-ozone/ozone-manager/target/classes/webapps/ozoneManager/,AVAILABLE}{/ozoneManager}
2019-06-12 13:20:57,334 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@2c0f7678{HTTP/1.1,[http/1.1]}{0.0.0.0:44583}
2019-06-12 13:20:57,335 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @3554ms
2019-06-12 13:20:57,336 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of OZONEMANAGER is listening at http://0.0.0.0:44583
2019-06-12 13:20:57,677 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-12 13:20:57,766 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-5qnff-751971879 ip:192.168.19.39
2019-06-12 13:20:57,809 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-12 13:20:57,812 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/containers/hdds to VolumeSet
2019-06-12 13:20:57,815 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7004e3d
2019-06-12 13:20:57,835 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7004e3d
2019-06-12 13:20:57,907 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 39695
2019-06-12 13:20:58,013 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-12 13:20:58,026 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 39695 (custom)
2019-06-12 13:20:58,027 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-12 13:20:58,029 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:20:58,030 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-12 13:20:58,030 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:20:58,266 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis] (custom)
2019-06-12 13:20:58,273 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 43863
2019-06-12 13:20:58,302 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-12 13:20:58,317 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-12 13:20:58,319 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:20:58,321 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:20:58,325 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:20:58,327 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-12 13:20:58,327 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:20:58,327 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:20:58,330 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 34821
2019-06-12 13:20:58,330 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:20:58,355 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7f572c37{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:20:58,355 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@3f93e4a8{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-12 13:20:58,359 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@3f49e266{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-12 13:20:58,360 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@5f18f9d2{HTTP/1.1,[http/1.1]}{0.0.0.0:34821}
2019-06-12 13:20:58,363 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @4583ms
2019-06-12 13:20:58,364 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:34821
Jun 12, 2019 1:20:58 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-12 13:20:59,626 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@28369db0
2019-06-12 13:20:59,630 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-12 13:20:59,630 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-5qnff-751971879 ip:192.168.19.39
2019-06-12 13:20:59,682 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@2428201d] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-12 13:20:59,702 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-12 13:20:59,702 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/containers/hdds to VolumeSet
2019-06-12 13:20:59,702 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@7cf78c85
2019-06-12 13:20:59,710 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@7cf78c85
2019-06-12 13:20:59,774 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 41639
2019-06-12 13:20:59,775 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-12 13:20:59,775 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 41639 (custom)
2019-06-12 13:20:59,776 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-12 13:20:59,776 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:20:59,776 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-12 13:20:59,776 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:20:59,777 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis] (custom)
2019-06-12 13:20:59,778 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 38119
2019-06-12 13:20:59,778 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-12 13:20:59,779 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-12 13:20:59,802 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:20:59,803 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:20:59,814 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:20:59,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-12 13:20:59,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:20:59,815 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:20:59,816 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 45305
2019-06-12 13:20:59,816 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:20:59,828 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@abbe000{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:20:59,829 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@5b9499fe{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-12 13:20:59,846 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@b46e103{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-12 13:20:59,848 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@518aac41{HTTP/1.1,[http/1.1]}{0.0.0.0:45305}
2019-06-12 13:20:59,849 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6069ms
2019-06-12 13:20:59,860 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:45305
Jun 12, 2019 1:20:59 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-12 13:20:59,948 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/meta/datanode.id
2019-06-12 13:21:00,249 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@77c1e611
2019-06-12 13:21:00,250 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-12 13:21:00,250 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-5qnff-751971879 ip:192.168.19.39
2019-06-12 13:21:00,262 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@6fb294e2] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-12 13:21:00,276 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/meta/datanode.id
2019-06-12 13:21:00,282 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-12 13:21:00,282 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/containers/hdds to VolumeSet
2019-06-12 13:21:00,283 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@2e463f4
2019-06-12 13:21:00,287 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@2e463f4
2019-06-12 13:21:00,315 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 39979
2019-06-12 13:21:00,316 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-12 13:21:00,316 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 39979 (custom)
2019-06-12 13:21:00,316 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-12 13:21:00,317 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:00,317 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-12 13:21:00,317 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:21:00,318 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis] (custom)
2019-06-12 13:21:00,318 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 44643
2019-06-12 13:21:00,319 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-12 13:21:00,321 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-12 13:21:00,323 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:21:00,323 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:21:00,326 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:21:00,327 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-12 13:21:00,327 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:21:00,327 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:21:00,328 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 38447
2019-06-12 13:21:00,328 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:21:00,344 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@fe87ddd{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:21:00,344 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7c281eb8{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-12 13:21:00,352 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@4d157493{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-12 13:21:00,353 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@54c622a7{HTTP/1.1,[http/1.1]}{0.0.0.0:38447}
2019-06-12 13:21:00,355 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6575ms
2019-06-12 13:21:00,356 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:38447
Jun 12, 2019 1:21:00 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-12 13:21:00,548 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@7bc6935c
2019-06-12 13:21:00,549 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-12 13:21:00,550 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-5qnff-751971879 ip:192.168.19.39
2019-06-12 13:21:00,570 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@7537bf6f] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-12 13:21:00,573 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/meta/datanode.id
2019-06-12 13:21:00,584 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-12 13:21:00,584 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/containers/hdds to VolumeSet
2019-06-12 13:21:00,584 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@75b38c36
2019-06-12 13:21:00,586 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@75b38c36
2019-06-12 13:21:00,606 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 43553
2019-06-12 13:21:00,607 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-12 13:21:00,607 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 43553 (custom)
2019-06-12 13:21:00,607 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-12 13:21:00,608 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:00,608 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-12 13:21:00,608 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:21:00,608 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis] (custom)
2019-06-12 13:21:00,609 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 34229
2019-06-12 13:21:00,609 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-12 13:21:00,611 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-12 13:21:00,612 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:21:00,613 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:21:00,615 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:21:00,616 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-12 13:21:00,616 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:21:00,616 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:21:00,617 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 39045
2019-06-12 13:21:00,617 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:21:00,628 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@7e3d7dd{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:21:00,630 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@413bef78{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-12 13:21:00,638 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@5974b7e8{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-12 13:21:00,644 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@6d8f7166{HTTP/1.1,[http/1.1]}{0.0.0.0:39045}
2019-06-12 13:21:00,645 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @6864ms
2019-06-12 13:21:00,645 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:39045
Jun 12, 2019 1:21:00 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-12 13:21:00,909 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3592c1c4
2019-06-12 13:21:00,915 [JUnit] INFO  impl.MetricsSystemImpl (MetricsSystemImpl.java:init(158)) - HddsDatanode metrics system started (again)
2019-06-12 13:21:00,916 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:start(185)) - HddsDatanodeService host:ozone-5qnff-751971879 ip:192.168.19.39
2019-06-12 13:21:00,950 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4d994e67] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-12 13:21:00,957 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/meta/datanode.id
2019-06-12 13:21:00,966 [JUnit] INFO  volume.HddsVolume (HddsVolume.java:<init>(176)) - Creating Volume: /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/containers/hdds of  storage type : DISK and capacity : 104021790720
2019-06-12 13:21:00,966 [JUnit] INFO  volume.VolumeSet (VolumeSet.java:initializeVolumeSet(170)) - Added Volume : /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/containers/hdds to VolumeSet
2019-06-12 13:21:00,966 [JUnit] INFO  volume.ThrottledAsyncChecker (ThrottledAsyncChecker.java:schedule(140)) - Scheduling a check for org.apache.hadoop.ozone.container.common.volume.HddsVolume@151ab2b9
2019-06-12 13:21:00,969 [JUnit] INFO  volume.HddsVolumeChecker (HddsVolumeChecker.java:checkAllVolumes(203)) - Scheduled health check for volume org.apache.hadoop.ozone.container.common.volume.HddsVolume@151ab2b9
2019-06-12 13:21:00,998 [JUnit] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:newXceiverServerRatis(401)) - Found a free port for the server : 37967
2019-06-12 13:21:00,999 [JUnit] INFO  impl.RaftServerProxy (ConfUtils.java:logGet(43)) - raft.rpc.type = GRPC (default)
2019-06-12 13:21:00,999 [JUnit] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.port = 37967 (custom)
2019-06-12 13:21:00,999 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.message.size.max = 33570816 (custom)
2019-06-12 13:21:01,000 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:01,000 [JUnit] INFO  server.GrpcService (ConfUtils.java:logGet(43)) - raft.grpc.flow.control.window = 1MB (=1048576) (default)
2019-06-12 13:21:01,000 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:21:01,001 [JUnit] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis] (custom)
2019-06-12 13:21:01,001 [JUnit] INFO  server.XceiverServerGrpc (XceiverServerGrpc.java:<init>(97)) - Found a free port for the server : 37543
2019-06-12 13:21:01,001 [JUnit] INFO  replication.SimpleContainerDownloader (SimpleContainerDownloader.java:<init>(72)) - Starting container downloader service to copy containers to replicate.
2019-06-12 13:21:01,005 [JUnit] INFO  hdfs.DFSUtil (DFSUtil.java:httpServerTemplateForNNAndJN(1641)) - Starting Web-server for hddsDatanode at: http://0.0.0.0:0
2019-06-12 13:21:01,007 [JUnit] INFO  server.AuthenticationFilter (AuthenticationFilter.java:constructSecretProvider(240)) - Unable to initialize FileSignerSecretProvider, falling back to use random secrets.
2019-06-12 13:21:01,008 [JUnit] WARN  http.HttpRequestLog (HttpRequestLog.java:getRequestLog(97)) - Jetty request log can only be enabled using Log4j
2019-06-12 13:21:01,010 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addGlobalFilter(975)) - Added global filter 'safety' (class=org.apache.hadoop.http.HttpServer2$QuotingInputFilter)
2019-06-12 13:21:01,011 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(948)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context hddsDatanode
2019-06-12 13:21:01,011 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context logs
2019-06-12 13:21:01,011 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:addFilter(958)) - Added filter static_user_filter (class=org.apache.hadoop.http.lib.StaticUserWebFilter$StaticUserFilter) to context static
2019-06-12 13:21:01,012 [JUnit] INFO  http.HttpServer2 (HttpServer2.java:bindListener(1191)) - Jetty bound to port 37409
2019-06-12 13:21:01,012 [JUnit] INFO  server.Server (Server.java:doStart(351)) - jetty-9.3.24.v20180605, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827
2019-06-12 13:21:01,062 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@1c61eda5{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,AVAILABLE}
2019-06-12 13:21:01,063 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.s.ServletContextHandler@59838256{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,AVAILABLE}
2019-06-12 13:21:01,068 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStart(781)) - Started o.e.j.w.WebAppContext@202898d7{/,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/hddsDatanode/,AVAILABLE}{/hddsDatanode}
2019-06-12 13:21:01,070 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStart(278)) - Started ServerConnector@7a8726ec{HTTP/1.1,[http/1.1]}{0.0.0.0:37409}
2019-06-12 13:21:01,070 [JUnit] INFO  server.Server (Server.java:doStart(419)) - Started @7290ms
2019-06-12 13:21:01,072 [JUnit] INFO  server.BaseHttpServer (BaseHttpServer.java:updateConnectorAddress(207)) - HTTP server of HDDSDATANODE is listening at http://0.0.0.0:37409
Jun 12, 2019 1:21:01 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-12 13:21:01,296 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:startPlugins(396)) - Started plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@1d7eb170
2019-06-12 13:21:01,299 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-12 13:21:01,322 [org.apache.hadoop.util.JvmPauseMonitor$Monitor@4f65c038] INFO  util.JvmPauseMonitor (JvmPauseMonitor.java:run(188)) - Starting JVM pause monitor
2019-06-12 13:21:01,323 [Datanode State Machine Thread - 0] INFO  datanode.InitDatanodeState (InitDatanodeState.java:persistContainerDatanodeDetails(140)) - DatanodeDetails is persisted to /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/meta/datanode.id
2019-06-12 13:21:01,711 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-12 13:21:01,711 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-12 13:21:01,712 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec at port 39695
2019-06-12 13:21:01,769 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start RPC server
2019-06-12 13:21:01,973 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: GrpcService started, listening on 0.0.0.0/0.0.0.0:39695
2019-06-12 13:21:02,268 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-12 13:21:02,270 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-12 13:21:02,270 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 981253f6-13e6-412d-99d7-955bff6db2c2 at port 41639
2019-06-12 13:21:02,300 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-12 13:21:02,307 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start RPC server
2019-06-12 13:21:02,323 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 981253f6-13e6-412d-99d7-955bff6db2c2: GrpcService started, listening on 0.0.0.0/0.0.0.0:41639
2019-06-12 13:21:02,577 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-12 13:21:02,578 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-12 13:21:02,578 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 9afe9f49-e1cc-4c44-8276-958a49474b11 at port 39979
2019-06-12 13:21:02,593 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start RPC server
2019-06-12 13:21:02,604 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: GrpcService started, listening on 0.0.0.0/0.0.0.0:39979
2019-06-12 13:21:02,957 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-12 13:21:02,959 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-12 13:21:02,959 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 3454a52c-2512-4e92-bda0-24f774123a8f at port 43553
2019-06-12 13:21:02,967 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 3454a52c-2512-4e92-bda0-24f774123a8f: start RPC server
2019-06-12 13:21:02,972 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 3454a52c-2512-4e92-bda0-24f774123a8f: GrpcService started, listening on 0.0.0.0/0.0.0.0:43553
2019-06-12 13:21:03,300 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 0 of 5 DN Heartbeats.
2019-06-12 13:21:03,326 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:start(186)) - Attempting to start container services.
2019-06-12 13:21:03,328 [Datanode State Machine Thread - 0] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:startContainerScrub(160)) - Background container scrubber has been disabled by hdds.containerscrub.enabled
2019-06-12 13:21:03,328 [Datanode State Machine Thread - 0] INFO  ratis.XceiverServerRatis (XceiverServerRatis.java:start(418)) - Starting XceiverServerRatis 2812392d-5f88-4ec2-8910-05af6013a4af at port 37967
2019-06-12 13:21:03,334 [Datanode State Machine Thread - 0] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$start$3(299)) - 2812392d-5f88-4ec2-8910-05af6013a4af: start RPC server
2019-06-12 13:21:03,336 [Datanode State Machine Thread - 0] INFO  server.GrpcService (GrpcService.java:startImpl(148)) - 2812392d-5f88-4ec2-8910-05af6013a4af: GrpcService started, listening on 0.0.0.0/0.0.0.0:37967
2019-06-12 13:21:03,703 [IPC Server handler 7 on 33157] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}
2019-06-12 13:21:03,713 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (DataNodeSafeModeRule.java:process(71)) - SCM in safe mode. 1 DataNodes registered, 1 required.
2019-06-12 13:21:03,714 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:validateSafeModeExitRules(177)) - ScmSafeModeManager, all rules are successfully validated
2019-06-12 13:21:03,714 [EventQueue-NodeRegistrationContainerReportForDataNodeSafeModeRule] INFO  safemode.SCMSafeModeManager (SCMSafeModeManager.java:exitSafeMode(193)) - SCM exiting safe mode.
2019-06-12 13:21:04,237 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: addNew group-0FC2C454EE19:[8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] returns group-0FC2C454EE19:java.util.concurrent.CompletableFuture@7c3cf7ba[Not completed]
2019-06-12 13:21:04,250 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: new RaftServerImpl for group-0FC2C454EE19:[8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,252 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,254 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,254 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,254 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,264 [IPC Server handler 9 on 33157] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 981253f6-13e6-412d-99d7-955bff6db2c2{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}
2019-06-12 13:21:04,265 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 ConfigurationManager, init=-1: [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,265 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis] (custom)
2019-06-12 13:21:04,272 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/40a7fb5f-a0af-4235-ba4a-0fc2c454ee19 does not exist. Creating ...
2019-06-12 13:21:04,278 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/40a7fb5f-a0af-4235-ba4a-0fc2c454ee19/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,282 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/40a7fb5f-a0af-4235-ba4a-0fc2c454ee19 has been successfully formatted.
2019-06-12 13:21:04,284 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,284 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,286 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,289 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,292 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,297 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,300 [pool-37-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/40a7fb5f-a0af-4235-ba4a-0fc2c454ee19
2019-06-12 13:21:04,301 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 2 of 5 DN Heartbeats.
2019-06-12 13:21:04,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,301 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,303 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,304 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,305 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,306 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,309 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,444 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,445 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,446 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,467 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start group-0FC2C454EE19
2019-06-12 13:21:04,468 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,469 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start FollowerState
2019-06-12 13:21:04,471 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FC2C454EE19,id=8b94d44c-8dc5-4b41-bfaf-9726c3db5eec
2019-06-12 13:21:04,527 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 40a7fb5f-a0af-4235-ba4a-0fc2c454ee19, Nodes: 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-12 13:21:04,547 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 981253f6-13e6-412d-99d7-955bff6db2c2: addNew group-6A045A6D2136:[981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639] returns group-6A045A6D2136:java.util.concurrent.CompletableFuture@1b9cd527[Not completed]
2019-06-12 13:21:04,548 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 981253f6-13e6-412d-99d7-955bff6db2c2: new RaftServerImpl for group-6A045A6D2136:[981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,549 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,549 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,550 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,550 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,550 [pool-58-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 ConfigurationManager, init=-1: [981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,550 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis] (custom)
2019-06-12 13:21:04,550 [pool-58-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/d65f2ec4-2ea4-4573-aff4-6a045a6d2136 does not exist. Creating ...
2019-06-12 13:21:04,553 [pool-58-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/d65f2ec4-2ea4-4573-aff4-6a045a6d2136/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,562 [pool-58-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/d65f2ec4-2ea4-4573-aff4-6a045a6d2136 has been successfully formatted.
2019-06-12 13:21:04,563 [pool-58-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,563 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,563 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,563 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,563 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,563 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/d65f2ec4-2ea4-4573-aff4-6a045a6d2136
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,564 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,565 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,565 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,565 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,569 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,570 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,570 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,570 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start group-6A045A6D2136
2019-06-12 13:21:04,570 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,586 [IPC Server handler 7 on 33157] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 9afe9f49-e1cc-4c44-8276-958a49474b11{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}
2019-06-12 13:21:04,573 [pool-58-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start FollowerState
2019-06-12 13:21:04,587 [pool-58-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A045A6D2136,id=981253f6-13e6-412d-99d7-955bff6db2c2
2019-06-12 13:21:04,603 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: d65f2ec4-2ea4-4573-aff4-6a045a6d2136, Nodes: 981253f6-13e6-412d-99d7-955bff6db2c2{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-12 13:21:04,617 [grpc-default-executor-0] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: addNew group-ECEBFA9BD555:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979] returns group-ECEBFA9BD555:java.util.concurrent.CompletableFuture@4a1b182[Not completed]
2019-06-12 13:21:04,640 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: new RaftServerImpl for group-ECEBFA9BD555:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,640 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,641 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,641 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,641 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,641 [pool-79-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 ConfigurationManager, init=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,641 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis] (custom)
2019-06-12 13:21:04,642 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/df018229-3146-4e94-ac72-ecebfa9bd555 does not exist. Creating ...
2019-06-12 13:21:04,646 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/df018229-3146-4e94-ac72-ecebfa9bd555/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,648 [pool-79-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/df018229-3146-4e94-ac72-ecebfa9bd555 has been successfully formatted.
2019-06-12 13:21:04,650 [pool-79-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,650 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,650 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,651 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,651 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,651 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,651 [pool-79-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/df018229-3146-4e94-ac72-ecebfa9bd555
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,653 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,654 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,654 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,654 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,654 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,654 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,655 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,655 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start group-ECEBFA9BD555
2019-06-12 13:21:04,655 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,655 [pool-79-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start FollowerState
2019-06-12 13:21:04,656 [pool-79-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-ECEBFA9BD555,id=9afe9f49-e1cc-4c44-8276-958a49474b11
2019-06-12 13:21:04,660 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: df018229-3146-4e94-ac72-ecebfa9bd555, Nodes: 9afe9f49-e1cc-4c44-8276-958a49474b11{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-12 13:21:04,691 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: addNew group-166B3F51B5DF:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] returns group-166B3F51B5DF:java.util.concurrent.CompletableFuture@4ae48315[Not completed]
2019-06-12 13:21:04,691 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: addNew group-166B3F51B5DF:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] returns group-166B3F51B5DF:java.util.concurrent.CompletableFuture@71759e7f[Not completed]
2019-06-12 13:21:04,696 [grpc-default-executor-1] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 981253f6-13e6-412d-99d7-955bff6db2c2: addNew group-166B3F51B5DF:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] returns group-166B3F51B5DF:java.util.concurrent.CompletableFuture@4edb1e91[Not completed]
2019-06-12 13:21:04,696 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 981253f6-13e6-412d-99d7-955bff6db2c2: new RaftServerImpl for group-166B3F51B5DF:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,696 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,696 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,697 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,697 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,697 [pool-58-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF ConfigurationManager, init=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,697 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis] (custom)
2019-06-12 13:21:04,697 [pool-58-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df does not exist. Creating ...
2019-06-12 13:21:04,696 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: new RaftServerImpl for group-166B3F51B5DF:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,697 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,697 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,698 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,698 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,698 [pool-37-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF ConfigurationManager, init=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,698 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis] (custom)
2019-06-12 13:21:04,698 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df does not exist. Creating ...
2019-06-12 13:21:04,698 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: new RaftServerImpl for group-166B3F51B5DF:[9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF ConfigurationManager, init=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis] (custom)
2019-06-12 13:21:04,699 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df does not exist. Creating ...
2019-06-12 13:21:04,699 [pool-58-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,701 [pool-79-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,701 [pool-37-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,702 [pool-58-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df has been successfully formatted.
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,703 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,704 [pool-37-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df has been successfully formatted.
2019-06-12 13:21:04,704 [pool-79-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df has been successfully formatted.
2019-06-12 13:21:04,704 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,705 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,705 [pool-58-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,705 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start group-166B3F51B5DF
2019-06-12 13:21:04,705 [pool-58-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,705 [pool-58-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start FollowerState
2019-06-12 13:21:04,704 [pool-37-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,705 [pool-79-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,705 [pool-58-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-166B3F51B5DF,id=981253f6-13e6-412d-99d7-955bff6db2c2
2019-06-12 13:21:04,705 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,706 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,706 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,706 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,706 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,706 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,706 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,706 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,706 [pool-37-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,707 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,708 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,709 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,709 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,709 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,709 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,709 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,710 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,710 [pool-37-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,712 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,712 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,712 [pool-79-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,713 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start group-166B3F51B5DF
2019-06-12 13:21:04,713 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start group-166B3F51B5DF
2019-06-12 13:21:04,713 [pool-37-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,714 [pool-37-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start FollowerState
2019-06-12 13:21:04,714 [pool-79-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,714 [pool-79-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start FollowerState
2019-06-12 13:21:04,714 [pool-37-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-166B3F51B5DF,id=8b94d44c-8dc5-4b41-bfaf-9726c3db5eec
2019-06-12 13:21:04,715 [pool-79-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-166B3F51B5DF,id=9afe9f49-e1cc-4c44-8276-958a49474b11
2019-06-12 13:21:04,731 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 13ecd491-4217-450f-b62a-166b3f51b5df, Nodes: 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}9afe9f49-e1cc-4c44-8276-958a49474b11{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}981253f6-13e6-412d-99d7-955bff6db2c2{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:THREE, State:OPEN]
2019-06-12 13:21:04,953 [IPC Server handler 2 on 33157] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 3454a52c-2512-4e92-bda0-24f774123a8f{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}
2019-06-12 13:21:04,967 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 3454a52c-2512-4e92-bda0-24f774123a8f: addNew group-83FADFACA32F:[3454a52c-2512-4e92-bda0-24f774123a8f:192.168.19.39:43553] returns group-83FADFACA32F:java.util.concurrent.CompletableFuture@5c69e813[Not completed]
2019-06-12 13:21:04,968 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 3454a52c-2512-4e92-bda0-24f774123a8f: new RaftServerImpl for group-83FADFACA32F:[3454a52c-2512-4e92-bda0-24f774123a8f:192.168.19.39:43553] with ContainerStateMachine:uninitialized
2019-06-12 13:21:04,968 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:04,968 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:04,968 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:04,969 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:04,969 [pool-100-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F ConfigurationManager, init=-1: [3454a52c-2512-4e92-bda0-24f774123a8f:192.168.19.39:43553], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:04,969 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis] (custom)
2019-06-12 13:21:04,969 [pool-100-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis/a3ada6c0-4e5a-4e00-82c6-83fadfaca32f does not exist. Creating ...
2019-06-12 13:21:04,971 [pool-100-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis/a3ada6c0-4e5a-4e00-82c6-83fadfaca32f/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:04,974 [pool-100-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis/a3ada6c0-4e5a-4e00-82c6-83fadfaca32f has been successfully formatted.
2019-06-12 13:21:04,974 [pool-100-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:04,974 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:04,974 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:04,974 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis/a3ada6c0-4e5a-4e00-82c6-83fadfaca32f
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:04,975 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:04,976 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:04,976 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:04,976 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:04,976 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:04,976 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:04,977 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:04,977 [pool-100-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:04,977 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 3454a52c-2512-4e92-bda0-24f774123a8f: start group-83FADFACA32F
2019-06-12 13:21:04,977 [pool-100-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:04,977 [pool-100-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3454a52c-2512-4e92-bda0-24f774123a8f: start FollowerState
2019-06-12 13:21:04,978 [pool-100-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-83FADFACA32F,id=3454a52c-2512-4e92-bda0-24f774123a8f
2019-06-12 13:21:04,985 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: a3ada6c0-4e5a-4e00-82c6-83fadfaca32f, Nodes: 3454a52c-2512-4e92-bda0-24f774123a8f{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-12 13:21:05,301 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Waiting for cluster to be ready. Got 4 of 5 DN Heartbeats.
2019-06-12 13:21:05,324 [IPC Server handler 8 on 33157] INFO  node.SCMNodeManager (SCMNodeManager.java:register(234)) - Registered Data node : 2812392d-5f88-4ec2-8910-05af6013a4af{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}
2019-06-12 13:21:05,336 [grpc-default-executor-2] INFO  impl.RaftServerProxy (RaftServerProxy.java:addNew(89)) - 2812392d-5f88-4ec2-8910-05af6013a4af: addNew group-AA3197D8FA17:[2812392d-5f88-4ec2-8910-05af6013a4af:192.168.19.39:37967] returns group-AA3197D8FA17:java.util.concurrent.CompletableFuture@50676b0b[Not completed]
2019-06-12 13:21:05,337 [pool-121-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:<init>(91)) - 2812392d-5f88-4ec2-8910-05af6013a4af: new RaftServerImpl for group-AA3197D8FA17:[2812392d-5f88-4ec2-8910-05af6013a4af:192.168.19.39:37967] with ContainerStateMachine:uninitialized
2019-06-12 13:21:05,337 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.min = 1s (custom)
2019-06-12 13:21:05,337 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.timeout.max = 1200ms (custom)
2019-06-12 13:21:05,337 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpcslowness.timeout = 120s (custom)
2019-06-12 13:21:05,337 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:05,338 [pool-121-thread-1] INFO  impl.RaftServerImpl (ServerState.java:<init>(101)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 ConfigurationManager, init=-1: [2812392d-5f88-4ec2-8910-05af6013a4af:192.168.19.39:37967], old=null, confs=<EMPTY_MAP>
2019-06-12 13:21:05,338 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.storage.dir = [/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis] (custom)
2019-06-12 13:21:05,338 [pool-121-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:analyzeStorage(246)) - The storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis/474b0884-b724-4c86-99b7-aa3197d8fa17 does not exist. Creating ...
2019-06-12 13:21:05,340 [pool-121-thread-1] INFO  storage.RaftStorageDirectory (RaftStorageDirectory.java:tryLock(328)) - Lock on /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis/474b0884-b724-4c86-99b7-aa3197d8fa17/in_use.lock acquired by nodename 16978@ozone-5qnff-751971879
2019-06-12 13:21:05,343 [pool-121-thread-1] INFO  storage.RaftStorage (RaftStorage.java:format(75)) - Storage directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis/474b0884-b724-4c86-99b7-aa3197d8fa17 has been successfully formatted.
2019-06-12 13:21:05,343 [pool-121-thread-1] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:loadSnapshot(199)) - The snapshot info is null.Setting the last applied index to:(t:0, i:~)
2019-06-12 13:21:05,343 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.leader.election.timeout = 120s (custom)
2019-06-12 13:21:05,343 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.use.memory = false (default)
2019-06-12 13:21:05,343 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:05,343 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.cache.num.max = 2 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:<init>(123)) - new 2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker for Storage Directory /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis/474b0884-b724-4c86-99b7-aa3197d8fa17
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.byte-limit = 2147483647 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.queue.element-limit = 1024 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.segment.size.max = 16384 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.preallocated.size = 16384 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.write.buffer.size = 33554432 (custom)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.force.sync.num = 128 (default)
2019-06-12 13:21:05,344 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync = true (default)
2019-06-12 13:21:05,345 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout = 10s (default)
2019-06-12 13:21:05,345 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.sync.timeout.retry = -1 (default)
2019-06-12 13:21:05,345 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.statemachine.data.caching.enabled = true (custom)
2019-06-12 13:21:05,345 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.enabled = true (custom)
2019-06-12 13:21:05,345 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.snapshot.auto.trigger.threshold = 10000 (custom)
2019-06-12 13:21:05,346 [pool-121-thread-1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.retrycache.expirytime = 600000ms (custom)
2019-06-12 13:21:05,346 [pool-121-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:start(173)) - 2812392d-5f88-4ec2-8910-05af6013a4af: start group-AA3197D8FA17
2019-06-12 13:21:05,346 [pool-121-thread-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 changes role from null to FOLLOWER at term 0 for startAsFollower
2019-06-12 13:21:05,346 [pool-121-thread-1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2812392d-5f88-4ec2-8910-05af6013a4af: start FollowerState
2019-06-12 13:21:05,346 [pool-121-thread-1] INFO  util.JmxRegister (JmxRegister.java:tryRegister(44)) - Successfully registered JMX Bean with object name Ratis:service=RaftServer,group=group-AA3197D8FA17,id=2812392d-5f88-4ec2-8910-05af6013a4af
2019-06-12 13:21:05,351 [RatisPipelineUtilsThread] INFO  pipeline.PipelineStateManager (PipelineStateManager.java:addPipeline(56)) - Created pipeline Pipeline[ Id: 474b0884-b724-4c86-99b7-aa3197d8fa17, Nodes: 2812392d-5f88-4ec2-8910-05af6013a4af{ip: 192.168.19.39, host: ozone-5qnff-751971879, networkLocation: /default-rack, certSerialId: null}, Type:RATIS, Factor:ONE, State:OPEN]
2019-06-12 13:21:05,481 [Thread-209] INFO  impl.FollowerState (FollowerState.java:run(101)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 changes to CANDIDATE, lastRpcTime:1011, electionTimeout:1011ms
2019-06-12 13:21:05,481 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown FollowerState
2019-06-12 13:21:05,481 [Thread-209] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:05,483 [Thread-209] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start LeaderElection
2019-06-12 13:21:05,489 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1: begin an election at term 1 for -1: [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,490 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown LeaderElection
2019-06-12 13:21:05,490 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-12 13:21:05,490 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 change Leader from null to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec at term 1 for becomeLeader, leader elected after 1206ms
2019-06-12 13:21:05,494 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-12 13:21:05,494 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-12 13:21:05,497 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-12 13:21:05,497 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-12 13:21:05,502 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start LeaderState
2019-06-12 13:21:05,520 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:05,528 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19:LeaderElection1] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 set configuration 0: [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null at 0
2019-06-12 13:21:05,677 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/40a7fb5f-a0af-4235-ba4a-0fc2c454ee19/current/log_inprogress_0
2019-06-12 13:21:05,737 [Thread-212] INFO  impl.FollowerState (FollowerState.java:run(101)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 changes to CANDIDATE, lastRpcTime:1164, electionTimeout:1150ms
2019-06-12 13:21:05,739 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown FollowerState
2019-06-12 13:21:05,739 [Thread-212] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:05,739 [Thread-212] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start LeaderElection
2019-06-12 13:21:05,743 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2: begin an election at term 1 for -1: [981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639], old=null
2019-06-12 13:21:05,744 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown LeaderElection
2019-06-12 13:21:05,744 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-12 13:21:05,744 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 change Leader from null to 981253f6-13e6-412d-99d7-955bff6db2c2 at term 1 for becomeLeader, leader elected after 1181ms
2019-06-12 13:21:05,745 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-12 13:21:05,745 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-12 13:21:05,745 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-12 13:21:05,745 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-12 13:21:05,746 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start LeaderState
2019-06-12 13:21:05,746 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:05,746 [981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136:LeaderElection2] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 set configuration 0: [981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639], old=null at 0
2019-06-12 13:21:05,764 [Thread-223] INFO  impl.FollowerState (FollowerState.java:run(101)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes to CANDIDATE, lastRpcTime:1049, electionTimeout:1038ms
2019-06-12 13:21:05,764 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown FollowerState
2019-06-12 13:21:05,764 [Thread-223] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:05,764 [Thread-223] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start LeaderElection
2019-06-12 13:21:05,764 [Thread-218] INFO  impl.FollowerState (FollowerState.java:run(101)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF changes to CANDIDATE, lastRpcTime:1058, electionTimeout:1047ms
2019-06-12 13:21:05,764 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown FollowerState
2019-06-12 13:21:05,764 [Thread-218] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:05,764 [Thread-215] INFO  impl.FollowerState (FollowerState.java:run(101)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 changes to CANDIDATE, lastRpcTime:1108, electionTimeout:1091ms
2019-06-12 13:21:05,765 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown FollowerState
2019-06-12 13:21:05,765 [Thread-215] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:05,766 [Thread-215] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start LeaderElection
2019-06-12 13:21:05,766 [Thread-218] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start LeaderElection
2019-06-12 13:21:05,785 [981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/d65f2ec4-2ea4-4573-aff4-6a045a6d2136/current/log_inprogress_0
2019-06-12 13:21:05,790 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3: begin an election at term 1 for -1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,790 [981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4: begin an election at term 1 for -1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,793 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5: begin an election at term 1 for -1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979], old=null
2019-06-12 13:21:05,794 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown LeaderElection
2019-06-12 13:21:05,794 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-12 13:21:05,794 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 change Leader from null to 9afe9f49-e1cc-4c44-8276-958a49474b11 at term 1 for becomeLeader, leader elected after 1143ms
2019-06-12 13:21:05,795 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-12 13:21:05,795 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-12 13:21:05,795 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-12 13:21:05,795 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-12 13:21:05,795 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start LeaderState
2019-06-12 13:21:05,796 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:05,801 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555:LeaderElection5] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 set configuration 0: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979], old=null at 0
2019-06-12 13:21:05,816 [Thread-222] INFO  impl.FollowerState (FollowerState.java:run(101)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF changes to CANDIDATE, lastRpcTime:1089, electionTimeout:1089ms
2019-06-12 13:21:05,816 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown FollowerState
2019-06-12 13:21:05,816 [Thread-222] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:05,816 [Thread-222] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start LeaderElection
2019-06-12 13:21:05,837 [9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/df018229-3146-4e94-ac72-ecebfa9bd555/current/log_inprogress_0
2019-06-12 13:21:05,841 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6: begin an election at term 1 for -1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,872 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3: Election REJECTED; received 2 response(s) [9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2,false-t1, 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec,false-t1] and 0 exception(s); 9afe9f49-e1cc-4c44-8276-958a49474b11:t1, leader=null, voted=9afe9f49-e1cc-4c44-8276-958a49474b11, raftlog=9afe9f49-e1cc-4c44-8276-958a49474b11-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,872 [981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4: Election REJECTED; received 2 response(s) [981253f6-13e6-412d-99d7-955bff6db2c2->9afe9f49-e1cc-4c44-8276-958a49474b11,false-t1, 981253f6-13e6-412d-99d7-955bff6db2c2->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec,false-t1] and 0 exception(s); 981253f6-13e6-412d-99d7-955bff6db2c2:t1, leader=null, voted=981253f6-13e6-412d-99d7-955bff6db2c2, raftlog=981253f6-13e6-412d-99d7-955bff6db2c2-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,874 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-06-12 13:21:05,874 [981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-06-12 13:21:05,877 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6: Election REJECTED; received 2 response(s) [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec->9afe9f49-e1cc-4c44-8276-958a49474b11,false-t1, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec->981253f6-13e6-412d-99d7-955bff6db2c2,false-t1] and 0 exception(s); 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:t1, leader=null, voted=8b94d44c-8dc5-4b41-bfaf-9726c3db5eec, raftlog=8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:05,876 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown LeaderElection
2019-06-12 13:21:05,884 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF changes role from CANDIDATE to FOLLOWER at term 1 for DISCOVERED_A_NEW_TERM
2019-06-12 13:21:05,885 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown LeaderElection
2019-06-12 13:21:05,884 [981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown LeaderElection
2019-06-12 13:21:05,886 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF:LeaderElection6] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start FollowerState
2019-06-12 13:21:05,885 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start FollowerState
2019-06-12 13:21:05,886 [981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF:LeaderElection4] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start FollowerState
2019-06-12 13:21:06,113 [Thread-227] INFO  impl.FollowerState (FollowerState.java:run(101)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F changes to CANDIDATE, lastRpcTime:1135, electionTimeout:1135ms
2019-06-12 13:21:06,113 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 3454a52c-2512-4e92-bda0-24f774123a8f: shutdown FollowerState
2019-06-12 13:21:06,113 [Thread-227] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:06,113 [Thread-227] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3454a52c-2512-4e92-bda0-24f774123a8f: start LeaderElection
2019-06-12 13:21:06,118 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7: begin an election at term 1 for -1: [3454a52c-2512-4e92-bda0-24f774123a8f:192.168.19.39:43553], old=null
2019-06-12 13:21:06,118 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 3454a52c-2512-4e92-bda0-24f774123a8f: shutdown LeaderElection
2019-06-12 13:21:06,118 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-12 13:21:06,119 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F change Leader from null to 3454a52c-2512-4e92-bda0-24f774123a8f at term 1 for becomeLeader, leader elected after 1144ms
2019-06-12 13:21:06,120 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-12 13:21:06,120 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-12 13:21:06,120 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-12 13:21:06,120 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-12 13:21:06,120 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 3454a52c-2512-4e92-bda0-24f774123a8f: start LeaderState
2019-06-12 13:21:06,120 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:06,121 [3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F:LeaderElection7] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F set configuration 0: [3454a52c-2512-4e92-bda0-24f774123a8f:192.168.19.39:43553], old=null at 0
2019-06-12 13:21:06,163 [3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/ratis/a3ada6c0-4e5a-4e00-82c6-83fadfaca32f/current/log_inprogress_0
2019-06-12 13:21:06,301 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:lambda$waitForClusterToBeReady$0(142)) - Cluster is ready. Got 5 of 5 DN Heartbeats.
Jun 12, 2019 1:21:06 PM com.sun.jersey.server.impl.application.WebApplicationImpl _initiate
INFO: Initiating Jersey application, version 'Jersey: 1.19 02/11/2015 03:25 AM'
2019-06-12 13:21:06,483 [Thread-230] INFO  impl.FollowerState (FollowerState.java:run(101)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 changes to CANDIDATE, lastRpcTime:1136, electionTimeout:1136ms
2019-06-12 13:21:06,483 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 2812392d-5f88-4ec2-8910-05af6013a4af: shutdown FollowerState
2019-06-12 13:21:06,483 [Thread-230] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 changes role from FOLLOWER to CANDIDATE at term 0 for changeToCandidate
2019-06-12 13:21:06,483 [Thread-230] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2812392d-5f88-4ec2-8910-05af6013a4af: start LeaderElection
2019-06-12 13:21:06,526 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8: begin an election at term 1 for -1: [2812392d-5f88-4ec2-8910-05af6013a4af:192.168.19.39:37967], old=null
2019-06-12 13:21:06,527 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 2812392d-5f88-4ec2-8910-05af6013a4af: shutdown LeaderElection
2019-06-12 13:21:06,527 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 changes role from CANDIDATE to LEADER at term 1 for changeToLeader
2019-06-12 13:21:06,527 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 change Leader from null to 2812392d-5f88-4ec2-8910-05af6013a4af at term 1 for becomeLeader, leader elected after 1183ms
2019-06-12 13:21:06,529 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-12 13:21:06,529 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-12 13:21:06,530 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-12 13:21:06,530 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-12 13:21:06,530 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 2812392d-5f88-4ec2-8910-05af6013a4af: start LeaderState
2019-06-12 13:21:06,530 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:06,557 [2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17:LeaderElection8] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 set configuration 0: [2812392d-5f88-4ec2-8910-05af6013a4af:192.168.19.39:37967], old=null at 0
2019-06-12 13:21:06,586 [2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/ratis/474b0884-b724-4c86-99b7-aa3197d8fa17/current/log_inprogress_0
2019-06-12 13:21:06,894 [Thread-247] INFO  impl.FollowerState (FollowerState.java:run(101)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes to CANDIDATE, lastRpcTime:1009, electionTimeout:1004ms
2019-06-12 13:21:06,894 [Thread-247] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown FollowerState
2019-06-12 13:21:06,894 [Thread-247] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes role from FOLLOWER to CANDIDATE at term 1 for changeToCandidate
2019-06-12 13:21:06,895 [Thread-247] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start LeaderElection
2019-06-12 13:21:06,903 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:askForVotes(181)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9: begin an election at term 2 for -1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:06,911 [grpc-default-executor-3] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF changes role from FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:9afe9f49-e1cc-4c44-8276-958a49474b11
2019-06-12 13:21:06,911 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown FollowerState
2019-06-12 13:21:06,911 [grpc-default-executor-3] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 981253f6-13e6-412d-99d7-955bff6db2c2: start FollowerState
2019-06-12 13:21:06,911 [Thread-249] INFO  impl.FollowerState (FollowerState.java:run(109)) - 981253f6-13e6-412d-99d7-955bff6db2c2: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-12 13:21:06,932 [grpc-default-executor-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF changes role from FOLLOWER to FOLLOWER at term 2 for recognizeCandidate:9afe9f49-e1cc-4c44-8276-958a49474b11
2019-06-12 13:21:06,933 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown FollowerState
2019-06-12 13:21:06,933 [grpc-default-executor-0] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: start FollowerState
2019-06-12 13:21:06,933 [Thread-248] INFO  impl.FollowerState (FollowerState.java:run(109)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-12 13:21:06,944 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.LeaderElection (LeaderElection.java:logAndReturn(56)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9: Election PASSED; received 1 response(s) [9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2,true-t2] and 0 exception(s); 9afe9f49-e1cc-4c44-8276-958a49474b11:t2, leader=null, voted=9afe9f49-e1cc-4c44-8276-958a49474b11, raftlog=9afe9f49-e1cc-4c44-8276-958a49474b11-SegmentedRaftLog:OPENED:c-1,f-1,i0, conf=-1: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null
2019-06-12 13:21:06,944 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderElection(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown LeaderElection
2019-06-12 13:21:06,944 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.RaftServerImpl (RaftServerImpl.java:setRole(164)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF changes role from CANDIDATE to LEADER at term 2 for changeToLeader
2019-06-12 13:21:06,944 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF change Leader from null to 9afe9f49-e1cc-4c44-8276-958a49474b11 at term 2 for becomeLeader, leader elected after 2238ms
2019-06-12 13:21:06,944 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.staging.catchup.gap = 1000 (default)
2019-06-12 13:21:06,945 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.sleep.time = 25ms (default)
2019-06-12 13:21:06,945 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout = 10s (default)
2019-06-12 13:21:06,960 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.watch.timeout.denomination = 1s (default)
2019-06-12 13:21:06,969 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-06-12 13:21:06,970 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:06,970 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-06-12 13:21:06,971 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-06-12 13:21:06,972 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:21:06,973 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:06,973 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.snapshot.chunk.size.max = 16MB (=16777216) (default)
2019-06-12 13:21:06,974 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.byte-limit = 33554432 (custom)
2019-06-12 13:21:06,974 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.buffer.element-limit = 1 (custom)
2019-06-12 13:21:06,974 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  grpc.GrpcConfigKeys$Server (ConfUtils.java:logGet(43)) - raft.grpc.server.leader.outstanding.appends.max = 128 (default)
2019-06-12 13:21:06,974 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.rpc.request.timeout = 3000ms (default)
2019-06-12 13:21:06,974 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  server.RaftServerConfigKeys (ConfUtils.java:logGet(43)) - raft.server.log.appender.install.snapshot.enabled = true (default)
2019-06-12 13:21:06,974 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.RoleInfo (RoleInfo.java:updateAndGet(143)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: start LeaderState
2019-06-12 13:21:06,975 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:06,982 [9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF:LeaderElection9] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF set configuration 0: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null at 0
2019-06-12 13:21:07,019 [Thread-252] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket22042.volume08364 implemented by OzoneFileSystem{URI=o3fs://bucket22042.volume08364, workingDir=o3fs://bucket22042.volume08364/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 0 read ops, 0 large read ops, 0 write ops}
2019-06-12 13:21:07,024 [9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/current/log_inprogress_0
2019-06-12 13:21:07,032 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF change Leader from null to 9afe9f49-e1cc-4c44-8276-958a49474b11 at term 2 for appendEntries, leader elected after 2326ms
2019-06-12 13:21:07,034 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setLeader(263)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF change Leader from null to 9afe9f49-e1cc-4c44-8276-958a49474b11 at term 2 for appendEntries, leader elected after 2330ms
2019-06-12 13:21:07,053 [grpc-default-executor-0] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF set configuration 0: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null at 0
2019-06-12 13:21:07,053 [grpc-default-executor-0] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker: Starting segment from index:0
2019-06-12 13:21:07,058 [grpc-default-executor-3] INFO  impl.RaftServerImpl (ServerState.java:setRaftConf(361)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF set configuration 0: [9afe9f49-e1cc-4c44-8276-958a49474b11:192.168.19.39:39979, 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639, 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695], old=null at 0
2019-06-12 13:21:07,058 [grpc-default-executor-3] INFO  storage.RaftLogWorker (RaftLogWorker.java:startLogSegment(298)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker: Starting segment from index:0
13:21:07.050 [IPC Server handler 2 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume08364, bucket=bucket22042, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume08364 bucket: bucket22042 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,113 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/current/log_inprogress_0
2019-06-12 13:21:07,136 [981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:execute(469)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker: created new log segment /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/current/log_inprogress_0
2019-06-12 13:21:07,168 [Thread-252] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Invoke listFiles(recursive=false) on empty directories, expect nothing found
13:21:07.204 [IPC Server handler 13 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume08364, bucket=bucket22042, key=test/testListFilesEmptyDirectoryNonrecursive, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume08364 bucket: bucket22042 key: test/testListFilesEmptyDirectoryNonrecursive
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,223 [Thread-252] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Test on empty subdirectory
2019-06-12 13:21:07,226 [Thread-252] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket22042.volume08364, workingDir=o3fs://bucket22042.volume08364/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 8 read ops, 0 large read ops, 1 write ops}
2019-06-12 13:21:07,379 [Thread-273] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket24026.volume29750 implemented by OzoneFileSystem{URI=o3fs://bucket24026.volume29750, workingDir=o3fs://bucket24026.volume29750/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 11 read ops, 0 large read ops, 2 write ops}
13:21:07.380 [IPC Server handler 7 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29750, bucket=bucket24026, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29750 bucket: bucket24026 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,392 [Thread-273] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - List status on an empty directory
13:21:07.399 [IPC Server handler 15 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume29750, bucket=bucket24026, key=test/testListStatusEmptyDirectory, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume29750 bucket: bucket24026 key: test/testListStatusEmptyDirectory
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,404 [Thread-273] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Test on empty subdirectory
2019-06-12 13:21:07,405 [Thread-273] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket24026.volume29750, workingDir=o3fs://bucket24026.volume29750/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 19 read ops, 0 large read ops, 3 write ops}
2019-06-12 13:21:07,465 [Thread-274] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket98901.volume19678 implemented by OzoneFileSystem{URI=o3fs://bucket98901.volume19678, workingDir=o3fs://bucket98901.volume19678/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 22 read ops, 0 large read ops, 4 write ops}
13:21:07.466 [IPC Server handler 13 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume19678, bucket=bucket98901, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume19678 bucket: bucket98901 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,470 [Thread-274] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Call listLocatedStatus() with filtering
2019-06-12 13:21:07,471 [Thread-274] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Call listStatus() against paths and directories with filtering
13:21:07.515 [IPC Server handler 11 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume19678, bucket=bucket98901, key=test/subdir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume19678 bucket: bucket98901 key: test/subdir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,522 [Thread-274] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket98901.volume19678, workingDir=o3fs://bucket98901.volume19678/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 37 read ops, 0 large read ops, 8 write ops}
2019-06-12 13:21:07,567 [Thread-275] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket79674.volume59461 implemented by OzoneFileSystem{URI=o3fs://bucket79674.volume59461, workingDir=o3fs://bucket79674.volume59461/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 40 read ops, 0 large read ops, 9 write ops}
13:21:07.568 [IPC Server handler 14 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume59461, bucket=bucket79674, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume59461 bucket: bucket79674 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,572 [Thread-275] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listStatus(path, filter) on a file
2019-06-12 13:21:07,577 [Thread-275] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket79674.volume59461, workingDir=o3fs://bucket79674.volume59461/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 43 read ops, 0 large read ops, 10 write ops}
2019-06-12 13:21:07,621 [Thread-276] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket42064.volume10716 implemented by OzoneFileSystem{URI=o3fs://bucket42064.volume10716, workingDir=o3fs://bucket42064.volume10716/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 46 read ops, 0 large read ops, 11 write ops}
13:21:07.621 [IPC Server handler 8 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10716, bucket=bucket42064, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10716 bucket: bucket42064 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,624 [Thread-276] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Invoke listFiles(recursive=true) on empty directories, expect nothing found
13:21:07.629 [IPC Server handler 18 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume10716, bucket=bucket42064, key=test/testListFilesEmptyDirectoryRecursive, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume10716 bucket: bucket42064 key: test/testListFilesEmptyDirectoryRecursive
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,634 [Thread-276] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Test on empty subdirectory
2019-06-12 13:21:07,636 [Thread-276] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket42064.volume10716, workingDir=o3fs://bucket42064.volume10716/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 55 read ops, 0 large read ops, 12 write ops}
2019-06-12 13:21:07,680 [Thread-277] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket16417.volume13927 implemented by OzoneFileSystem{URI=o3fs://bucket16417.volume13927, workingDir=o3fs://bucket16417.volume13927/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 58 read ops, 0 large read ops, 13 write ops}
13:21:07.681 [IPC Server handler 16 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume13927, bucket=bucket16417, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume13927 bucket: bucket16417 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,685 [Thread-277] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listLocatedStatus(path) on a file
2019-06-12 13:21:07,689 [Thread-277] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket16417.volume13927, workingDir=o3fs://bucket16417.volume13927/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 62 read ops, 0 large read ops, 14 write ops}
2019-06-12 13:21:07,729 [Thread-280] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket79145.volume31455 implemented by OzoneFileSystem{URI=o3fs://bucket79145.volume31455, workingDir=o3fs://bucket79145.volume31455/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 65 read ops, 0 large read ops, 15 write ops}
13:21:07.730 [IPC Server handler 12 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume31455, bucket=bucket79145, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume31455 bucket: bucket79145 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,734 [Thread-280] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket79145.volume31455, workingDir=o3fs://bucket79145.volume31455/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 68 read ops, 0 large read ops, 15 write ops}
2019-06-12 13:21:07,776 [Thread-281] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket87624.volume69456 implemented by OzoneFileSystem{URI=o3fs://bucket87624.volume69456, workingDir=o3fs://bucket87624.volume69456/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 71 read ops, 0 large read ops, 16 write ops}
13:21:07.777 [IPC Server handler 7 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume69456, bucket=bucket87624, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume69456 bucket: bucket87624 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,780 [Thread-281] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Call listStatus() against paths and directories with filtering
13:21:07.792 [IPC Server handler 1 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume69456, bucket=bucket87624, key=test/subdir, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume69456 bucket: bucket87624 key: test/subdir
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,797 [Thread-281] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket87624.volume69456, workingDir=o3fs://bucket87624.volume69456/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 84 read ops, 0 large read ops, 18 write ops}
2019-06-12 13:21:07,837 [Thread-282] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket66120.volume68781 implemented by OzoneFileSystem{URI=o3fs://bucket66120.volume68781, workingDir=o3fs://bucket66120.volume68781/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 87 read ops, 0 large read ops, 19 write ops}
13:21:07.838 [IPC Server handler 1 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume68781, bucket=bucket66120, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume68781 bucket: bucket66120 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,841 [Thread-282] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listFiles calls on a path which is not present
13:21:07.841 [IPC Server handler 2 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=LIST_STATUS {volume=volume68781, bucket=bucket66120, key=test/missing, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume68781 bucket: bucket66120 key: test/missing
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listStatus(KeyManagerImpl.java:1884) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.listStatus(OzoneManager.java:2999) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.listStatus(OzoneManagerRequestHandler.java:1112) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:357) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:07.842 [IPC Server handler 6 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=LIST_STATUS {volume=volume68781, bucket=bucket66120, key=test/missing, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume68781 bucket: bucket66120 key: test/missing
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listStatus(KeyManagerImpl.java:1884) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.listStatus(OzoneManager.java:2999) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.listStatus(OzoneManagerRequestHandler.java:1112) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:357) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,843 [Thread-282] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket66120.volume68781, workingDir=o3fs://bucket66120.volume68781/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 91 read ops, 0 large read ops, 19 write ops}
2019-06-12 13:21:07,889 [Thread-283] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket82694.volume95527 implemented by OzoneFileSystem{URI=o3fs://bucket82694.volume95527, workingDir=o3fs://bucket82694.volume95527/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 94 read ops, 0 large read ops, 20 write ops}
13:21:07.890 [IPC Server handler 18 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95527, bucket=bucket82694, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95527 bucket: bucket82694 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,893 [Thread-283] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Invoke listLocatedStatus() on empty directories; expect directories to be found
13:21:07.897 [IPC Server handler 6 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume95527, bucket=bucket82694, key=test/testListLocatedStatusEmptyDirectory, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume95527 bucket: bucket82694 key: test/testListLocatedStatusEmptyDirectory
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,901 [Thread-283] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Test on empty subdirectory
2019-06-12 13:21:07,902 [Thread-283] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket82694.volume95527, workingDir=o3fs://bucket82694.volume95527/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 102 read ops, 0 large read ops, 21 write ops}
2019-06-12 13:21:07,940 [Thread-284] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket59553.volume04557 implemented by OzoneFileSystem{URI=o3fs://bucket59553.volume04557, workingDir=o3fs://bucket59553.volume04557/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 105 read ops, 0 large read ops, 22 write ops}
13:21:07.941 [IPC Server handler 1 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume04557, bucket=bucket59553, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume04557 bucket: bucket59553 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:07,943 [Thread-284] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listStatus(path) on a file
2019-06-12 13:21:07,949 [Thread-284] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket59553.volume04557, workingDir=o3fs://bucket59553.volume04557/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 109 read ops, 0 large read ops, 23 write ops}
2019-06-12 13:21:08,001 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket23402.volume36784 implemented by OzoneFileSystem{URI=o3fs://bucket23402.volume36784, workingDir=o3fs://bucket23402.volume36784/user/root, userName=root, statistics=0 bytes read, 0 bytes written, 112 read ops, 0 large read ops, 24 write ops}
13:21:08.003 [IPC Server handler 5 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:08.007 [IPC Server handler 4 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:08,198 [grpc-default-executor-0] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 0-OrderedRequestStreamObserver0: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
13:21:09.658 [IPC Server handler 3 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0000, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0000
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.845 [IPC Server handler 1 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0000/dir-0-0000-0000, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0000/dir-0-0000-0000
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.849 [IPC Server handler 6 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0000/dir-0-0000-0001, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0000/dir-0-0000-0001
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.852 [IPC Server handler 8 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0000/dir-0-0000-0002, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0000/dir-0-0000-0002
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.856 [IPC Server handler 16 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0001, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0001
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.970 [IPC Server handler 12 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0001/dir-0-0001-0000, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0001/dir-0-0001-0000
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.974 [IPC Server handler 18 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0001/dir-0-0001-0001, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0001/dir-0-0001-0001
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.977 [IPC Server handler 1 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0001/dir-0-0001-0002, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0001/dir-0-0001-0002
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:09.982 [IPC Server handler 10 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0002, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0002
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:10.121 [IPC Server handler 6 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0002/dir-0-0002-0000, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0002/dir-0-0002-0000
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:10.124 [IPC Server handler 8 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0002/dir-0-0002-0001, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0002/dir-0-0002-0001
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:10.127 [IPC Server handler 12 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume36784, bucket=bucket23402, key=test/testComplexDirActions/dir-0-0002/dir-0-0002-0002, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume36784 bucket: bucket23402 key: test/testComplexDirActions/dir-0-0002/dir-0-0002-0002
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,130 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Expect listStatus to list all entries in top dir only
2019-06-12 13:21:10,132 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Expect listLocatedStatus to list all entries in top dir only
2019-06-12 13:21:10,136 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verifying file statuses
2019-06-12 13:21:10,146 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Expect non-recursive listFiles(false) to list all entries in top dir only
2019-06-12 13:21:10,150 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verifying file statuses
2019-06-12 13:21:10,157 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - Expect recursive listFiles(true) to list all files down the tree
2019-06-12 13:21:10,168 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verifying file statuses
2019-06-12 13:21:10,188 [Thread-285] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - verifying consistency with treewalk's files
2019-06-12 13:21:10,189 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000*
2019-06-12 13:21:10,190 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001*
2019-06-12 13:21:10,190 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002*
2019-06-12 13:21:10,190 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/file--0-0000.txt
2019-06-12 13:21:10,190 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/file--0-0001.txt
2019-06-12 13:21:10,190 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/file--0-0002.txt
2019-06-12 13:21:10,190 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/file--0-0003.txt
2019-06-12 13:21:10,191 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/dir-0-0000-0000*
2019-06-12 13:21:10,191 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/dir-0-0000-0001*
2019-06-12 13:21:10,191 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/dir-0-0000-0002*
2019-06-12 13:21:10,191 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/file--0-0000-0000.txt
2019-06-12 13:21:10,191 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/file--0-0000-0001.txt
2019-06-12 13:21:10,191 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/file--0-0000-0002.txt
2019-06-12 13:21:10,192 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0000/file--0-0000-0003.txt
2019-06-12 13:21:10,195 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/dir-0-0001-0000*
2019-06-12 13:21:10,195 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/dir-0-0001-0001*
2019-06-12 13:21:10,195 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/dir-0-0001-0002*
2019-06-12 13:21:10,196 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/file--0-0001-0000.txt
2019-06-12 13:21:10,196 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/file--0-0001-0001.txt
2019-06-12 13:21:10,196 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/file--0-0001-0002.txt
2019-06-12 13:21:10,196 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0001/file--0-0001-0003.txt
2019-06-12 13:21:10,199 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/dir-0-0002-0000*
2019-06-12 13:21:10,199 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/dir-0-0002-0001*
2019-06-12 13:21:10,199 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/dir-0-0002-0002*
2019-06-12 13:21:10,200 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/file--0-0002-0000.txt
2019-06-12 13:21:10,200 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/file--0-0002-0001.txt
2019-06-12 13:21:10,200 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/file--0-0002-0002.txt
2019-06-12 13:21:10,200 [Thread-285] INFO  contract.ContractTestUtils (ContractTestUtils.java:treeWalk(1400)) - o3fs://bucket23402.volume36784/test/testComplexDirActions/dir-0-0002/file--0-0002-0003.txt
2019-06-12 13:21:10,220 [Thread-285] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket23402.volume36784, workingDir=o3fs://bucket23402.volume36784/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 256 read ops, 0 large read ops, 40 write ops}
2019-06-12 13:21:10,290 [Thread-488] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket24466.volume39772 implemented by OzoneFileSystem{URI=o3fs://bucket24466.volume39772, workingDir=o3fs://bucket24466.volume39772/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 259 read ops, 0 large read ops, 41 write ops}
13:21:10.291 [IPC Server handler 10 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume39772, bucket=bucket24466, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume39772 bucket: bucket24466 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,294 [Thread-488] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listStatus(path) on a file
2019-06-12 13:21:10,298 [Thread-488] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket24466.volume39772, workingDir=o3fs://bucket24466.volume39772/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 262 read ops, 0 large read ops, 42 write ops}
2019-06-12 13:21:10,339 [Thread-489] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket03039.volume07407 implemented by OzoneFileSystem{URI=o3fs://bucket03039.volume07407, workingDir=o3fs://bucket03039.volume07407/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 265 read ops, 0 large read ops, 43 write ops}
13:21:10.340 [IPC Server handler 2 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume07407, bucket=bucket03039, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume07407 bucket: bucket03039 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,342 [Thread-489] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listStatus(path) call on a path which is not present
13:21:10.345 [IPC Server handler 9 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=LIST_STATUS {volume=volume07407, bucket=bucket03039, key=test/missing, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume07407 bucket: bucket03039 key: test/missing
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listStatus(KeyManagerImpl.java:1884) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.listStatus(OzoneManager.java:2999) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.listStatus(OzoneManagerRequestHandler.java:1112) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:357) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,346 [Thread-489] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket03039.volume07407, workingDir=o3fs://bucket03039.volume07407/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 268 read ops, 0 large read ops, 43 write ops}
2019-06-12 13:21:10,380 [Thread-490] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket49405.volume98426 implemented by OzoneFileSystem{URI=o3fs://bucket49405.volume98426, workingDir=o3fs://bucket49405.volume98426/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 271 read ops, 0 large read ops, 44 write ops}
13:21:10.381 [IPC Server handler 0 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume98426, bucket=bucket49405, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume98426 bucket: bucket49405 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,383 [Thread-490] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listStatus(path, filter) call on a missing path
13:21:10.385 [IPC Server handler 3 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=LIST_STATUS {volume=volume98426, bucket=bucket49405, key=test/missing, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume98426 bucket: bucket49405 key: test/missing
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listStatus(KeyManagerImpl.java:1884) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.listStatus(OzoneManager.java:2999) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.listStatus(OzoneManagerRequestHandler.java:1112) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:357) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,385 [Thread-490] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket49405.volume98426, workingDir=o3fs://bucket49405.volume98426/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 274 read ops, 0 large read ops, 44 write ops}
2019-06-12 13:21:10,423 [Thread-491] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket05160.volume21619 implemented by OzoneFileSystem{URI=o3fs://bucket05160.volume21619, workingDir=o3fs://bucket05160.volume21619/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 277 read ops, 0 large read ops, 45 write ops}
13:21:10.424 [IPC Server handler 16 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume21619, bucket=bucket05160, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume21619 bucket: bucket05160 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,426 [Thread-491] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the listFiles(path, true) on a file
2019-06-12 13:21:10,430 [Thread-491] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket05160.volume21619, workingDir=o3fs://bucket05160.volume21619/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 281 read ops, 0 large read ops, 46 write ops}
2019-06-12 13:21:10,465 [Thread-492] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket07487.volume39670 implemented by OzoneFileSystem{URI=o3fs://bucket07487.volume39670, workingDir=o3fs://bucket07487.volume39670/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 284 read ops, 0 large read ops, 47 write ops}
13:21:10.466 [IPC Server handler 12 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume39670, bucket=bucket07487, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume39670 bucket: bucket07487 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,468 [Thread-492] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:describe(255)) - test the LocatedStatus call on a path which is not present
13:21:10.469 [IPC Server handler 15 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=LIST_STATUS {volume=volume39670, bucket=bucket07487, key=test/missing, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume39670 bucket: bucket07487 key: test/missing
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.KeyManagerImpl.listStatus(KeyManagerImpl.java:1884) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.listStatus(OzoneManager.java:2999) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.listStatus(OzoneManagerRequestHandler.java:1112) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:357) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,470 [Thread-492] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket07487.volume39670, workingDir=o3fs://bucket07487.volume39670/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 287 read ops, 0 large read ops, 47 write ops}
2019-06-12 13:21:10,506 [Thread-493] INFO  contract.AbstractFSContractTestBase (AbstractFSContractTestBase.java:setup(184)) - Test filesystem = o3fs://bucket26781.volume87411 implemented by OzoneFileSystem{URI=o3fs://bucket26781.volume87411, workingDir=o3fs://bucket26781.volume87411/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 290 read ops, 0 large read ops, 48 write ops}
13:21:10.507 [IPC Server handler 7 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume87411, bucket=bucket26781, key=test, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume87411 bucket: bucket26781 key: test
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
13:21:10.510 [IPC Server handler 14 on 34047] ERROR OMAudit - user=root | ip=127.0.0.1 | op=GET_FILE_STATUS {volume=volume87411, bucket=bucket26781, key=test/test/target, dataSize=0, replicationType=null, replicationFactor=null, keyLocationInfo=null} | ret=FAILURE
org.apache.hadoop.ozone.om.exceptions.OMException: Unable to get file status: volume: volume87411 bucket: bucket26781 key: test/test/target
	at org.apache.hadoop.ozone.om.KeyManagerImpl.getFileStatus(KeyManagerImpl.java:1701) ~[classes/:?]
	at org.apache.hadoop.ozone.om.OzoneManager.getFileStatus(OzoneManager.java:2897) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.getOzoneFileStatus(OzoneManagerRequestHandler.java:1048) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerRequestHandler.handle(OzoneManagerRequestHandler.java:339) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequestDirectlyToOM(OzoneManagerProtocolServerSideTranslatorPB.java:180) [classes/:?]
	at org.apache.hadoop.ozone.protocolPB.OzoneManagerProtocolServerSideTranslatorPB.submitRequest(OzoneManagerProtocolServerSideTranslatorPB.java:102) [classes/:?]
	at org.apache.hadoop.ozone.protocol.proto.OzoneManagerProtocolProtos$OzoneManagerService$2.callBlockingMethod(OzoneManagerProtocolProtos.java) [classes/:?]
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:524) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.RPC$Server.call(RPC.java:1025) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:876) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$RpcCall.run(Server.java:822) [hadoop-common-3.2.0.jar:?]
	at java.security.AccessController.doPrivileged(Native Method) [?:1.8.0_212]
	at javax.security.auth.Subject.doAs(Subject.java:422) [?:1.8.0_212]
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730) [hadoop-common-3.2.0.jar:?]
	at org.apache.hadoop.ipc.Server$Handler.run(Server.java:2682) [hadoop-common-3.2.0.jar:?]
2019-06-12 13:21:10,511 [Thread-493] INFO  contract.ITestOzoneContractGetFileStatus (ITestOzoneContractGetFileStatus.java:teardown(57)) - FS details OzoneFileSystem{URI=o3fs://bucket26781.volume87411, workingDir=o3fs://bucket26781.volume87411/user/root, userName=root, statistics=0 bytes read, 8192 bytes written, 293 read ops, 0 large read ops, 48 write ops}
2019-06-12 13:21:10,515 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:shutdown(321)) - Shutting down the Mini Ozone Cluster
2019-06-12 13:21:10,515 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(336)) - Stopping the Mini Ozone Cluster
2019-06-12 13:21:10,515 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(338)) - Stopping the OzoneManager
2019-06-12 13:21:10,516 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 34047
2019-06-12 13:21:10,517 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service KeyDeletingService
2019-06-12 13:21:10,517 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-12 13:21:10,518 [IPC Server listener on 34047] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 34047
2019-06-12 13:21:10,520 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@18ca3c62{/,null,UNAVAILABLE}{/ozoneManager}
2019-06-12 13:21:10,522 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@2c0f7678{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:10,523 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@4d666b41{/static,file:///opt/src/hadoop-ozone/ozone-manager/target/classes/webapps/static/,UNAVAILABLE}
2019-06-12 13:21:10,523 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@66f66866{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-12 13:21:10,525 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(344)) - Stopping the StorageContainerManager
2019-06-12 13:21:10,525 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(789)) - Stopping Replication Manager Service.
2019-06-12 13:21:10,525 [JUnit] INFO  container.ReplicationManager (ReplicationManager.java:stop(191)) - Replication Monitor Thread is not running.
2019-06-12 13:21:10,525 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(796)) - Stopping Lease Manager of the command watchers
2019-06-12 13:21:10,525 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(803)) - Stopping datanode service RPC server
2019-06-12 13:21:10,525 [JUnit] INFO  server.SCMDatanodeProtocolServer (SCMDatanodeProtocolServer.java:stop(373)) - Stopping the RPC server for DataNodes
2019-06-12 13:21:10,526 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 33157
2019-06-12 13:21:10,526 [IPC Server listener on 33157] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 33157
2019-06-12 13:21:10,526 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-12 13:21:10,527 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(811)) - Stopping block service RPC server
2019-06-12 13:21:10,527 [JUnit] INFO  server.SCMBlockProtocolServer (SCMBlockProtocolServer.java:stop(145)) - Stopping the RPC server for Block Protocol
2019-06-12 13:21:10,527 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 42175
2019-06-12 13:21:10,528 [IPC Server listener on 42175] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 42175
2019-06-12 13:21:10,528 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(818)) - Stopping the StorageContainerLocationProtocol RPC server
2019-06-12 13:21:10,528 [JUnit] INFO  server.SCMClientProtocolServer (SCMClientProtocolServer.java:stop(157)) - Stopping the RPC server for Client Protocol
2019-06-12 13:21:10,528 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-12 13:21:10,528 [JUnit] INFO  ipc.Server (Server.java:stop(3082)) - Stopping server on 38293
2019-06-12 13:21:10,530 [IPC Server listener on 38293] INFO  ipc.Server (Server.java:run(1185)) - Stopping IPC Server listener on 38293
2019-06-12 13:21:10,530 [IPC Server Responder] INFO  ipc.Server (Server.java:run(1319)) - Stopping IPC Server Responder
2019-06-12 13:21:10,530 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(825)) - Stopping Storage Container Manager HTTP server.
2019-06-12 13:21:10,531 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@69637b10{/,null,UNAVAILABLE}{/scm}
2019-06-12 13:21:10,531 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@63192798{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:10,532 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@22f31dec{/static,file:///opt/src/hadoop-hdds/server-scm/target/classes/webapps/static/,UNAVAILABLE}
2019-06-12 13:21:10,532 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@e57b96d{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-12 13:21:10,532 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(836)) - Stopping Block Manager Service.
2019-06-12 13:21:10,533 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-06-12 13:21:10,533 [JUnit] INFO  utils.BackgroundService (BackgroundService.java:shutdown(148)) - Shutting down service SCMBlockDeletingService
2019-06-12 13:21:10,533 [JUnit] INFO  server.StorageContainerManager (StorageContainerManager.java:stop(858)) - Stopping SCM Event Queue.
2019-06-12 13:21:10,537 [JUnit] INFO  ozone.MiniOzoneClusterImpl (MiniOzoneClusterImpl.java:stop(350)) - Shutting the HddsDatanodes
2019-06-12 13:21:10,538 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-12 13:21:10,539 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@28369db0
2019-06-12 13:21:10,539 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-12 13:21:10,540 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-12 13:21:10,540 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: close
2019-06-12 13:21:10,541 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown group-166B3F51B5DF
2019-06-12 13:21:10,541 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown group-0FC2C454EE19
2019-06-12 13:21:10,541 [ForkJoinPool.commonPool-worker-0] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-166B3F51B5DF,id=8b94d44c-8dc5-4b41-bfaf-9726c3db5eec
2019-06-12 13:21:10,541 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-0FC2C454EE19,id=8b94d44c-8dc5-4b41-bfaf-9726c3db5eec
2019-06-12 13:21:10,541 [ForkJoinPool.commonPool-worker-0] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown FollowerState
2019-06-12 13:21:10,542 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown LeaderState
2019-06-12 13:21:10,542 [Thread-262] INFO  impl.FollowerState (FollowerState.java:run(109)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-12 13:21:10,542 [StateMachineUpdater-8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-group-166B3F51B5DF] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:2, i:63)
2019-06-12 13:21:10,543 [StateMachineUpdater-8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-group-166B3F51B5DF] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/sm/snapshot.2_63
2019-06-12 13:21:10,543 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-PendingRequests: sendNotLeaderResponses
2019-06-12 13:21:10,542 [ForkJoinPool.commonPool-worker-0] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-group-166B3F51B5DF: set stopIndex = 63
2019-06-12 13:21:10,549 [StateMachineUpdater-8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-group-0FC2C454EE19] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-12 13:21:10,552 [ForkJoinPool.commonPool-worker-0] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-166B3F51B5DF closes. The last applied log index is 63
2019-06-12 13:21:10,549 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-group-0FC2C454EE19: set stopIndex = 0
2019-06-12 13:21:10,553 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:group-0FC2C454EE19 closes. The last applied log index is 0
2019-06-12 13:21:10,553 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:10,553 [8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:10,555 [ForkJoinPool.commonPool-worker-0] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker close()
2019-06-12 13:21:10,557 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec-RaftLogWorker close()
2019-06-12 13:21:10,558 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown server with port 39695 now
2019-06-12 13:21:10,562 [grpc-default-executor-0] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: appendEntries onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-12 13:21:10,565 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 0 seconds.
java.io.EOFException: End of File Exception between local host is: "ozone-5qnff-751971879/192.168.19.39"; destination host is: "0.0.0.0":33157; : java.io.EOFException; For more details see:  http://wiki.apache.org/hadoop/EOFException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:789)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.EOFException
	at java.io.DataInputStream.readInt(DataInputStream.java:392)
	at org.apache.hadoop.ipc.Client$IpcStreams.readResponse(Client.java:1816)
	at org.apache.hadoop.ipc.Client$Connection.receiveRpcResponse(Client.java:1173)
	at org.apache.hadoop.ipc.Client$Connection.run(Client.java:1069)
2019-06-12 13:21:10,567 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-06-12 13:21:10,571 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 65 -> 0
2019-06-12 13:21:10,572 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: shutdown server with port 39695 successfully
2019-06-12 13:21:10,577 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-0/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-12 13:21:10,590 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-12 13:21:10,591 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@3f49e266{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-12 13:21:10,591 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@5f18f9d2{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:10,591 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@3f93e4a8{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-12 13:21:10,592 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7f572c37{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-12 13:21:10,592 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-12 13:21:10,592 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@77c1e611
2019-06-12 13:21:10,593 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-12 13:21:10,624 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:10,629 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:11,121 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:11,122 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:11,571 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:11,622 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:11,623 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:12,126 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:12,127 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:12,571 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:12,628 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:12,629 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:13,129 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:13,130 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:13,572 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:13,631 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:13,632 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:14,133 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:14,134 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:14,572 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:14,635 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:14,636 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:15,136 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:15,138 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:15,573 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:15,593 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 0 seconds.
java.io.InterruptedIOException: DestHost:destPort 0.0.0.0:33157 , LocalHost:localPort ozone-5qnff-751971879/192.168.19.39:0. Failed on local exception: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.io.InterruptedIOException: Interrupted: action=RetryAction(action=RETRY, delayMillis=1000, reason=retries get failed due to exceeded maximum allowed retries number: 10), retry policy=RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
	at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:945)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:706)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
Caused by: java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at org.apache.hadoop.ipc.Client$Connection.handleConnectionFailure(Client.java:943)
	... 18 more
2019-06-12 13:21:15,595 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-12 13:21:15,595 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 981253f6-13e6-412d-99d7-955bff6db2c2: close
2019-06-12 13:21:15,596 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown group-6A045A6D2136
2019-06-12 13:21:15,596 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown group-166B3F51B5DF
2019-06-12 13:21:15,596 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-6A045A6D2136,id=981253f6-13e6-412d-99d7-955bff6db2c2
2019-06-12 13:21:15,596 [ForkJoinPool.commonPool-worker-1] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-166B3F51B5DF,id=981253f6-13e6-412d-99d7-955bff6db2c2
2019-06-12 13:21:15,597 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown LeaderState
2019-06-12 13:21:15,597 [ForkJoinPool.commonPool-worker-1] INFO  impl.RoleInfo (RoleInfo.java:shutdownFollowerState(121)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown FollowerState
2019-06-12 13:21:15,597 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 981253f6-13e6-412d-99d7-955bff6db2c2-PendingRequests: sendNotLeaderResponses
2019-06-12 13:21:15,597 [StateMachineUpdater-981253f6-13e6-412d-99d7-955bff6db2c2-group-166B3F51B5DF] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:2, i:63)
2019-06-12 13:21:15,597 [StateMachineUpdater-981253f6-13e6-412d-99d7-955bff6db2c2-group-166B3F51B5DF] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/sm/snapshot.2_63
2019-06-12 13:21:15,597 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-981253f6-13e6-412d-99d7-955bff6db2c2-group-6A045A6D2136: set stopIndex = 0
2019-06-12 13:21:15,600 [Thread-261] INFO  impl.FollowerState (FollowerState.java:run(109)) - 981253f6-13e6-412d-99d7-955bff6db2c2: FollowerState was interrupted: java.lang.InterruptedException: sleep interrupted
2019-06-12 13:21:15,597 [ForkJoinPool.commonPool-worker-1] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-981253f6-13e6-412d-99d7-955bff6db2c2-group-166B3F51B5DF: set stopIndex = 64
2019-06-12 13:21:15,597 [StateMachineUpdater-981253f6-13e6-412d-99d7-955bff6db2c2-group-6A045A6D2136] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-12 13:21:15,601 [ForkJoinPool.commonPool-worker-1] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-166B3F51B5DF closes. The last applied log index is 64
2019-06-12 13:21:15,601 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 981253f6-13e6-412d-99d7-955bff6db2c2:group-6A045A6D2136 closes. The last applied log index is 0
2019-06-12 13:21:15,601 [981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:15,601 [981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:15,603 [ForkJoinPool.commonPool-worker-1] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker close()
2019-06-12 13:21:15,603 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 981253f6-13e6-412d-99d7-955bff6db2c2-RaftLogWorker close()
2019-06-12 13:21:15,606 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown server with port 41639 now
2019-06-12 13:21:15,608 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: HTTP/2 error code: CANCEL
Received Rst Stream
2019-06-12 13:21:15,608 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 981253f6-13e6-412d-99d7-955bff6db2c2: shutdown server with port 41639 successfully
2019-06-12 13:21:15,609 [grpc-default-executor-1] WARN  server.GrpcServerProtocolService (LogUtils.java:warn(134)) - 981253f6-13e6-412d-99d7-955bff6db2c2: appendEntries onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-12 13:21:15,609 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 65 -> 0
2019-06-12 13:21:15,611 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-1/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-12 13:21:15,641 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:15,643 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:15,647 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:15,648 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:15,650 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-12 13:21:15,651 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@b46e103{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-12 13:21:15,651 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@518aac41{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:15,651 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@5b9499fe{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-12 13:21:15,651 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@abbe000{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-12 13:21:15,652 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-12 13:21:15,652 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@7bc6935c
2019-06-12 13:21:15,653 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-12 13:21:16,142 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:16,144 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:16,146 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:16,147 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:16,595 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:16,643 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:16,644 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:16,647 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:16,648 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:17,145 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:17,147 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:17,149 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:17,150 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:17,596 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:17,649 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:17,651 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:17,657 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:17,658 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:18,148 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:18,150 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:18,151 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:18,152 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:18,597 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:18,651 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:18,652 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:18,652 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:18,653 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:19,152 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:19,152 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:19,154 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:19,154 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:19,597 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:19,653 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:19,653 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:19,655 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:19,655 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:20,154 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:20,155 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:20,155 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:20,156 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:20,598 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:20,654 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:20,654 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:20,656 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:20,656 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:21,155 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:21,155 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:21,158 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:21,158 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:21,598 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:21,656 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:21,656 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:21,656 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:21,656 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:22,156 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:22,156 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:22,157 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:22,157 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:22,599 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:22,657 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:22,661 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:22,661 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:22,662 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:23,158 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:23,158 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:23,158 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:23,158 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:23,600 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:23,658 [grpc-default-executor-3] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:23,658 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:23,659 [grpc-default-executor-3] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:23,659 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:24,159 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:24,159 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:24,160 [grpc-default-executor-0] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:24,160 [grpc-default-executor-0] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:24,600 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:24,660 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:24,660 [grpc-default-executor-4] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:24,660 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:24,660 [grpc-default-executor-4] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:25,161 [grpc-default-executor-2] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 981253f6-13e6-412d-99d7-955bff6db2c2:192.168.19.39:41639: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:25,161 [grpc-default-executor-1] WARN  server.GrpcLogAppender (LogUtils.java:warn(134)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: Failed appendEntries to 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec:192.168.19.39:39695: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: UNAVAILABLE: io exception
2019-06-12 13:21:25,161 [grpc-default-executor-2] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->981253f6-13e6-412d-99d7-955bff6db2c2: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:25,161 [grpc-default-executor-1] INFO  impl.FollowerInfo (FollowerInfo.java:lambda$new$0(50)) - 9afe9f49-e1cc-4c44-8276-958a49474b11->8b94d44c-8dc5-4b41-bfaf-9726c3db5eec: nextIndex: updateUnconditionally 0 -> 0
2019-06-12 13:21:25,601 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:25,603 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 0 seconds.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-12 13:21:25,653 [JUnit] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:close(257)) - Unable to shutdown state machine properly.
2019-06-12 13:21:25,653 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-12 13:21:25,653 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: close
2019-06-12 13:21:25,654 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown group-166B3F51B5DF
2019-06-12 13:21:25,654 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-166B3F51B5DF,id=9afe9f49-e1cc-4c44-8276-958a49474b11
2019-06-12 13:21:25,654 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown LeaderState
2019-06-12 13:21:25,654 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-PendingRequests: sendNotLeaderResponses
2019-06-12 13:21:25,655 [org.apache.ratis.server.impl.LogAppender$$Lambda$351/1325422580@4667b932] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(142)) - GrpcLogAppender(9afe9f49-e1cc-4c44-8276-958a49474b11 -> 981253f6-13e6-412d-99d7-955bff6db2c2): Wait interrupted by java.lang.InterruptedException
2019-06-12 13:21:25,655 [org.apache.ratis.server.impl.LogAppender$$Lambda$351/1325422580@445b8082] WARN  server.GrpcLogAppender (GrpcLogAppender.java:mayWait(142)) - GrpcLogAppender(9afe9f49-e1cc-4c44-8276-958a49474b11 -> 8b94d44c-8dc5-4b41-bfaf-9726c3db5eec): Wait interrupted by java.lang.InterruptedException
2019-06-12 13:21:25,658 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-9afe9f49-e1cc-4c44-8276-958a49474b11-group-166B3F51B5DF: set stopIndex = 64
2019-06-12 13:21:25,658 [StateMachineUpdater-9afe9f49-e1cc-4c44-8276-958a49474b11-group-166B3F51B5DF] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:2, i:63)
2019-06-12 13:21:25,658 [StateMachineUpdater-9afe9f49-e1cc-4c44-8276-958a49474b11-group-166B3F51B5DF] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(249)) - Taking a snapshot to file /opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/ratis/13ecd491-4217-450f-b62a-166b3f51b5df/sm/snapshot.2_63
2019-06-12 13:21:25,658 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-166B3F51B5DF closes. The last applied log index is 64
2019-06-12 13:21:25,659 [9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:25,662 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker close()
2019-06-12 13:21:25,664 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown group-ECEBFA9BD555
2019-06-12 13:21:25,664 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-ECEBFA9BD555,id=9afe9f49-e1cc-4c44-8276-958a49474b11
2019-06-12 13:21:25,664 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown LeaderState
2019-06-12 13:21:25,664 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-PendingRequests: sendNotLeaderResponses
2019-06-12 13:21:25,664 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-9afe9f49-e1cc-4c44-8276-958a49474b11-group-ECEBFA9BD555: set stopIndex = 0
2019-06-12 13:21:25,665 [StateMachineUpdater-9afe9f49-e1cc-4c44-8276-958a49474b11-group-ECEBFA9BD555] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-12 13:21:25,665 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 9afe9f49-e1cc-4c44-8276-958a49474b11:group-ECEBFA9BD555 closes. The last applied log index is 0
2019-06-12 13:21:25,665 [9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:25,666 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 9afe9f49-e1cc-4c44-8276-958a49474b11-RaftLogWorker close()
2019-06-12 13:21:25,667 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown server with port 39979 now
2019-06-12 13:21:25,668 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 9afe9f49-e1cc-4c44-8276-958a49474b11: shutdown server with port 39979 successfully
2019-06-12 13:21:25,672 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-2/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-12 13:21:25,669 [grpc-default-executor-2] WARN  client.GrpcClientProtocolService (LogUtils.java:warn(134)) - 1-UnorderedRequestStreamObserver1: onError: org.apache.ratis.thirdparty.io.grpc.StatusRuntimeException: CANCELLED: cancelled before receiving half close
2019-06-12 13:21:25,686 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-12 13:21:25,687 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@4d157493{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-12 13:21:25,687 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@54c622a7{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:25,688 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7c281eb8{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-12 13:21:25,688 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@fe87ddd{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-12 13:21:25,688 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-12 13:21:25,689 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@3592c1c4
2019-06-12 13:21:25,689 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-12 13:21:26,605 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:27,606 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:28,607 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:29,607 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:30,608 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:31,609 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 5 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:32,609 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 6 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:33,610 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 7 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:34,611 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 8 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:35,611 [Datanode State Machine Thread - 0] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 9 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:35,612 [Datanode State Machine Thread - 0] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 0 seconds.
java.net.ConnectException: Your endpoint configuration is wrong; For more details see:  http://wiki.apache.org/hadoop/UnsetHostnameOrPort
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:423)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:831)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:751)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.net.ConnectException: Connection refused
	at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:717)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:206)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-12 13:21:35,614 [Datanode State Machine Thread - 0] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:35,615 [Datanode State Machine Thread - 0] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:35,689 [JUnit] ERROR statemachine.DatanodeStateMachine (DatanodeStateMachine.java:close(257)) - Unable to shutdown state machine properly.
2019-06-12 13:21:35,690 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-12 13:21:35,690 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 3454a52c-2512-4e92-bda0-24f774123a8f: close
2019-06-12 13:21:35,690 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 3454a52c-2512-4e92-bda0-24f774123a8f: shutdown group-83FADFACA32F
2019-06-12 13:21:35,690 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-83FADFACA32F,id=3454a52c-2512-4e92-bda0-24f774123a8f
2019-06-12 13:21:35,690 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 3454a52c-2512-4e92-bda0-24f774123a8f: shutdown LeaderState
2019-06-12 13:21:35,690 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 3454a52c-2512-4e92-bda0-24f774123a8f-PendingRequests: sendNotLeaderResponses
2019-06-12 13:21:35,691 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-3454a52c-2512-4e92-bda0-24f774123a8f-group-83FADFACA32F: set stopIndex = 0
2019-06-12 13:21:35,691 [StateMachineUpdater-3454a52c-2512-4e92-bda0-24f774123a8f-group-83FADFACA32F] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-12 13:21:35,691 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 3454a52c-2512-4e92-bda0-24f774123a8f:group-83FADFACA32F closes. The last applied log index is 0
2019-06-12 13:21:35,691 [3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:35,693 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 3454a52c-2512-4e92-bda0-24f774123a8f-RaftLogWorker close()
2019-06-12 13:21:35,694 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 3454a52c-2512-4e92-bda0-24f774123a8f: shutdown server with port 43553 now
2019-06-12 13:21:35,694 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 3454a52c-2512-4e92-bda0-24f774123a8f: shutdown server with port 43553 successfully
2019-06-12 13:21:35,695 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-3/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-12 13:21:35,713 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-12 13:21:35,713 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@5974b7e8{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-12 13:21:35,714 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@6d8f7166{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:35,714 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@413bef78{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-12 13:21:35,715 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@7e3d7dd{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
2019-06-12 13:21:35,715 [JUnit] INFO  datanode.ObjectStoreHandler (ObjectStoreHandler.java:close(155)) - Closing ObjectStoreHandler.
2019-06-12 13:21:35,715 [JUnit] INFO  ozone.HddsDatanodeService (HddsDatanodeService.java:stop(452)) - Stopped plug-in org.apache.hadoop.ozone.web.OzoneHddsDatanodeService@1d7eb170
2019-06-12 13:21:35,716 [Datanode State Machine Thread - 0] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:lambda$startDaemon$0(350)) - Ozone container server started.
2019-06-12 13:21:36,617 [Datanode State Machine Thread - 1] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 0 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:37,617 [Datanode State Machine Thread - 1] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 1 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:38,618 [Datanode State Machine Thread - 1] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 2 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:39,619 [Datanode State Machine Thread - 1] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 3 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:40,619 [Datanode State Machine Thread - 1] INFO  ipc.Client (Client.java:handleConnectionFailure(948)) - Retrying connect to server: 0.0.0.0/0.0.0.0:33157. Already tried 4 time(s); retry policy is RetryUpToMaximumCountWithFixedSleep(maxRetries=10, sleepTime=1000 MILLISECONDS)
2019-06-12 13:21:40,717 [Datanode State Machine Thread - 1] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,717 [Datanode State Machine Thread - 1] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,718 [Datanode State Machine Thread - 2] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,718 [Datanode State Machine Thread - 2] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,719 [Datanode State Machine Thread - 2] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,720 [Datanode State Machine Thread - 2] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,720 [Datanode State Machine Thread - 1] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,720 [Datanode State Machine Thread - 3] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,721 [Datanode State Machine Thread - 3] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,721 [Datanode State Machine Thread - 2] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,724 [Datanode State Machine Thread - 2] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,724 [Datanode State Machine Thread - 3] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,724 [Datanode State Machine Thread - 3] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,725 [Datanode State Machine Thread - 3] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,725 [Datanode State Machine Thread - 3] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,726 [Datanode State Machine Thread - 4] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,727 [Datanode State Machine Thread - 4] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,728 [Datanode State Machine Thread - 4] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,728 [Datanode State Machine Thread - 4] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,728 [Datanode State Machine Thread - 4] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,728 [Datanode State Machine Thread - 4] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,729 [Datanode State Machine Thread - 5] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,729 [Datanode State Machine Thread - 5] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,730 [Datanode State Machine Thread - 6] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,730 [Datanode State Machine Thread - 6] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,731 [Datanode State Machine Thread - 5] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,732 [Datanode State Machine Thread - 5] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,732 [Datanode State Machine Thread - 7] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,732 [Datanode State Machine Thread - 7] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,732 [Datanode State Machine Thread - 6] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,733 [Datanode State Machine Thread - 6] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,733 [Datanode State Machine Thread - 7] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,734 [Datanode State Machine Thread - 7] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,734 [Datanode State Machine Thread - 8] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,734 [Datanode State Machine Thread - 8] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,735 [Datanode State Machine Thread - 8] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,736 [Datanode State Machine Thread - 8] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,736 [Datanode State Machine Thread - 9] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,743 [Datanode State Machine Thread - 9] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,744 [Datanode State Machine Thread - 10] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,744 [Datanode State Machine Thread - 10] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,745 [Datanode State Machine Thread - 10] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 10 seconds.
java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "ozone-5qnff-751971879/192.168.19.39"; destination host is: "0.0.0.0":33157; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:816)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-12 13:21:40,745 [Datanode State Machine Thread - 11] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,746 [Datanode State Machine Thread - 11] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,746 [Datanode State Machine Thread - 9] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,747 [Datanode State Machine Thread - 9] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,748 [Datanode State Machine Thread - 12] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,748 [Datanode State Machine Thread - 12] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,749 [Datanode State Machine Thread - 13] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,749 [Datanode State Machine Thread - 13] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,749 [Datanode State Machine Thread - 14] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,750 [Datanode State Machine Thread - 14] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,750 [Datanode State Machine Thread - 15] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,751 [Datanode State Machine Thread - 15] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,751 [Datanode State Machine Thread - 16] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,751 [Datanode State Machine Thread - 16] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,754 [Datanode State Machine Thread - 10] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,754 [Datanode State Machine Thread - 10] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,754 [Datanode State Machine Thread - 10] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 10 seconds.
java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "ozone-5qnff-751971879/192.168.19.39"; destination host is: "0.0.0.0":33157; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:816)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-12 13:21:40,755 [Datanode State Machine Thread - 11] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,755 [Datanode State Machine Thread - 11] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,756 [Datanode State Machine Thread - 12] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,756 [Datanode State Machine Thread - 12] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,756 [Datanode State Machine Thread - 17] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,757 [Datanode State Machine Thread - 17] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,757 [Datanode State Machine Thread - 13] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,758 [Datanode State Machine Thread - 13] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,759 [Datanode State Machine Thread - 14] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,759 [Datanode State Machine Thread - 14] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,760 [Datanode State Machine Thread - 18] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,760 [Datanode State Machine Thread - 18] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,761 [Datanode State Machine Thread - 19] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,761 [Datanode State Machine Thread - 19] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,762 [Datanode State Machine Thread - 20] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,762 [Datanode State Machine Thread - 20] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,763 [Datanode State Machine Thread - 20] ERROR statemachine.EndpointStateMachine (EndpointStateMachine.java:logIfNeeded(204)) - Unable to communicate to SCM server at 0.0.0.0:33157 for past 20 seconds.
java.io.IOException: Failed on local exception: java.nio.channels.ClosedByInterruptException; Host Details : local host is: "ozone-5qnff-751971879/192.168.19.39"; destination host is: "0.0.0.0":33157; 
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:816)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
Caused by: java.nio.channels.ClosedByInterruptException
	at java.nio.channels.spi.AbstractInterruptibleChannel.end(AbstractInterruptibleChannel.java:202)
	at sun.nio.ch.SocketChannelImpl.connect(SocketChannelImpl.java:659)
	at org.apache.hadoop.net.SocketIOWithTimeout.connect(SocketIOWithTimeout.java:192)
	at org.apache.hadoop.net.NetUtils.connect(NetUtils.java:531)
	at org.apache.hadoop.ipc.Client$Connection.setupConnection(Client.java:690)
	at org.apache.hadoop.ipc.Client$Connection.setupIOstreams(Client.java:794)
	at org.apache.hadoop.ipc.Client$Connection.access$3700(Client.java:411)
	at org.apache.hadoop.ipc.Client.getConnection(Client.java:1572)
	at org.apache.hadoop.ipc.Client.call(Client.java:1403)
	... 13 more
2019-06-12 13:21:40,763 [Datanode State Machine Thread - 21] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,764 [Datanode State Machine Thread - 21] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,764 [Datanode State Machine Thread - 22] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,764 [Datanode State Machine Thread - 22] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,766 [Datanode State Machine Thread - 23] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,766 [Datanode State Machine Thread - 23] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,767 [Datanode State Machine Thread - 24] WARN  ipc.Client (Client.java:handleConnectionFailure(938)) - Interrupted while trying for connection
2019-06-12 13:21:40,767 [Datanode State Machine Thread - 24] WARN  net.NetUtils (NetUtils.java:wrapWithMessage(834)) - Unable to wrap exception of type class java.nio.channels.ClosedByInterruptException: it has no (String) constructor
java.lang.NoSuchMethodException: java.nio.channels.ClosedByInterruptException.<init>(java.lang.String)
	at java.lang.Class.getConstructor0(Class.java:3082)
	at java.lang.Class.getConstructor(Class.java:1825)
	at org.apache.hadoop.net.NetUtils.wrapWithMessage(NetUtils.java:830)
	at org.apache.hadoop.net.NetUtils.wrapException(NetUtils.java:806)
	at org.apache.hadoop.ipc.Client.getRpcResponse(Client.java:1515)
	at org.apache.hadoop.ipc.Client.call(Client.java:1457)
	at org.apache.hadoop.ipc.Client.call(Client.java:1367)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:228)
	at org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:116)
	at com.sun.proxy.$Proxy89.sendHeartbeat(Unknown Source)
	at org.apache.hadoop.ozone.protocolPB.StorageContainerDatanodeProtocolClientSideTranslatorPB.sendHeartbeat(StorageContainerDatanodeProtocolClientSideTranslatorPB.java:131)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:139)
	at org.apache.hadoop.ozone.container.common.states.endpoint.HeartbeatEndpointTask.call(HeartbeatEndpointTask.java:74)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
	at java.util.concurrent.FutureTask.run(FutureTask.java:266)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)
	at java.lang.Thread.run(Thread.java:748)
2019-06-12 13:21:40,768 [JUnit] INFO  ozoneimpl.OzoneContainer (OzoneContainer.java:stop(199)) - Attempting to stop container services.
2019-06-12 13:21:40,769 [JUnit] INFO  impl.RaftServerProxy (RaftServerProxy.java:lambda$close$4(314)) - 2812392d-5f88-4ec2-8910-05af6013a4af: close
2019-06-12 13:21:40,769 [JUnit] INFO  impl.RaftServerImpl (RaftServerImpl.java:lambda$shutdown$3(238)) - 2812392d-5f88-4ec2-8910-05af6013a4af: shutdown group-AA3197D8FA17
2019-06-12 13:21:40,769 [JUnit] INFO  util.JmxRegister (JmxRegister.java:unregister(73)) - Successfully un-registered JMX Bean with object name Ratis:service=RaftServer,group=group-AA3197D8FA17,id=2812392d-5f88-4ec2-8910-05af6013a4af
2019-06-12 13:21:40,769 [JUnit] INFO  impl.RoleInfo (RoleInfo.java:shutdownLeaderState(104)) - 2812392d-5f88-4ec2-8910-05af6013a4af: shutdown LeaderState
2019-06-12 13:21:40,770 [JUnit] INFO  impl.PendingRequests (PendingRequests.java:sendNotLeaderResponses(140)) - 2812392d-5f88-4ec2-8910-05af6013a4af-PendingRequests: sendNotLeaderResponses
2019-06-12 13:21:40,770 [JUnit] INFO  impl.StateMachineUpdater (StateMachineUpdater.java:stopAndJoin(109)) - StateMachineUpdater-2812392d-5f88-4ec2-8910-05af6013a4af-group-AA3197D8FA17: set stopIndex = 0
2019-06-12 13:21:40,770 [StateMachineUpdater-2812392d-5f88-4ec2-8910-05af6013a4af-group-AA3197D8FA17] INFO  ratis.ContainerStateMachine (ContainerStateMachine.java:takeSnapshot(245)) - Taking snapshot at termIndex:(t:0, i:~)
2019-06-12 13:21:40,771 [JUnit] INFO  impl.RaftServerImpl (ServerState.java:close(394)) - 2812392d-5f88-4ec2-8910-05af6013a4af:group-AA3197D8FA17 closes. The last applied log index is 0
2019-06-12 13:21:40,771 [2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker] INFO  storage.RaftLogWorker (RaftLogWorker.java:run(236)) - 2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker was interrupted, exiting. There are 0 tasks remaining in the queue.
2019-06-12 13:21:40,772 [JUnit] INFO  storage.RaftLogWorker (RaftLogWorker.java:close(168)) - 2812392d-5f88-4ec2-8910-05af6013a4af-RaftLogWorker close()
2019-06-12 13:21:40,773 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(154)) - 2812392d-5f88-4ec2-8910-05af6013a4af: shutdown server with port 37967 now
2019-06-12 13:21:40,774 [JUnit] INFO  server.GrpcService (GrpcService.java:closeImpl(162)) - 2812392d-5f88-4ec2-8910-05af6013a4af: shutdown server with port 37967 successfully
2019-06-12 13:21:40,776 [refreshUsed-/opt/src/hadoop-ozone/ozonefs/target/test-dir/MiniOzoneClusterImpl-3505faa3-cf9a-4b69-9bc1-f00135256e5e/datanode-4/data/containers] WARN  fs.CachingGetSpaceUsed (CachingGetSpaceUsed.java:run(183)) - Thread Interrupted waiting to refresh disk information: sleep interrupted
2019-06-12 13:21:40,798 [JUnit] INFO  statemachine.DatanodeStateMachine (DatanodeStateMachine.java:stopDaemon(395)) - Ozone container server stopped.
2019-06-12 13:21:40,799 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.w.WebAppContext@202898d7{/,null,UNAVAILABLE}{/hddsDatanode}
2019-06-12 13:21:40,799 [JUnit] INFO  server.AbstractConnector (AbstractConnector.java:doStop(318)) - Stopped ServerConnector@7a8726ec{HTTP/1.1,[http/1.1]}{0.0.0.0:0}
2019-06-12 13:21:40,800 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@59838256{/static,file:///opt/src/hadoop-hdds/container-service/target/classes/webapps/static,UNAVAILABLE}
2019-06-12 13:21:40,800 [JUnit] INFO  handler.ContextHandler (ContextHandler.java:doStop(910)) - Stopped o.e.j.s.ServletContextHandler@1c61eda5{/logs,file:///opt/src/hadoop-ozone/ozonefs/target/log,UNAVAILABLE}
